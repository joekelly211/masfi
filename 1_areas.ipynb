{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/main/1_areas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUUhJgLFYI88"
      },
      "source": [
        "# Imports, directories and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr4kdJvHapxh"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "# Use '/content/drive/MyDrive/' for a personal drive\n",
        "# Use '/gdrive/Shareddrives/' for a shared drive (must be created first)\n",
        "\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "# base_dir = '/content/drive/MyDrive/masfi'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "if base_dir.startswith('/gdrive/Shareddrives/'):\n",
        "  drive.mount('/gdrive', force_remount=True)\n",
        "elif base_dir.startswith('/content/drive/MyDrive/'):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "else: print(\"Create a base_dir beginning with '/gdrive/Shareddrives/' or '/content/drive/MyDrive/'.\")\n",
        "\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljIpLF7_GwQb"
      },
      "outputs": [],
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs and upgrades\n",
        "!pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOQrLyVyW1Qa"
      },
      "outputs": [],
      "source": [
        "# Reload imports, replacing those in the cache.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "import ipywidgets as widgets\n",
        "import math\n",
        "import numpy as np\n",
        "import requests\n",
        "import tarfile\n",
        "import warnings\n",
        "from os import makedirs, remove\n",
        "from os.path import exists, join\n",
        "from shapely.geometry import box\n",
        "from shutil import copyfile, copy\n",
        "from osgeo import gdal, ogr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8ZQtAdTl6vt"
      },
      "outputs": [],
      "source": [
        "# Define directories.\n",
        "areas_dir = join(base_dir, \"1_areas\")\n",
        "predictors_dir = join(base_dir, \"3_predictors\")\n",
        "polygons_dir = join(areas_dir, \"polygons\")\n",
        "dem_dir = join(areas_dir, \"dem\")\n",
        "dem_tiles_dir = join(dem_dir, \"tiles\")\n",
        "\n",
        "# Create directories if they do not exist.\n",
        "makedirs(areas_dir, exist_ok=True)\n",
        "makedirs(polygons_dir, exist_ok=True)\n",
        "makedirs(dem_dir, exist_ok=True)\n",
        "makedirs(dem_tiles_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb2lqtUz4Yw2"
      },
      "outputs": [],
      "source": [
        "# Global function: export an array as a .tif\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "nodatavalue = -1111111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_tif_path, nodatavalue=nodatavalue, compress=compress):\n",
        "  template = gdal.Open(template)\n",
        "  template_band = template.GetRasterBand(1)\n",
        "  template_dimensions, template_projection = template.GetGeoTransform(), template.GetProjection()\n",
        "  if compress: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32,\n",
        "                                                options=[\"COMPRESS=DEFLATE\",\"PREDICTOR=2\",\"ZLEVEL=9\"])\n",
        "  if compress == False: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32)\n",
        "  driver.GetRasterBand(1).WriteArray(input_array)\n",
        "  driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "  driver.SetGeoTransform(template_dimensions)\n",
        "  driver.SetProjection(template_projection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuNPGIEE2BI4"
      },
      "source": [
        "# Project area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xIGIHOL2DSq"
      },
      "outputs": [],
      "source": [
        "# Upload 'project_area.gpkg' polygon to the 1_areas/polygons directory.\n",
        "# This can be a polygon of any shape. A bounding box will be used to create the\n",
        "# GEDI download area in 1_variates.ipynb. # A buffered bounding box will be used\n",
        "# for the raster template, to ensure all predictor edge effects are included.\n",
        "\n",
        "#Project CRS EPSG\n",
        "crs_epsg = 4326\n",
        "\n",
        "# Recommended to buffer at least 300 m to account for predictor edge effects\n",
        "# and clipping imprecision\n",
        "buffer_distance_metres = 300\n",
        "\n",
        "project_area_path = join(polygons_dir, 'project_area.gpkg')\n",
        "\n",
        "if exists(project_area_path):\n",
        "  print(\"Project polygon found:\\n\")\n",
        "  # Read project polygon\n",
        "  project_area_read = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "  display(project_area_read[\"geometry\"].iloc[0])\n",
        "  if project_area_read.crs.to_epsg() == crs_epsg:\n",
        "    project_area_path = join(polygons_dir, \"project_area.gpkg\")\n",
        "    project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "    # Calculate the bounding box of the project polygon\n",
        "    if not exists (project_area_buffered_bbox_path):\n",
        "      # Suppress warning about not being a geographic CRS, as we account for this.\n",
        "      # However larger buffers or project areas near the poles might still need to be converted.\n",
        "      warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "      # Get the centroid of the project polygon\n",
        "      project_polygon_centroid = project_area_read.centroid.values[0]\n",
        "      # Convert the buffer distance from meters to decimal degrees based on the location at the centroid\n",
        "      buffer_distance_degrees = buffer_distance_metres / (111320 * abs(math.cos(math.radians(project_polygon_centroid.y))))\n",
        "      # Buffer the polygon\n",
        "      project_area_buffered = project_area_read.buffer(buffer_distance_degrees)\n",
        "      # Create a bounding box polygon and save\n",
        "      project_area_buffered_bbox = box(*project_area_buffered.total_bounds)\n",
        "      gdf = gpd.GeoDataFrame(geometry=[project_area_buffered_bbox], crs=f\"EPSG:{crs_epsg}\")\n",
        "      gdf.to_file(project_area_buffered_bbox_path, driver='GPKG')\n",
        "      print(f\"Buffered the project area to {buffer_distance_metres} and created a bounding box: {project_area_buffered_bbox_path}\")\n",
        "    else: print(f\"Project area has already been buffered and bound to a box: {project_area_buffered_bbox_path}\")\n",
        "    # Read the buffered project area bounding box\n",
        "    project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "    bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "    project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "    project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "    print(f\"\\nThe buffered polygon bounding box has the coordinates:\\n{project_x_min}, {project_y_min} to {project_x_max}, {project_y_max}.\")\n",
        "  else: print(\"Reproject 'project_area.gpkg' to EPSG:4326.\")\n",
        "else: print(\"Create 'project_area.gpkg' and upload to 1_areas/polygons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2a_lWnP08i"
      },
      "source": [
        "# Download DEM tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjrScY7cLm-S"
      },
      "outputs": [],
      "source": [
        "# Download Copernicus DEM tiles for the project area. Currently the most recent\n",
        "# product is COP-DEM_GLO-30-DGED__2023_1\n",
        "# press release > https://sentinels.copernicus.eu/web/sentinel/-/copernicus-dem-new-direct-data-download-access\n",
        "# Guide > https://spacedata.copernicus.eu/documents/20123/121286/Copernicus+DEM+Open+HTTPS+Access.pdf\n",
        "# List of dataset tiles > https://prism-dem-open.copernicus.eu/pd-desk-open-access/publicDemURLs/COP-DEM_GLO-30-DGED__2023_1\n",
        "# Sometimes the direct servers are down, in which case the '.tar' for each tile needs\n",
        "# to be manually downloaded through other (ever-changing) GLO-30 data repositories\n",
        "# and uploaded to '1_areas/dem/tiles'. Then continue to the 'Process DEM tiles' section.\n",
        "\n",
        "dem_tiles_url_txt_path = join(dem_dir, \"dem_tiles_url.txt\")\n",
        "dem_tiles_url_list = []\n",
        "\n",
        "# If the list of DEM tiles exists as a .txt then open, otherwise download and save.\n",
        "try:\n",
        "  with open(dem_tiles_url_txt_path, 'r') as dem_tiles_url_txt_file:\n",
        "    for url in dem_tiles_url_txt_file:\n",
        "        dem_tiles_url_list.append(url[:-1]) # Remove new line\n",
        "  print(\"DEM tile URL dowload list exists as 'dem_tiles_url.txt' in '1_areas/dem'.\")\n",
        "except:\n",
        "  # Get html content to search for DEM tile download URLS\n",
        "  html = 'https://prism-dem-open.copernicus.eu/pd-desk-open-access/publicDemURLs/COP-DEM_GLO-30-DGED__2023_1'\n",
        "  response = requests.get(html)\n",
        "  response.raise_for_status()\n",
        "  html_content = response.text\n",
        "  # Create list of DEM tile download URLs\n",
        "  url_prefix, url_suffix = '<nativeDemUrl>', '</nativeDemUrl>'\n",
        "  for i in range(1, html_content.count(url_prefix)+1):\n",
        "    tile_url = html_content.split(url_prefix)[i].split(url_suffix)[0]\n",
        "    if 'DSM_10' in tile_url: dem_tiles_url_list.append(tile_url) # avoid DSM_30\n",
        "  # Save the DEM tiles URL list as a .txt file\n",
        "  with open(dem_tiles_url_txt_path, 'w') as dem_tiles_url_txt_file:\n",
        "    for url in dem_tiles_url_list:\n",
        "      dem_tiles_url_txt_file.write(url + \"\\n\")\n",
        "  print(\"DEM tile URL download list saved to 'all_dem_tiles.txt' in '1_areas/dem'.\")\n",
        "\n",
        "# Read the buffered project area bounding box\n",
        "project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "\n",
        "# Filter URL list to tiles overlapped by the project polygon bounding box\n",
        "dem_tiles_url_list_filtered = []\n",
        "\n",
        "for url in dem_tiles_url_list:\n",
        "  # Degree coordinates of DEM tile\n",
        "  degree_coordinates = url[-18:-4]\n",
        "\n",
        "  # Set number of degrees per tile (assuming square)\n",
        "  tile_size = 1\n",
        "\n",
        "  # Extract degree coordinate values\n",
        "  tile_x_dir, tile_x_deg, tile_x_minutes = degree_coordinates[7:8], int(degree_coordinates[8:11]), int(degree_coordinates[12:14])\n",
        "  tile_y_dir, tile_y_deg, tile_y_minutes = degree_coordinates[0][0], int(degree_coordinates[1:3]), int(degree_coordinates[4:6])\n",
        "\n",
        "  # Convert to decimal degree coordinates\n",
        "  if tile_x_dir == 'E':\n",
        "    tile_x_min = tile_x_deg + (tile_x_minutes / 60.0)\n",
        "    tile_x_max = tile_x_min + tile_size\n",
        "  if tile_x_dir == 'W':\n",
        "    tile_x_min = 0 - tile_x_deg - (tile_x_minutes / 60.0)\n",
        "    tile_x_max = tile_x_min + tile_size\n",
        "  if tile_y_dir == 'N':\n",
        "    tile_y_min = tile_y_deg + (tile_y_minutes / 60.0)\n",
        "    tile_y_max = tile_y_min + tile_size\n",
        "  if tile_y_dir == 'S':\n",
        "    tile_y_min = 0 - tile_y_deg - (tile_y_minutes / 60.0)\n",
        "    tile_y_max = tile_y_min + tile_size\n",
        "\n",
        "  # Check whether project bounding box is inside the tile\n",
        "  lon_check = project_x_max > tile_x_min and project_x_min < tile_x_max\n",
        "  lat_check = project_y_max > tile_y_min and project_y_min < tile_y_max\n",
        "  if lon_check and lat_check:\n",
        "    dem_tiles_url_list_filtered.append(url)\n",
        "\n",
        "print(\"DEM tile URL list filtered to project_area_buffered_bbox.gpkg.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MzMbHy3KmLA"
      },
      "outputs": [],
      "source": [
        "# Display progress\n",
        "index = 0\n",
        "progress_label = widgets.Label(value=f\"DEM tile download progress: {index}/{len(dem_tiles_url_list_filtered)}\")\n",
        "display(progress_label)\n",
        "\n",
        "# Process URLs\n",
        "for url in dem_tiles_url_list_filtered:\n",
        "    url = url.strip()  # Remove any white space\n",
        "    dem_tile_zip_filename = url.split('/')[-1]\n",
        "    dem_tile_zip_path = join(dem_tiles_dir, dem_tile_zip_filename)\n",
        "    while True:\n",
        "        try:\n",
        "            if not exists(dem_tile_zip_path):\n",
        "                request = requests.get(url, allow_redirects=True)\n",
        "                open(dem_tile_zip_path, 'wb').write(request.content)\n",
        "            with tarfile.open(dem_tile_zip_path, 'r') as tar:\n",
        "                tar.getmembers()  # Check if tarball is valid\n",
        "            break  # Exit loop if successful\n",
        "        except Exception as e:\n",
        "            if exists(dem_tile_zip_path):\n",
        "                remove(dem_tile_zip_path)  # Delete file if invalid\n",
        "            print(f\"Failed URL: {url} - {e}\")\n",
        "    # Update progress\n",
        "    index += 1\n",
        "    progress_label.value = f\"DEM tile download progress: {index}/{len(dem_tiles_url_list_filtered)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9TuMSdehVVK"
      },
      "source": [
        "# Process DEM tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke7mOK4TfSd-"
      },
      "outputs": [],
      "source": [
        "# Display progress\n",
        "index = 0\n",
        "progress_label = widgets.Label(value=f\"DEM tile extraction progress: {index}/{len(dem_tiles_url_list_filtered)}\")\n",
        "display(progress_label)\n",
        "\n",
        "# Extract tile 'DEM.tif' into the DEM tiles directory if it doesn't already exist.\n",
        "for file in os.listdir(dem_tiles_dir):\n",
        "  if file.endswith(\".tar\"):\n",
        "    dem_tile_filename = f\"{file[:-4]}_DEM.tif\"\n",
        "    dem_tile_path = join(dem_tiles_dir, dem_tile_filename)\n",
        "    if not exists(dem_tile_path):\n",
        "      tar_path = join(dem_tiles_dir, file)\n",
        "      tar_file = tarfile.open(tar_path, 'r')\n",
        "      for member in tar_file.getmembers():\n",
        "        if dem_tile_filename in member.name:\n",
        "          member.name = os.path.basename(member.name)\n",
        "          tar_file.extract(member, dem_tiles_dir)\n",
        "    index += 1\n",
        "    progress_label.value = f\"DEM tile extraction progress: {index}/{len(dem_tiles_url_list_filtered)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyTQqNr_27Fw"
      },
      "outputs": [],
      "source": [
        "# Merge the DEM tiles into a single raster\n",
        "dem_merged_path = join(dem_dir, \"dem_merged.tif\")\n",
        "\n",
        "if not exists(dem_merged_path):\n",
        "  # List tiles\n",
        "  tiles_to_merge = []\n",
        "  for file in os.listdir(dem_tiles_dir):\n",
        "    if file.endswith(\".tif\"):\n",
        "      tiles_to_merge.append(join(dem_tiles_dir, file))\n",
        "  # Create a temporary virtual file (VRT) from the tiles\n",
        "  temp_vrt = join(dem_dir, 'temp.vrt')\n",
        "  gdal.BuildVRT(temp_vrt, tiles_to_merge)\n",
        "  # Merge the input files into a single GeoTIFF file\n",
        "  merge_options = gdal.TranslateOptions(format='GTiff', outputType=gdal.GDT_Float32, noData=nodatavalue,\n",
        "                                  creationOptions=['COMPRESS=DEFLATE', 'PREDICTOR=2', 'ZLEVEL=9'])\n",
        "  gdal.Translate(dem_merged_path, temp_vrt, options=merge_options)\n",
        "  # Remove the temporary VRT file\n",
        "  os.remove(temp_vrt)\n",
        "  print(f\"The merged DEM raster has been saved to: {dem_merged_path}\")\n",
        "else: print(f\"A merged DEM raster already exists at: {dem_merged_path}\")\n",
        "\n",
        "# Clip the raster to project area extent\n",
        "dem_merged_clipped_path = join(dem_dir, \"dem_merged_clipped.tif\")\n",
        "\n",
        "if not exists(dem_merged_clipped_path):\n",
        "  # Read the buffered project area bounding box\n",
        "  project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "  project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "  bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "  # Get coordinates\n",
        "  project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "  project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "  project_coords = [project_x_min, project_y_max, project_x_max, project_y_min]\n",
        "  # Define Translate options\n",
        "  clip_options = gdal.TranslateOptions(projWin=[project_x_min, project_y_max, project_x_max, project_y_min],\n",
        "                                  outputType=gdal.GDT_Float32, noData=nodatavalue)\n",
        "  # call gdal.Translate() with the new options argument\n",
        "  gdal.Translate(dem_merged_clipped_path, dem_merged_path, options=clip_options)\n",
        "  print(f\"The clipped, merged DEM raster has been saved to: {dem_merged_clipped_path}\")\n",
        "else: print(f\"A clipped merged DEM raster already exists at: {dem_merged_clipped_path}\")\n",
        "\n",
        "# Copy the clipped, merged DEM to '3_predictors' directory to use as the base DEM\n",
        "base_dem_path = join(areas_dir, \"base_dem.tif\")\n",
        "\n",
        "if not exists(base_dem_path):\n",
        "  copy(dem_merged_clipped_path, base_dem_path)\n",
        "  print(f\"The clipped, merged DEM has been copied for use as a base DEM: {base_dem_path}\")\n",
        "else: print(f\"A base DEM already exists at: {base_dem_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwICylX1t4mZ"
      },
      "source": [
        "# Create template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys_zk5eHpPkd"
      },
      "outputs": [],
      "source": [
        "# Create template from DEM\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "if not exists(template_tif_path):\n",
        "  dem_merged_clipped_path = join(dem_dir, \"dem_merged_clipped.tif\")\n",
        "  dem_merged_clipped_array = gdal.Open(dem_merged_clipped_path).ReadAsArray() # Convert DEM to array\n",
        "  template_array = np.ones_like(dem_merged_clipped_array) # Change all values to 1\n",
        "  export_array_as_tif(template_array, template_tif_path, template=dem_merged_clipped_path, compress=False)\n",
        "  print(f\"A template raster has been created: {template_tif_path}\")\n",
        "else: print(f\"A template raster already exists at: {template_tif_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDHujjIH7Ftq"
      },
      "outputs": [],
      "source": [
        "# Create template polygon\n",
        "template_polygon_path = join(polygons_dir, \"template.gpkg\")\n",
        "if not exists(template_polygon_path):\n",
        "  # Get template raster spatial data\n",
        "  template_raster = gdal.Open(template_tif_path)\n",
        "  template_raster_band = template_raster.GetRasterBand(1)\n",
        "  spatial_ref = ogr.osr.SpatialReference()\n",
        "  spatial_ref.ImportFromWkt(template_raster.GetProjection())\n",
        "  # Polygonize template raster without fields or layer name\n",
        "  template_polygon_file = ogr.GetDriverByName(\"GPKG\").CreateDataSource(template_polygon_path)\n",
        "  template_polygon_layer = template_polygon_file.CreateLayer(\"\", srs=spatial_ref, geom_type=ogr.wkbPolygon)\n",
        "  gdal.Polygonize(template_raster_band, None, template_polygon_layer, -1)\n",
        "  print(f\"A template polygon has been created: {template_polygon_path}\")\n",
        "else: print(f\"A template polygon already exists at: {template_polygon_path}\")\n",
        "template_polygon_read = gpd.read_file(template_polygon_path)\n",
        "template_polygon_bounds = template_polygon_read.total_bounds\n",
        "print(f\"\\nThe template polygon has the coordinates:\\n{template_polygon_bounds[0]}, {template_polygon_bounds[1]} to {template_polygon_bounds[2]}, {template_polygon_bounds[3]}.\")\n",
        "\n",
        "# Create an inverse project area path for masking\n",
        "inverse_project_area_path = join(polygons_dir, \"project_area_inverse.gpkg\")\n",
        "if not exists(inverse_project_area_path):\n",
        "  template_polygon_path = join(polygons_dir, \"template.gpkg\")\n",
        "  template_polygon = gpd.read_file(template_polygon_path)\n",
        "  project_area_polygon = gpd.read_file(project_area_path)\n",
        "  inverse_project_area_polygon = template_polygon['geometry'].difference(project_area_polygon['geometry']).iloc[0]\n",
        "  inverse_project_area_polygon_gdf = gpd.GeoDataFrame({'geometry': [inverse_project_area_polygon]}, crs=f\"EPSG:{crs_epsg}\")\n",
        "  inverse_project_area_polygon_gdf.to_file(inverse_project_area_path, driver=\"GPKG\")\n",
        "  print(f\"An inverse project area polygon has been created: {template_polygon_path}\")\n",
        "else: print(f\"An inverse project area already exists at: {template_polygon_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c367RQcutCrA"
      },
      "source": [
        "# Create measurement rasters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbZ03-E1vrfA"
      },
      "outputs": [],
      "source": [
        "# Create measurement rasters for predictors and precise summing of pixels\n",
        "\n",
        "# Define template\n",
        "template_path = join(areas_dir, \"template.tif\")\n",
        "template = gdal.Open(template_path)\n",
        "template_array = template.ReadAsArray()\n",
        "rows, cols = template_array.shape\n",
        "\n",
        "# Define Earth radius\n",
        "equatorial_radius = 6_378_137.0 # Equatorial radius in metres\n",
        "polar_radius = 6_356_752.0 # Polar radius in metres\n",
        "\n",
        "# Function for obtaining latitude distance in meters from decimal degrees, at a specific latitude\n",
        "def distance_of_decimal_degrees_latitude(latitude: float, decimal_degrees: float) -> float:\n",
        "    # Calculate the eccentricity squared (e2)\n",
        "    e2 = (equatorial_radius**2 - polar_radius**2) / equatorial_radius**2\n",
        "    # Convert latitude to radians\n",
        "    latitude_rad = math.radians(latitude)\n",
        "    # Calculate the meridional radius of curvature (M)\n",
        "    M = equatorial_radius * (1 - e2) / (1 - e2 * math.sin(latitude_rad)**2)**(3/2)\n",
        "    # Calculate the distance of one degree of latitude\n",
        "    distance_per_degree = math.pi * M / 180\n",
        "    # Calculate the distance of the specified decimal degrees\n",
        "    distance_latitude = distance_per_degree * decimal_degrees\n",
        "    return np.float64(distance_latitude) # Force high precision\n",
        "\n",
        "# Function for obtaining longitude distance in meters from decimal degrees, at a specific latitude\n",
        "def distance_of_decimal_degrees_longitude(latitude: float, decimal_degrees: float) -> float:\n",
        "    # Handle pole proximity\n",
        "    if abs(latitude) > 89.9: return 0.0\n",
        "    # Convert latitude to radians\n",
        "    latitude_rad = math.radians(latitude)\n",
        "    # Calculate the distance of one degree of longitude at the given latitude\n",
        "    distance_per_degree = (math.pi * equatorial_radius * math.cos(latitude_rad)) / 180\n",
        "    # Calculate the distance of the specified decimal degrees\n",
        "    distance_longitude = distance_per_degree * decimal_degrees\n",
        "    return np.float64(distance_longitude) # Force high precision\n",
        "\n",
        "geotransform = template.GetGeoTransform()\n",
        "\n",
        "# Create a raster for the longitude in decimal degrees at the center of each pixel\n",
        "longitude_path = join(areas_dir, \"longitude.tif\")\n",
        "if not exists(longitude_path):\n",
        "    # Handle antimeridian wrapping\n",
        "    longitude_array = np.array([[((geotransform[0] + (c * geotransform[1]) + (r * geotransform[4]) + (geotransform[1] / 2) + 180) % 360 - 180)\n",
        "                                for c in range(cols)] for r in range(rows)], dtype=np.float64) # Force precision\n",
        "    export_array_as_tif(longitude_array, longitude_path)\n",
        "    print(f\"Raster with cell longitude in decimal degrees created: {longitude_path}\")\n",
        "else: print(f\"Raster with cell longitude in decimal degrees already exists: {longitude_path}\")\n",
        "\n",
        "# Create a raster for the latitude in decimal degrees at the center of each pixel\n",
        "latitude_path = join(areas_dir, \"latitude.tif\")\n",
        "if not exists(latitude_path):\n",
        "    # Clamp latitude to valid range\n",
        "    latitude_array = np.clip(np.array([[geotransform[3] + (r * geotransform[5]) + (c * geotransform[2]) + (geotransform[5] / 2)\n",
        "                                      for c in range(cols)] for r in range(rows)], dtype=np.float64), -90, 90) # Force precision\n",
        "    export_array_as_tif(latitude_array, latitude_path)\n",
        "    print(f\"Raster with cell latitude in decimal degrees created: {latitude_path}\")\n",
        "else: print(f\"Raster with cell latitude in decimal degrees already exists: {latitude_path}\")\n",
        "latitude_array = gdal.Open(latitude_path).ReadAsArray()\n",
        "\n",
        "# Create a raster for the cell width in meters\n",
        "cell_size_x_path = join(areas_dir, \"cell_size_x.tif\")\n",
        "if not exists(cell_size_x_path):\n",
        "    cell_size_x_array = np.vectorize(distance_of_decimal_degrees_longitude)(latitude_array, geotransform[1])\n",
        "    export_array_as_tif(cell_size_x_array, cell_size_x_path)\n",
        "    print(f\"Raster with cell width in metres created: {cell_size_x_path}\")\n",
        "else: print(f\"Raster with cell width in metres already exists: {cell_size_x_path}\")\n",
        "\n",
        "# Create a raster for the cell height in meters\n",
        "cell_size_y_path = join(areas_dir, \"cell_size_y.tif\")\n",
        "if not exists(cell_size_y_path):\n",
        "    cell_size_y_array = np.vectorize(distance_of_decimal_degrees_latitude)(latitude_array, abs(geotransform[5]))\n",
        "    export_array_as_tif(cell_size_y_array, cell_size_y_path)\n",
        "    print(f\"Raster with cell height in metres created: {cell_size_y_path}\")\n",
        "else: print(f\"Raster with cell height in metres already exists: {cell_size_y_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_RENY6twBXx"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h__20O9kwA9K"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "J9TuMSdehVVK",
        "NwICylX1t4mZ",
        "c367RQcutCrA"
      ],
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}