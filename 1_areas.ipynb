{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/main/1_areas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUUhJgLFYI88"
      },
      "source": [
        "# Imports, directories and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr4kdJvHapxh"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "\n",
        "# Mount Google Drive and set base directory\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljIpLF7_GwQb"
      },
      "outputs": [],
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs and upgrades\n",
        "!pip install geopandas\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOQrLyVyW1Qa"
      },
      "outputs": [],
      "source": [
        "# Reload imports, replacing those in the cache\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# Imports\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "import ipywidgets as widgets\n",
        "import math\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import requests\n",
        "import tarfile\n",
        "import warnings\n",
        "from os import makedirs, remove\n",
        "from os.path import exists, join\n",
        "from rasterio.features import rasterize\n",
        "from shapely.geometry import box\n",
        "from shutil import copyfile, copy\n",
        "from osgeo import gdal, ogr\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8ZQtAdTl6vt"
      },
      "outputs": [],
      "source": [
        "# Define 1_areas directories.\n",
        "areas_dir = join(base_dir, \"1_areas\")\n",
        "predictors_dir = join(base_dir, \"3_predictors\")\n",
        "\n",
        "countries_dir = join(areas_dir, \"countries\")\n",
        "polygons_dir = join(areas_dir, \"polygons\")\n",
        "dem_dir = join(areas_dir, \"dem\")\n",
        "dem_tiles_dir = join(dem_dir, \"tiles\")\n",
        "masks_dir = join(areas_dir, \"masks\")\n",
        "\n",
        "# Create directories if they do not exist.\n",
        "makedirs(areas_dir, exist_ok=True)\n",
        "makedirs(countries_dir, exist_ok=True)\n",
        "makedirs(polygons_dir, exist_ok=True)\n",
        "makedirs(dem_dir, exist_ok=True)\n",
        "makedirs(dem_tiles_dir, exist_ok=True)\n",
        "makedirs(masks_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGXEy9Yjoxel"
      },
      "outputs": [],
      "source": [
        "# Global function: export an array as a .tif\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "nodatavalue = -1111111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_tif_path, nodatavalue=nodatavalue, compress=compress):\n",
        "  template = gdal.Open(template)\n",
        "  template_band = template.GetRasterBand(1)\n",
        "  template_dimensions, template_projection = template.GetGeoTransform(), template.GetProjection()\n",
        "  if compress: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32,\n",
        "                                                options=[\"COMPRESS=DEFLATE\",\"PREDICTOR=2\",\"ZLEVEL=9\"])\n",
        "  if compress == False: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32)\n",
        "  driver.GetRasterBand(1).WriteArray(input_array)\n",
        "  driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "  driver.SetGeoTransform(template_dimensions)\n",
        "  driver.SetProjection(template_projection)\n",
        "\n",
        "# Global function: burn a polygon to raster\n",
        "# Burn a polygon to raster\n",
        "def burn_polygon_to_raster(raster, polygon, fixed=True, fixed_value=1, column_name=None, all_touched=True):\n",
        "  with rasterio.open(raster, 'r+') as src:\n",
        "      array = src.read(1)\n",
        "      transform = src.transform\n",
        "      gdf = gpd.read_file(polygon)\n",
        "      for geom in gdf.geometry:\n",
        "          if not fixed and column_name == None:\n",
        "              column_name = gdf.columns[0]\n",
        "          if not fixed: burn_value = gdf.loc[gdf.geometry == geom, column_name].values[0]\n",
        "          else: burn_value = fixed_value\n",
        "          rasterize([(geom, burn_value)], out=array, transform=transform,\n",
        "              all_touched=all_touched, dtype=src.meta['dtype'], out_shape=src.shape)\n",
        "      src.write(array, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGPPPXBnyWxW"
      },
      "source": [
        "# Download country polygons (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fhtr2Uxx8Wn"
      },
      "outputs": [],
      "source": [
        "# The framework is best applied at the landscape level.\n",
        "# Small countries (<30,000 km2 in rectangular extent) provide good test cases.\n",
        "# Download countries from https://gist.github.com/DanielJWood/b71237cc200831acf8e637c05ce2c375\n",
        "countries_url = 'https://naturalearth.s3.amazonaws.com/10m_cultural/ne_10m_admin_0_countries.zip'\n",
        "countries_file_path = join(countries_dir, 'countries.zip')\n",
        "if not exists(countries_file_path):\n",
        "  request = requests.get(countries_url, allow_redirects=True)\n",
        "  open(countries_file_path, 'wb').write(request.content)\n",
        "\n",
        "countries_df = gpd.read_file(countries_file_path)\n",
        "\n",
        "# Print the available country names\n",
        "print(countries_df['SOVEREIGNT'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM7RmPMoyiVM"
      },
      "outputs": [],
      "source": [
        "# Creates a box around all selected countries for the 'project area'.\n",
        "# List of countries\n",
        "countries = [\n",
        "    'Dominica',\n",
        "    ]\n",
        "\n",
        "project_area_path = join(polygons_dir, 'project_area.gpkg')\n",
        "if not exists(project_area_path):\n",
        "  # Filter the data for the desired countries\n",
        "  selected_countries = countries_df[countries_df['SOVEREIGNT'].isin(countries)]\n",
        "  # Get the bounding box coordinates of the selected countries\n",
        "  minx, miny, maxx, maxy = selected_countries.total_bounds\n",
        "  # Create a bounding box as a GeoDataFrame\n",
        "  countries_bounding_box = gpd.GeoDataFrame(geometry=[box(minx, miny, maxx, maxy)], crs=\"EPSG:4326\")\n",
        "  # Export the result as a project area\n",
        "  countries_bounding_box.to_file(project_area_path, driver='GPKG', crs=f\"EPSG:{crs_epsg}\")\n",
        "  print(\"Project area has been created.\")\n",
        "else: print(\"Project area exists. Delete this first, then retry.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuNPGIEE2BI4"
      },
      "source": [
        "# Project area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xIGIHOL2DSq"
      },
      "outputs": [],
      "source": [
        "# If no country polygons downloaded, manually upload 'project_area.gpkg' polygon to the 1_areas/polygons directory.\n",
        "# This can be a polygon of any shape. A bounding box will be used to create the GEDI download area in 1_variates.ipynb.\n",
        "# A buffered bounding box will be used for the template, to ensure all predictor edge effects are included.\n",
        "\n",
        "#Project CRS EPSG\n",
        "crs_epsg = 4326\n",
        "\n",
        "# Recommended to buffer at least 300 m to account for edge effects and clipping imprecision\n",
        "buffer_distance_metres = 300\n",
        "\n",
        "project_area_path = join(polygons_dir, 'project_area.gpkg')\n",
        "\n",
        "if exists(project_area_path):\n",
        "  print(\"Project polygon found:\\n\")\n",
        "  # Read project polygon\n",
        "  project_area_read = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "  display(project_area_read[\"geometry\"].iloc[0])\n",
        "  if project_area_read.crs.to_epsg() == crs_epsg:\n",
        "    project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "    # Calculate the bounding box of the project polygon\n",
        "    if not exists (project_area_buffered_bbox_path):\n",
        "      # Suppress warning about not being a geographic CRS, as we account for this.\n",
        "      # However larger buffers or project areas near the poles might still need to be converted.\n",
        "      warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "      # Get the centroid of the project polygon\n",
        "      project_polygon_centroid = project_area_read.centroid.values[0]\n",
        "      # Convert the buffer distance from meters to decimal degrees based on the location at the centroid\n",
        "      buffer_distance_degrees = buffer_distance_metres / (111320 * abs(math.cos(math.radians(project_polygon_centroid.y))))\n",
        "      # Buffer the polygon\n",
        "      project_area_buffered = project_area_read.buffer(buffer_distance_degrees)\n",
        "      # Create a bounding box polygon and save\n",
        "      project_area_buffered_bbox = box(*project_area_buffered.total_bounds)\n",
        "      gdf = gpd.GeoDataFrame(geometry=[project_area_buffered_bbox], crs=f\"EPSG:{crs_epsg}\")\n",
        "      gdf.to_file(project_area_buffered_bbox_path, driver='GPKG')\n",
        "      print(f\"Buffered the project area to {buffer_distance_metres} and created a bounding box: {project_area_buffered_bbox_path}\")\n",
        "    else: print(f\"Project area has already been buffered and bound to a box: {project_area_buffered_bbox_path}\")\n",
        "    # Read the buffered project area bounding box\n",
        "    project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "    bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "    project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "    project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "    print(f\"\\nThe buffered polygon bounding box has the coordinates:\\n{project_x_min}, {project_y_min} to {project_x_max}, {project_y_max}.\")\n",
        "  else: print(\"Reproject 'project_area.gpkg' to EPSG:4326.\")\n",
        "else: print(\"Create 'project_area.gpkg' and upload to 1_areas/polygons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq2a_lWnP08i"
      },
      "source": [
        "# Download DEM tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjrScY7cLm-S"
      },
      "outputs": [],
      "source": [
        "# Download Copernicus DEM tiles for the project area. Currently the most recent is COP-DEM_GLO-30-DGED__2023_1\n",
        "# press release > https://sentinels.copernicus.eu/web/sentinel/-/copernicus-dem-new-direct-data-download-access\n",
        "# Guide > https://spacedata.copernicus.eu/documents/20123/121286/Copernicus+DEM+Open+HTTPS+Access.pdf\n",
        "# List of dataset tiles > https://prism-dem-open.copernicus.eu/pd-desk-open-access/publicDemURLs/COP-DEM_GLO-30-DGED__2023_1\n",
        "\n",
        "dem_tiles_url_txt_path = join(dem_dir, \"dem_tiles_url.txt\")\n",
        "dem_tiles_url_list = []\n",
        "\n",
        "# If the list of DEM tiles exists as a .txt then open, otherwise download and save.\n",
        "try:\n",
        "  with open(dem_tiles_url_txt_path, 'r') as dem_tiles_url_txt_file:\n",
        "    for url in dem_tiles_url_txt_file:\n",
        "        dem_tiles_url_list.append(url[:-1]) # Remove new line\n",
        "  print(\"DEM tile URL dowload list exists as 'dem_tiles_url.txt' in '1_areas/dem'.\")\n",
        "except:\n",
        "  # Get html content to search for DEM tile download URLS\n",
        "  html = 'https://prism-dem-open.copernicus.eu/pd-desk-open-access/publicDemURLs/COP-DEM_GLO-30-DGED__2023_1'\n",
        "  response = requests.get(html)\n",
        "  response.raise_for_status()\n",
        "  html_content = response.text\n",
        "  # Create list of DEM tile download URLs\n",
        "  url_prefix, url_suffix = '<nativeDemUrl>', '</nativeDemUrl>'\n",
        "  for i in range(1, html_content.count(url_prefix)+1):\n",
        "    tile_url = html_content.split(url_prefix)[i].split(url_suffix)[0]\n",
        "    if 'DSM_10' in tile_url: dem_tiles_url_list.append(tile_url) # avoid DSM_30\n",
        "  # Save the DEM tiles URL list as a .txt file\n",
        "  with open(dem_tiles_url_txt_path, 'w') as dem_tiles_url_txt_file:\n",
        "    for url in dem_tiles_url_list:\n",
        "      dem_tiles_url_txt_file.write(url + \"\\n\")\n",
        "  print(\"DEM tile URL download list saved to 'all_dem_tiles.txt' in '1_areas/dem'.\")\n",
        "\n",
        "# Read the buffered project area bounding box\n",
        "project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "\n",
        "# Filter URL list to tiles overlapped by the project polygon bounding box\n",
        "dem_tiles_url_list_filtered = []\n",
        "\n",
        "for url in dem_tiles_url_list:\n",
        "  # Degree coordinates of DEM tile\n",
        "  degree_coordinates = url[-18:-4]\n",
        "\n",
        "  # Set number of degrees per tile (assuming square)\n",
        "  tile_size = 1\n",
        "\n",
        "  # Extract degree coordinate values\n",
        "  tile_x_dir, tile_x_deg, tile_x_minutes = degree_coordinates[7:8], int(degree_coordinates[8:11]), int(degree_coordinates[12:14])\n",
        "  tile_y_dir, tile_y_deg, tile_y_minutes = degree_coordinates[0][0], int(degree_coordinates[1:3]), int(degree_coordinates[4:6])\n",
        "\n",
        "  # Convert to decimal degree coordinates\n",
        "  if tile_x_dir == 'E':\n",
        "    tile_x_min = tile_x_deg + (tile_x_minutes / 60.0)\n",
        "    tile_x_max = tile_x_min + tile_size\n",
        "  if tile_x_dir == 'W':\n",
        "    tile_x_min = 0 - tile_x_deg - (tile_x_minutes / 60.0)\n",
        "    tile_x_max = tile_x_min + tile_size\n",
        "  if tile_y_dir == 'N':\n",
        "    tile_y_min = tile_y_deg + (tile_y_minutes / 60.0)\n",
        "    tile_y_max = tile_y_min + tile_size\n",
        "  if tile_y_dir == 'S':\n",
        "    tile_y_min = 0 - tile_y_deg - (tile_y_minutes / 60.0)\n",
        "    tile_y_max = tile_y_min + tile_size\n",
        "\n",
        "  # Check whether project bounding box is inside the tile\n",
        "  lon_check = project_x_max > tile_x_min and project_x_min < tile_x_max\n",
        "  lat_check = project_y_max > tile_y_min and project_y_min < tile_y_max\n",
        "  if lon_check and lat_check:\n",
        "    dem_tiles_url_list_filtered.append(url)\n",
        "\n",
        "print(\"DEM tile URL list filtered to project_area_buffered_bbox.gpkg.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MzMbHy3KmLA"
      },
      "outputs": [],
      "source": [
        "# Display progress\n",
        "index = 0\n",
        "progress_label = widgets.Label(value=f\"DEM tile download progress: {index}/{len(dem_tiles_url_list_filtered)}\")\n",
        "display(progress_label)\n",
        "\n",
        "# Process URLs\n",
        "for url in dem_tiles_url_list_filtered:\n",
        "    url = url.strip()  # Remove any white space\n",
        "    dem_tile_zip_filename = url.split('/')[-1]\n",
        "    dem_tile_zip_path = join(dem_tiles_dir, dem_tile_zip_filename)\n",
        "    while True:\n",
        "        try:\n",
        "            if not exists(dem_tile_zip_path):\n",
        "                request = requests.get(url, allow_redirects=True)\n",
        "                open(dem_tile_zip_path, 'wb').write(request.content)\n",
        "            with tarfile.open(dem_tile_zip_path, 'r') as tar:\n",
        "                tar.getmembers()  # Check if tarball is valid\n",
        "            break  # Exit loop if successful\n",
        "        except Exception as e:\n",
        "            if exists(dem_tile_zip_path):\n",
        "                remove(dem_tile_zip_path)  # Delete file if invalid\n",
        "            print(f\"Failed URL: {url} - {e}\")\n",
        "    # Update progress\n",
        "    index += 1\n",
        "    progress_label.value = f\"DEM tile download progress: {index}/{len(dem_tiles_url_list_filtered)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9TuMSdehVVK"
      },
      "source": [
        "# Process DEM tiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke7mOK4TfSd-"
      },
      "outputs": [],
      "source": [
        "# Display progress\n",
        "index = 0\n",
        "progress_label = widgets.Label(value=f\"DEM tile extraction progress: {index}/{len(dem_tiles_url_list_filtered)}\")\n",
        "display(progress_label)\n",
        "\n",
        "# Extract tile 'DEM.tif' into the DEM tiles directory if it doesn't already exist.\n",
        "for file in os.listdir(dem_tiles_dir):\n",
        "  if file.endswith(\".tar\"):\n",
        "    dem_tile_filename = f\"{file[:-4]}_DEM.tif\"\n",
        "    dem_tile_path = join(dem_tiles_dir, dem_tile_filename)\n",
        "    if not exists(dem_tile_path):\n",
        "      tar_path = join(dem_tiles_dir, file)\n",
        "      tar_file = tarfile.open(tar_path, 'r')\n",
        "      for member in tar_file.getmembers():\n",
        "        if dem_tile_filename in member.name:\n",
        "          member.name = os.path.basename(member.name)\n",
        "          tar_file.extract(member, dem_tiles_dir)\n",
        "    index += 1\n",
        "    progress_label.value = f\"DEM tile extraction progress: {index}/{len(dem_tiles_url_list_filtered)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyTQqNr_27Fw"
      },
      "outputs": [],
      "source": [
        "# Merge the DEM tiles into a single raster\n",
        "dem_merged_path = join(dem_dir, \"dem_merged.tif\")\n",
        "\n",
        "if not exists(dem_merged_path):\n",
        "  # List tiles\n",
        "  tiles_to_merge = []\n",
        "  for file in os.listdir(dem_tiles_dir):\n",
        "    if file.endswith(\".tif\"):\n",
        "      tiles_to_merge.append(join(dem_tiles_dir, file))\n",
        "  # Create a temporary virtual file (VRT) from the tiles\n",
        "  temp_vrt = join(dem_dir, 'temp.vrt')\n",
        "  gdal.BuildVRT(temp_vrt, tiles_to_merge)\n",
        "  # Merge the input files into a single GeoTIFF file\n",
        "  merge_options = gdal.TranslateOptions(format='GTiff', outputType=gdal.GDT_Float32, noData=nodatavalue,\n",
        "                                  creationOptions=['COMPRESS=DEFLATE', 'PREDICTOR=2', 'ZLEVEL=9'])\n",
        "  gdal.Translate(dem_merged_path, temp_vrt, options=merge_options)\n",
        "  # Remove the temporary VRT file\n",
        "  os.remove(temp_vrt)\n",
        "  print(f\"The merged DEM raster has been saved to: {dem_merged_path}\")\n",
        "else: print(f\"A merged DEM raster already exists at: {dem_merged_path}\")\n",
        "\n",
        "# Clip the raster to project area extent\n",
        "dem_merged_clipped_path = join(dem_dir, \"dem_merged_clipped.tif\")\n",
        "\n",
        "if not exists(dem_merged_clipped_path):\n",
        "  # Read the buffered project area bounding box\n",
        "  project_area_buffered_bbox_path = join(polygons_dir, 'project_area_buffered_bbox.gpkg')\n",
        "  project_area_buffered_bbox_read = gpd.read_file(project_area_buffered_bbox_path)\n",
        "  bbox_bounds = project_area_buffered_bbox_read.total_bounds\n",
        "  # Get coordinates\n",
        "  project_x_min, project_x_max = bbox_bounds[0], bbox_bounds[2]\n",
        "  project_y_min, project_y_max = bbox_bounds[1], bbox_bounds[3]\n",
        "  project_coords = [project_x_min, project_y_max, project_x_max, project_y_min]\n",
        "  # Define Translate options\n",
        "  clip_options = gdal.TranslateOptions(projWin=[project_x_min, project_y_max, project_x_max, project_y_min],\n",
        "                                  outputType=gdal.GDT_Float32, noData=nodatavalue)\n",
        "  # call gdal.Translate() with the new options argument\n",
        "  gdal.Translate(dem_merged_clipped_path, dem_merged_path, options=clip_options)\n",
        "  print(f\"The clipped, merged DEM raster has been saved to: {dem_merged_clipped_path}\")\n",
        "else: print(f\"A clipped merged DEM raster already exists at: {dem_merged_clipped_path}\")\n",
        "\n",
        "# Copy the clipped, merged DEM to '3_predictors' directory to use as the base DEM\n",
        "base_dem_path = join(areas_dir, \"base_dem.tif\")\n",
        "\n",
        "if not exists(base_dem_path):\n",
        "  copy(dem_merged_clipped_path, base_dem_path)\n",
        "  print(f\"The clipped, merged DEM has been copied for use as a base DEM: {base_dem_path}\")\n",
        "else: print(f\"A base DEM already exists at: {base_dem_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwICylX1t4mZ"
      },
      "source": [
        "# Create template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys_zk5eHpPkd"
      },
      "outputs": [],
      "source": [
        "# Create template from DEM\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "if not exists(template_tif_path):\n",
        "  dem_merged_clipped_path = join(dem_dir, \"dem_merged_clipped.tif\")\n",
        "  dem_merged_clipped_array = gdal.Open(dem_merged_clipped_path).ReadAsArray() # Convert DEM to array\n",
        "  template_array = np.ones_like(dem_merged_clipped_array) # Change all values to 1\n",
        "  export_array_as_tif(template_array, template_tif_path, template=dem_merged_clipped_path, compress=False)\n",
        "  print(f\"A template raster has been created: {template_tif_path}\")\n",
        "else: print(f\"A template raster already exists at: {template_tif_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDHujjIH7Ftq"
      },
      "outputs": [],
      "source": [
        "# Create template polygon\n",
        "template_polygon_path = join(polygons_dir, \"template.gpkg\")\n",
        "if not exists(template_polygon_path):\n",
        "  # Get template raster spatial data\n",
        "  template_raster = gdal.Open(template_tif_path)\n",
        "  template_raster_band = template_raster.GetRasterBand(1)\n",
        "  spatial_ref = ogr.osr.SpatialReference()\n",
        "  spatial_ref.ImportFromWkt(template_raster.GetProjection())\n",
        "  # Polygonize template raster without fields or layer name\n",
        "  template_polygon_file = ogr.GetDriverByName(\"GPKG\").CreateDataSource(template_polygon_path)\n",
        "  template_polygon_layer = template_polygon_file.CreateLayer(\"\", srs=spatial_ref, geom_type=ogr.wkbPolygon)\n",
        "  gdal.Polygonize(template_raster_band, None, template_polygon_layer, -1)\n",
        "  print(f\"A template polygon has been created: {template_polygon_path}\")\n",
        "else: print(f\"A template polygon already exists at: {template_polygon_path}\")\n",
        "template_polygon_read = gpd.read_file(template_polygon_path)\n",
        "template_polygon_bounds = template_polygon_read.total_bounds\n",
        "print(f\"\\nThe template polygon has the coordinates:\\n{template_polygon_bounds[0]}, {template_polygon_bounds[1]} to {template_polygon_bounds[2]}, {template_polygon_bounds[3]}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c367RQcutCrA"
      },
      "source": [
        "# Create measurement rasters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbZ03-E1vrfA"
      },
      "outputs": [],
      "source": [
        "# Create measurement rasters for predictors and precise summing of pixels\n",
        "\n",
        "# Define template\n",
        "template_path = join(areas_dir, \"template.tif\")\n",
        "template = gdal.Open(template_path)\n",
        "template_array = template.ReadAsArray()\n",
        "rows, cols = template_array.shape\n",
        "\n",
        "# Define Earth radius\n",
        "equatorial_radius = 6_378_137.0 # Equatorial radius in metres\n",
        "polar_radius = 6_356_752.0 # Polar radius in metres\n",
        "\n",
        "# Function for obtaining latitude distance in meters from decimal degrees, at a specific latitude\n",
        "def distance_of_decimal_degrees_latitude(latitude: float, decimal_degrees: float) -> float:\n",
        "    # Calculate the eccentricity squared (e2)\n",
        "    e2 = (equatorial_radius**2 - polar_radius**2) / equatorial_radius**2\n",
        "    # Convert latitude to radians\n",
        "    latitude_rad = math.radians(latitude)\n",
        "    # Calculate the meridional radius of curvature (M)\n",
        "    M = equatorial_radius * (1 - e2) / (1 - e2 * math.sin(latitude_rad)**2)**(3/2)\n",
        "    # Calculate the distance of one degree of latitude\n",
        "    distance_per_degree = math.pi * M / 180\n",
        "    # Calculate the distance of the specified decimal degrees\n",
        "    distance_latitude = distance_per_degree * decimal_degrees\n",
        "    return distance_latitude\n",
        "\n",
        "# Function for obtaining longitude distance in meters from decimal degrees, at a specific latitude\n",
        "def distance_of_decimal_degrees_longitude(latitude: float, decimal_degrees: float) -> float:\n",
        "    # Convert latitude to radians\n",
        "    latitude_rad = math.radians(latitude)\n",
        "    # Calculate the distance of one degree of longitude at the given latitude\n",
        "    distance_per_degree = (math.pi * equatorial_radius * math.cos(latitude_rad)) / 180\n",
        "    # Calculate the distance of the specified decimal degrees\n",
        "    distance_longitude = distance_per_degree * decimal_degrees\n",
        "    return distance_longitude\n",
        "\n",
        "geotransform = template.GetGeoTransform()\n",
        "\n",
        "# Create a raster for the longitude in decimal degrees at the center of each pixel\n",
        "longitude_path = join(areas_dir, \"longitude.tif\")\n",
        "if not exists(longitude_path):\n",
        "  longitude_array = np.array([[geotransform[0] + (c * geotransform[1]) + (r * geotransform[4]) + (geotransform[1] / 2) for c in range(cols)] for r in range(rows)])\n",
        "  export_array_as_tif(longitude_array, longitude_path)\n",
        "  print(f\"Raster with cell longitude in decimal degrees created: {longitude_path}\")\n",
        "else: print(f\"Raster with cell longitude in decimal degrees already exists: {longitude_path}\")\n",
        "\n",
        "# Create a raster for the latitude in decimal degrees at the center of each pixel\n",
        "latitude_path = join(areas_dir, \"latitude.tif\")\n",
        "if not exists(latitude_path):\n",
        "  latitude_array = np.array([[geotransform[3] + (r * geotransform[5]) + (c * geotransform[2]) + (geotransform[5] / 2) for c in range(cols)] for r in range(rows)])\n",
        "  export_array_as_tif(latitude_array, latitude_path)\n",
        "  print(f\"Raster with cell latitude in decimal degrees created: {latitude_path}\")\n",
        "else: print(f\"Raster with cell latitude in decimal degrees already exists: {latitude_path}\")\n",
        "latitude_array = gdal.Open(latitude_path).ReadAsArray()\n",
        "\n",
        "# Create a raster for the cell width in meters\n",
        "cell_size_x_path = join(areas_dir, \"cell_size_x.tif\")\n",
        "if not exists(cell_size_x_path):\n",
        "  cell_size_x_array = np.vectorize(distance_of_decimal_degrees_longitude)(latitude_array, geotransform[1])\n",
        "  export_array_as_tif(cell_size_x_array, cell_size_x_path)\n",
        "  print(f\"Raster with cell width in metres created: {cell_size_x_path}\")\n",
        "else: print(f\"Raster with cell width in metres already exists: {cell_size_x_path}\")\n",
        "\n",
        "# Create a raster for the cell height in meters\n",
        "cell_size_y_path = join(areas_dir, \"cell_size_y.tif\")\n",
        "if not exists(cell_size_y_path):\n",
        "  cell_size_y_array = np.vectorize(distance_of_decimal_degrees_latitude)(latitude_array, abs(geotransform[5]))\n",
        "  export_array_as_tif(cell_size_y_array, cell_size_y_path)\n",
        "  print(f\"Raster with cell height in metres created: {cell_size_y_path}\")\n",
        "else: print(f\"Raster with cell height in metres already exists: {cell_size_y_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn-q2xLuSpzp"
      },
      "source": [
        "# Create project area mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk5JrWmwSx4Z"
      },
      "outputs": [],
      "source": [
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "project_mask_path = join(masks_dir, 'project_mask.tif')\n",
        "project_area_polygon_path = join(polygons_dir, 'project_area.gpkg')\n",
        "\n",
        "if exists(project_area_polygon_path):\n",
        "  print(f\"Project area polygon found: {project_area_polygon_path}\\n\")\n",
        "  if not exists(project_mask_path):\n",
        "    # Convert all template values to 'nodata'\n",
        "    template_tif = gdal.Open(template_tif_path)\n",
        "    template_tif_nodatavalue = template_tif.GetRasterBand(1).GetNoDataValue()\n",
        "    template_mask_array = gdal.Open(template_tif_path).ReadAsArray()\n",
        "    template_mask_array[template_mask_array != None] = template_tif_nodatavalue\n",
        "    export_array_as_tif(template_mask_array, project_mask_path)\n",
        "    # Burn the value '1' where it overlaps with the project area polygon\n",
        "    burn_polygon_to_raster(project_mask_path, project_area_polygon_path, fixed=True, fixed_value=1)\n",
        "    print(f\"Project mask has been created: {project_mask_path}\")\n",
        "  else: print(f\"Project mask already exists: {project_mask_path}\")\n",
        "else: print(f\"Project polygon not found. Place 'project_area.gpkg' in: {polygons_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji7TJuuQkG39"
      },
      "source": [
        "# Create additional masks (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psIxZnBffGkS"
      },
      "outputs": [],
      "source": [
        "# Collect available polygons\n",
        "polygon_list = []\n",
        "for polygon in os.listdir(polygons_dir):\n",
        "  if polygon not in [\"project_area_buffered_bbox.gpkg\",\"template.gpkg\",\"project_area.gpkg\",\"project_area_inverse.gpkg\"]:\n",
        "    polygon_list.append(polygon)\n",
        "\n",
        "# Select scenarios to predict\n",
        "print(\"additional_masks = [\")\n",
        "for polygon in sorted(polygon_list):\n",
        "  print(f'  \"{polygon[:-5]}\",')\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVCJvE-NgCpU"
      },
      "outputs": [],
      "source": [
        "additional_masks = [\n",
        "  \"\",\n",
        "]\n",
        "\n",
        "# If fixed is True, choose a fixed value.\n",
        "fixed = True\n",
        "fixed_value = 1\n",
        "# If fixed is False, choose the polygon column to draw values from.\n",
        "column_name = 'test_column'\n",
        "# Toggle whether all touched pixels are burned, or only those with a centre inside the polygon\n",
        "all_touched=True\n",
        "\n",
        "# Use the template.tif as a base, and convert all template values to 'nodata'\n",
        "template_tif = gdal.Open(template_tif_path)\n",
        "template_tif_nodatavalue = template_tif.GetRasterBand(1).GetNoDataValue()\n",
        "template_mask_array = gdal.Open(template_tif_path).ReadAsArray()\n",
        "template_mask_array[template_mask_array != None] = template_tif_nodatavalue\n",
        "\n",
        "# Loop through selected masks\n",
        "for mask in additional_masks:\n",
        "  mask_tif_path = join(masks_dir, f\"{mask}.tif\")\n",
        "  mask_polygon_path = join(polygons_dir, f\"{mask}.gpkg\")\n",
        "  if not exists(mask_tif_path):\n",
        "    export_array_as_tif(template_mask_array, mask_tif_path)\n",
        "    # Burn the chosen values with the mask polygon\n",
        "    burn_polygon_to_raster(mask_tif_path, mask_polygon_path,\n",
        "                           fixed=fixed, fixed_value=fixed_value,\n",
        "                           column_name=column_name, all_touched=all_touched)\n",
        "    print(f\"The mask for {mask}.gpkg has been created: {mask_tif_path}\")\n",
        "  else: print(f\"The mask for {mask}.gpkg already exists: {mask_tif_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_RENY6twBXx"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h__20O9kwA9K"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "TGPPPXBnyWxW",
        "J9TuMSdehVVK",
        "NwICylX1t4mZ",
        "c367RQcutCrA",
        "ji7TJuuQkG39"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}