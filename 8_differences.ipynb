{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/dev/8_differences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ8jLRKRSfgb"
      },
      "source": [
        "# Imports, directories and global functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkvV803eSUQY"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "# Use '/content/drive/MyDrive/' for a personal drive\n",
        "# Use '/gdrive/Shareddrives/' for a shared drive (must be created first)\n",
        "\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "# base_dir = '/content/drive/MyDrive/masfi'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "if base_dir.startswith('/gdrive/Shareddrives/'):\n",
        "  drive.mount('/gdrive', force_remount=True)\n",
        "elif base_dir.startswith('/content/drive/MyDrive/'):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "else: print(\"Create a base_dir beginning with '/gdrive/Shareddrives/' or '/content/drive/MyDrive/'.\")\n",
        "\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEpdIjOwSiB1"
      },
      "outputs": [],
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs and upgrades\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!apt-get install -y gdal-bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQDSsvGeSi4u"
      },
      "outputs": [],
      "source": [
        "# Reload imports, replacing those in the cache\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "# Imports\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "from os import makedirs\n",
        "from os.path import join, exists\n",
        "from osgeo import gdal, ogr\n",
        "gdal.UseExceptions()\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.features import rasterize\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxxgT3K1Sjum"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "areas_dir = join(base_dir, \"1_areas\")\n",
        "polygons_dir = join(areas_dir, \"polygons\")\n",
        "scenarios_dir = join(base_dir, \"6_scenarios\")\n",
        "masks_dir = join(scenarios_dir, \"scenario_masks\")\n",
        "uncertainty_dir = join(base_dir, \"7_uncertainty\")\n",
        "differences_dir = join(base_dir, \"8_differences\")\n",
        "\n",
        "# Create directories\n",
        "makedirs(differences_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96FAfeyooMLz"
      },
      "outputs": [],
      "source": [
        "# Global function: export an array as a .tif\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "nodatavalue = -1111111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_tif_path, nodatavalue=nodatavalue, compress=compress, dtype=gdal.GDT_Float32):\n",
        "    template_ds = gdal.Open(template)\n",
        "    template_band = template_ds.GetRasterBand(1)\n",
        "    template_dimensions, template_projection = template_ds.GetGeoTransform(), template_ds.GetProjection()\n",
        "    if compress: options = [\"COMPRESS=DEFLATE\", \"PREDICTOR=3\", \"ZLEVEL=9\"]\n",
        "    else: options = []\n",
        "    driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, 1, dtype, options=options)\n",
        "    driver.GetRasterBand(1).WriteArray(input_array)\n",
        "    driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "    driver.SetGeoTransform(template_dimensions)\n",
        "    driver.SetProjection(template_projection)\n",
        "    template_ds = driver = None\n",
        "\n",
        "# Global function: burn a polygon to raster\n",
        "def burn_polygon_to_raster(raster_path, polygon_path, fixed=True, fixed_value=1, column_name=None, all_touched=True):\n",
        "    raster = vector = None\n",
        "    try:\n",
        "        raster = gdal.Open(raster_path, gdal.GA_Update)\n",
        "        vector = ogr.Open(polygon_path)\n",
        "        if not raster or not vector:\n",
        "            raise ValueError(\"Cannot open input files\")\n",
        "        layer = vector.GetLayer()\n",
        "        options = [\"ALL_TOUCHED=TRUE\"] if all_touched else []\n",
        "        if fixed:\n",
        "            gdal.RasterizeLayer(raster, [1], layer, burn_values=[fixed_value], options=options)\n",
        "        else:\n",
        "            attr_name = column_name or layer.GetLayerDefn().GetFieldDefn(0).GetName()\n",
        "            options.append(f\"ATTRIBUTE={attr_name}\")\n",
        "            gdal.RasterizeLayer(raster, [1], layer, options=options)\n",
        "    finally:\n",
        "        if raster: raster.FlushCache()\n",
        "        raster = vector = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_OkHaUkTCyB"
      },
      "source": [
        "# Select source and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mB0XrPNYU_I"
      },
      "outputs": [],
      "source": [
        "# Select if to source predictions from scenarios_dir or uncertainty_dir\n",
        "# If available, uncertainty_dir should be selected so that uncertainty can\n",
        "# be propagated and scenario 'mean' iteration values used.\n",
        "\n",
        "# source_dir = uncertainty_dir\n",
        "source_dir = scenarios_dir\n",
        "\n",
        "print(f\"{source_dir.split('/')[-1]} has been selected as the source directory for predictions\")\n",
        "print(\"to calculate disturbance and intactness.\\n\")\n",
        "\n",
        "# If uncertainty selected, check it exists\n",
        "if not exists(uncertainty_dir) and source_dir == uncertainty_dir:\n",
        "  print(\"The uncertainty directory does not yet exist. Defaulting to scenarios directory.\")\n",
        "  source_dir = scenarios_dir\n",
        "\n",
        "source_dir_name = f\"{source_dir.split('_')[-1]}_dir\"\n",
        "\n",
        "# Select the model\n",
        "for subdir in os.listdir(source_dir):\n",
        "  if 'scenario_masks' not in subdir:\n",
        "    print(f\"selected_model = '{subdir}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbXY6iP_qjYc"
      },
      "outputs": [],
      "source": [
        "selected_model = 'agbd_tekai_250625_003858'\n",
        "\n",
        "selected_model_dir = join(source_dir, selected_model)\n",
        "if source_dir == scenarios_dir: predictions_dir = join(selected_model_dir, 'scenario_predictions')\n",
        "if source_dir == uncertainty_dir: predictions_dir = join(selected_model_dir, 'uncertainty_predictions')\n",
        "\n",
        "# Check predictions exist to calculate differences\n",
        "if len(os.listdir(predictions_dir)) < 2: print(f\"At least 2 predictions must exist in {source_dir} to calculate differences.\")\n",
        "else:\n",
        "  model_differences_dir = join(differences_dir, f\"{selected_model}_{source_dir_name}\")\n",
        "  disturbance_dir = join(model_differences_dir, 'disturbance')\n",
        "  intactness_dir = join(model_differences_dir, 'intactness')\n",
        "  makedirs(model_differences_dir, exist_ok=True)\n",
        "  makedirs(disturbance_dir, exist_ok=True)\n",
        "  makedirs(intactness_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECHaTfrs0n7i"
      },
      "source": [
        "# Disturbance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disturbance is measured as absolute AGBD loss\n",
        "# This block builds dictionaries of disturbance options based on available files\n",
        "\n",
        "# Extract all available scenarios from scenarios predictions directory\n",
        "if source_dir == scenarios_dir:\n",
        "  scenarios = set()\n",
        "  for file in os.listdir(predictions_dir):\n",
        "      scenarios.add(file.split(\"__\")[0])\n",
        "\n",
        "# OR Extract all available scenarios from uncertainty predictions directory\n",
        "if source_dir == uncertainty_dir:\n",
        "  prediction_stats = {}\n",
        "  for file in os.listdir(predictions_dir):\n",
        "      parts = file.split(\"__\")\n",
        "      if len(parts) >= 2:\n",
        "          stat, scenario = parts[0], parts[1]\n",
        "          if scenario not in prediction_stats:\n",
        "              prediction_stats[scenario] = set()\n",
        "          prediction_stats[scenario].add(stat)\n",
        "  # Only keep scenarios that have both 'uncertainty' and 'mean' prediction stats\n",
        "  scenarios = {prediction for prediction, stats in prediction_stats.items()\n",
        "              if 'uncertainty' in stats and 'mean' in stats}\n",
        "\n",
        "# Categorise years from scenarios\n",
        "years = set()\n",
        "plain_years = set()\n",
        "oldgrowth_years = set()\n",
        "oldgrowth_all_land_years = set()\n",
        "\n",
        "for s in scenarios:\n",
        "    if s.isdigit():\n",
        "        years.add(int(s))\n",
        "        plain_years.add(int(s))\n",
        "    elif \"_oldgrowth_all_land\" in s:\n",
        "        year = s.split(\"_oldgrowth_all_land\")[0]\n",
        "        if year.isdigit():\n",
        "            years.add(int(year))\n",
        "            oldgrowth_all_land_years.add(int(year))\n",
        "    elif \"_oldgrowth\" in s:\n",
        "        year = s.split(\"_oldgrowth\")[0]\n",
        "        if year.isdigit():\n",
        "            years.add(int(year))\n",
        "            oldgrowth_years.add(int(year))\n",
        "    elif any(pattern in s for pattern in [\"_no_disturbance_since_\", \"_no_degradation_since_\"]):\n",
        "        year = s.split(\"_\")[0]\n",
        "        if year.isdigit():\n",
        "            years.add(int(year))\n",
        "        if \"_since_\" in s:\n",
        "            since_year = s.split(\"_since_\")[1]\n",
        "            if since_year.isdigit():\n",
        "                years.add(int(since_year) - 1)\n",
        "\n",
        "years_sorted = sorted(list(years))\n",
        "\n",
        "# Output dictionaries\n",
        "disturbance_since = {}\n",
        "degradation_since_dictionary = {}\n",
        "deforestation_since_dictionary = {}\n",
        "before_dictionary = {}\n",
        "\n",
        "print(\"disturbance_since_dictionary = {\")\n",
        "print(\"\")\n",
        "\n",
        "# 1. Process disturbance_since scenarios\n",
        "for year_a in sorted(years_sorted):\n",
        "    a_str = str(year_a)\n",
        "    for year_b in sorted(years_sorted):\n",
        "        if year_a <= year_b:\n",
        "            continue\n",
        "        b_str, b_plus1 = str(year_b), str(year_b + 1)\n",
        "\n",
        "        if year_a in plain_years and f\"{a_str}_no_disturbance_since_{b_plus1}\" in scenarios:\n",
        "            print(f\"# Disturbance in {a_str} caused by events since {b_plus1}\")\n",
        "            print(f\"  ('{a_str}', '{a_str}_no_disturbance_since_{b_plus1}'):\")\n",
        "            print(f\"    '{a_str}_disturbance_since_{b_plus1}',\")\n",
        "            print(\"\")\n",
        "            disturbance_since[(a_str, f\"{a_str}_no_disturbance_since_{b_plus1}\")] = f\"{a_str}_disturbance_since_{b_plus1}\"\n",
        "\n",
        "# Process disturbance_since_oldgrowth scenarios\n",
        "oldgrowth_printed = False\n",
        "for year in years_sorted:\n",
        "    y_str = str(year)\n",
        "    if (year in plain_years and year in oldgrowth_all_land_years and f\"{y_str}_oldgrowth_all_land\" in scenarios):\n",
        "        if not oldgrowth_printed:\n",
        "            print(f\"# Disturbance in {y_str} caused by events since an oldgrowth state.\")\n",
        "            oldgrowth_printed = True\n",
        "        print(f\"  ('{y_str}', '{y_str}_oldgrowth_all_land'):\")\n",
        "        print(f\"    '{y_str}_disturbance_since_oldgrowth',\")\n",
        "        print(\"\")\n",
        "        disturbance_since[(y_str, f\"{y_str}_oldgrowth_all_land\")] = f\"{y_str}_disturbance_since_oldgrowth\"\n",
        "\n",
        "print(\"}\\n\")\n",
        "\n",
        "# 2. Degradation since dictionary\n",
        "print(\"degradation_since_dictionary = {\\n\")\n",
        "\n",
        "for year_a in sorted(years_sorted):\n",
        "    a_str = str(year_a)\n",
        "    for year_b in sorted(years_sorted):\n",
        "        if year_a <= year_b:\n",
        "            continue\n",
        "        b_str, b_plus1 = str(year_b), str(year_b + 1)\n",
        "\n",
        "        if year_a in plain_years and f\"{a_str}_no_degradation_since_{b_plus1}\" in scenarios:\n",
        "            print(f\"# Degradation in {a_str} caused by events since {b_plus1}\")\n",
        "            print(f\"  ('{a_str}', '{a_str}_no_degradation_since_{b_plus1}'):\")\n",
        "            print(f\"    '{a_str}_degradation_since_{b_plus1}',\")\n",
        "            print(\"\")\n",
        "            degradation_since_dictionary[(a_str, f\"{a_str}_no_degradation_since_{b_plus1}\")] = f\"{a_str}_degradation_since_{b_plus1}\"\n",
        "\n",
        "# Process degradation_since_oldgrowth scenarios\n",
        "oldgrowth_printed = False\n",
        "for year in years_sorted:\n",
        "    y_str = str(year)\n",
        "    if (year in plain_years and year in oldgrowth_years and f\"{y_str}_oldgrowth\" in scenarios):\n",
        "        if not oldgrowth_printed:\n",
        "            print(f\"# Degradation in {y_str} caused by events since an old-growth state.\")\n",
        "            oldgrowth_printed = True\n",
        "        print(f\"  ('{y_str}', '{y_str}_oldgrowth'):\")\n",
        "        print(f\"    '{y_str}_degradation_since_oldgrowth',\")\n",
        "        print(\"\")\n",
        "        degradation_since_dictionary[(y_str, f\"{y_str}_oldgrowth\")] = f\"{y_str}_degradation_since_oldgrowth\"\n",
        "\n",
        "print(\"}\\n\")\n",
        "\n",
        "# 3. Deforestation since dictionary\n",
        "print(\"deforestation_since_dictionary = {\\n\")\n",
        "\n",
        "for year_a in sorted(years_sorted):\n",
        "    a_str = str(year_a)\n",
        "    for year_b in sorted(years_sorted):\n",
        "        if year_a <= year_b:\n",
        "            continue\n",
        "        b_str, b_plus1 = str(year_b), str(year_b + 1)\n",
        "\n",
        "        deg_key = (a_str, f\"{a_str}_no_degradation_since_{b_plus1}\")\n",
        "        dist_key = (a_str, f\"{a_str}_no_disturbance_since_{b_plus1}\")\n",
        "\n",
        "        if deg_key in degradation_since_dictionary and dist_key in disturbance_since:\n",
        "            deg_result = degradation_since_dictionary[deg_key]\n",
        "            dist_result = disturbance_since[dist_key]\n",
        "            defor_result = f\"{a_str}_deforestation_since_{b_plus1}\"\n",
        "\n",
        "            print(f\"# Deforestation in {a_str} caused by events since {b_plus1}\")\n",
        "            print(f\"  ('{deg_result}', '{dist_result}'):\")\n",
        "            print(f\"    '{defor_result}',\")\n",
        "            print(\"\")\n",
        "            deforestation_since_dictionary[(deg_result, dist_result)] = defor_result\n",
        "\n",
        "# Process deforestation_since_oldgrowth scenarios\n",
        "oldgrowth_printed = False\n",
        "for year in years_sorted:\n",
        "    y_str = str(year)\n",
        "    deg_key = (y_str, f\"{y_str}_oldgrowth\")\n",
        "    dist_key = (y_str, f\"{y_str}_oldgrowth_all_land\")\n",
        "\n",
        "    if deg_key in degradation_since_dictionary and dist_key in disturbance_since:\n",
        "        if not oldgrowth_printed:\n",
        "            print(f\"# Deforestation in {y_str} caused by events since an old-growth state.\")\n",
        "            oldgrowth_printed = True\n",
        "        deg_result = degradation_since_dictionary[deg_key]\n",
        "        dist_result = disturbance_since[dist_key]\n",
        "        defor_result = f\"{y_str}_deforestation_since_oldgrowth\"\n",
        "        print(f\"  ('{deg_result}', '{dist_result}'):\")\n",
        "        print(f\"    '{defor_result}',\")\n",
        "        print(\"\")\n",
        "        deforestation_since_dictionary[(deg_result, dist_result)] = defor_result\n",
        "\n",
        "print(\"}\\n\")\n",
        "\n",
        "# 4. Disturbance before the baseline years\n",
        "print(\"before_dictionary = {\\n\")\n",
        "\n",
        "for year_a in sorted(years_sorted):\n",
        "    a_str = str(year_a)\n",
        "    for year_b in sorted(years_sorted):\n",
        "        if year_a <= year_b:\n",
        "            continue\n",
        "        b_str, b_plus1 = str(year_b), str(year_b + 1)\n",
        "\n",
        "        # Check all three types of before calculations\n",
        "        checks = [\n",
        "            (disturbance_since, f\"{a_str}_no_disturbance_since_{b_plus1}\", f\"{a_str}_oldgrowth_all_land\", \"disturbance\"),\n",
        "            (degradation_since_dictionary, f\"{a_str}_no_degradation_since_{b_plus1}\", f\"{a_str}_oldgrowth\", \"degradation\")\n",
        "        ]\n",
        "\n",
        "        printed_header = False\n",
        "        for dictionary, since_scenario, oldgrowth_scenario, dist_type in checks:\n",
        "            since_key = (a_str, since_scenario)\n",
        "            oldgrowth_key = (a_str, oldgrowth_scenario)\n",
        "\n",
        "            if since_key in dictionary and oldgrowth_key in dictionary:\n",
        "                if not printed_header:\n",
        "                    print(f\"# Disturbances in {a_str} caused by events before {b_plus1}.\")\n",
        "                    printed_header = True\n",
        "                since_result = dictionary[since_key]\n",
        "                oldgrowth_result = dictionary[oldgrowth_key]\n",
        "                before_result = f\"{a_str}_{dist_type}_before_{b_plus1}\"\n",
        "                print(f\"  ('{oldgrowth_result}', '{since_result}'):\")\n",
        "                print(f\"    '{before_result}',\\n\")\n",
        "                before_dictionary[(oldgrowth_result, since_result)] = before_result\n",
        "\n",
        "        # Check deforestation before\n",
        "        defor_since_name = f\"{a_str}_deforestation_since_{b_plus1}\"\n",
        "        defor_oldgrowth_name = f\"{a_str}_deforestation_since_oldgrowth\"\n",
        "\n",
        "        if (defor_since_name in deforestation_since_dictionary.values() and\n",
        "            defor_oldgrowth_name in deforestation_since_dictionary.values()):\n",
        "            if not printed_header:\n",
        "                print(f\"# Disturbances in {a_str} caused by events before {b_plus1}.\")\n",
        "                printed_header = True\n",
        "            before_result = f\"{a_str}_deforestation_before_{b_plus1}\"\n",
        "            print(f\"  ('{defor_oldgrowth_name}', '{defor_since_name}'):\")\n",
        "            print(f\"    '{before_result}',\\n\")\n",
        "            before_dictionary[(defor_oldgrowth_name, defor_since_name)] = before_result\n",
        "\n",
        "        if printed_header:\n",
        "            print(\"\")\n",
        "\n",
        "print(\"}\\n\")\n",
        "\n",
        "# 5. Area-based dictionary (unchanged)\n",
        "print(\"area_based_dictionary = {\")\n",
        "\n",
        "# Get polygon names from polygons directory\n",
        "polygon_names = set()\n",
        "if os.path.exists(polygons_dir):\n",
        "    for file in os.listdir(polygons_dir):\n",
        "        if file.endswith('.gpkg'):\n",
        "            polygon_names.add(file[:-5])\n",
        "\n",
        "area_based_entries = []\n",
        "\n",
        "for scenario in scenarios:\n",
        "    parts = scenario.split('_')\n",
        "    # Check for deforestation (ends with \"Xm_degradation_buffer\")\n",
        "    if len(parts) >= 5 and parts[-1] == 'buffer' and parts[-2] == 'degradation' and parts[-3].endswith('m'):\n",
        "        alt_year, year_affix, dist_type = parts[0], parts[-4], parts[-5]\n",
        "        polygon_name = '_'.join(parts[1:-5])\n",
        "        if polygon_name in polygon_names and dist_type == 'deforestation':\n",
        "            output_name = f\"{alt_year}_deforestation_of_{polygon_name}_{year_affix}\"\n",
        "            area_based_entries.append((scenario, alt_year, output_name))\n",
        "    # Check for degradation (ends with \"degradation_YYYY\")\n",
        "    elif len(parts) >= 3 and parts[-2] == 'degradation' and parts[-1].isdigit() and len(parts[-1]) == 4:\n",
        "        alt_year, year_affix = parts[0], parts[-1]\n",
        "        polygon_name = '_'.join(parts[1:-2])\n",
        "        if polygon_name in polygon_names:\n",
        "            output_name = f\"{alt_year}_degradation_of_{polygon_name}_{year_affix}\"\n",
        "            area_based_entries.append((scenario, alt_year, output_name))\n",
        "\n",
        "if area_based_entries:\n",
        "    print(\"\\n# Area-based disturbance from alternate scenarios\")\n",
        "    for scenario, alt_year, output_name in sorted(area_based_entries):\n",
        "        print(f\"  ('{scenario}', '{alt_year}'):\")\n",
        "        print(f\"    '{output_name}',\")\n",
        "\n",
        "print(\"}\\n\")"
      ],
      "metadata": {
        "id": "IUaYCCymYI2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disturbance_since_dictionary = {\n",
        "\n",
        "# Disturbance in 2024 caused by events since 2022\n",
        "  ('2024', '2024_no_disturbance_since_2022'):\n",
        "    '2024_disturbance_since_2022',\n",
        "\n",
        "# Disturbance in 2024 caused by events since 2023\n",
        "  ('2024', '2024_no_disturbance_since_2023'):\n",
        "    '2024_disturbance_since_2023',\n",
        "\n",
        "# Disturbance in 2024 caused by events since 2024\n",
        "  ('2024', '2024_no_disturbance_since_2024'):\n",
        "    '2024_disturbance_since_2024',\n",
        "\n",
        "# Disturbance in 2021 caused by events since an oldgrowth state.\n",
        "  ('2021', '2021_oldgrowth_all_land'):\n",
        "    '2021_disturbance_since_oldgrowth',\n",
        "\n",
        "  ('2024', '2024_oldgrowth_all_land'):\n",
        "    '2024_disturbance_since_oldgrowth',\n",
        "\n",
        "}\n",
        "\n",
        "degradation_since_dictionary = {\n",
        "\n",
        "# Degradation in 2021 caused by events since 1993\n",
        "  ('2021', '2021_no_degradation_since_1993'):\n",
        "    '2021_degradation_since_1993',\n",
        "\n",
        "# Degradation in 2024 caused by events since 1996\n",
        "  ('2024', '2024_no_degradation_since_1996'):\n",
        "    '2024_degradation_since_1996',\n",
        "\n",
        "# Degradation in 2024 caused by events since 2024\n",
        "  ('2024', '2024_no_degradation_since_2024'):\n",
        "    '2024_degradation_since_2024',\n",
        "\n",
        "# Degradation in 2021 caused by events since an old-growth state.\n",
        "  ('2021', '2021_oldgrowth'):\n",
        "    '2021_degradation_since_oldgrowth',\n",
        "\n",
        "  ('2024', '2024_oldgrowth'):\n",
        "    '2024_degradation_since_oldgrowth',\n",
        "\n",
        "}\n",
        "\n",
        "deforestation_since_dictionary = {\n",
        "\n",
        "# Deforestation in 2024 caused by events since 2024\n",
        "  ('2024_degradation_since_2024', '2024_disturbance_since_2024'):\n",
        "    '2024_deforestation_since_2024',\n",
        "\n",
        "# Deforestation in 2021 caused by events since an old-growth state.\n",
        "  ('2021_degradation_since_oldgrowth', '2021_disturbance_since_oldgrowth'):\n",
        "    '2021_deforestation_since_oldgrowth',\n",
        "\n",
        "  ('2024_degradation_since_oldgrowth', '2024_disturbance_since_oldgrowth'):\n",
        "    '2024_deforestation_since_oldgrowth',\n",
        "\n",
        "}\n",
        "\n",
        "before_dictionary = {\n",
        "\n",
        "# Disturbances in 2021 caused by events before 1993.\n",
        "  ('2021_degradation_since_oldgrowth', '2021_degradation_since_1993'):\n",
        "    '2021_degradation_before_1993',\n",
        "\n",
        "\n",
        "# Disturbances in 2024 caused by events before 1996.\n",
        "  ('2024_degradation_since_oldgrowth', '2024_degradation_since_1996'):\n",
        "    '2024_degradation_before_1996',\n",
        "\n",
        "\n",
        "# Disturbances in 2024 caused by events before 2022.\n",
        "  ('2024_disturbance_since_oldgrowth', '2024_disturbance_since_2022'):\n",
        "    '2024_disturbance_before_2022',\n",
        "\n",
        "\n",
        "# Disturbances in 2024 caused by events before 2023.\n",
        "  ('2024_disturbance_since_oldgrowth', '2024_disturbance_since_2023'):\n",
        "    '2024_disturbance_before_2023',\n",
        "\n",
        "\n",
        "# Disturbances in 2024 caused by events before 2024.\n",
        "  ('2024_disturbance_since_oldgrowth', '2024_disturbance_since_2024'):\n",
        "    '2024_disturbance_before_2024',\n",
        "\n",
        "  ('2024_degradation_since_oldgrowth', '2024_degradation_since_2024'):\n",
        "    '2024_degradation_before_2024',\n",
        "\n",
        "  ('2024_deforestation_since_oldgrowth', '2024_deforestation_since_2024'):\n",
        "    '2024_deforestation_before_2024',\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "area_based_dictionary = {\n",
        "\n",
        "# Area-based disturbance from alternate scenarios\n",
        "  ('2024_road_mat_daling_deforestation_2023_30m_degradation_buffer', '2024'):\n",
        "    '2024_deforestation_of_road_mat_daling_2023',\n",
        "}\n"
      ],
      "metadata": {
        "id": "gFNUYdP3Fibv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P-0bj40AxZ2"
      },
      "outputs": [],
      "source": [
        "# Functions for subtract calculations\n",
        "def subtract_arrays(array1, array2):\n",
        "    dist_array = array1 - array2\n",
        "    return dist_array\n",
        "\n",
        "# Relative uncertainty propagation for change estimates\n",
        "# Based on IPCC and CEOS Land Product Validation Protocol methods\n",
        "# Follows Liang et al. (2023) Quantifying aboveground biomass dynamics from\n",
        "# charcoal degradation in Mozambique using GEDI Lidar and Landsat.\n",
        "def propagate_uncertainty(mean1, uncertainty1, mean2, uncertainty2):\n",
        "    absolute_uncertainty1 = np.multiply(mean1, uncertainty1, dtype='float64')\n",
        "    absolute_uncertainty2 = np.multiply(mean2, uncertainty2, dtype='float64')\n",
        "    sums_of_squares = np.square(absolute_uncertainty1, dtype='float64') + np.square(absolute_uncertainty2, dtype='float64')\n",
        "    # Avoid division by zero\n",
        "    denominator = np.abs(mean1 - mean2)\n",
        "    epsilon = np.finfo(np.float64).eps\n",
        "    denominator = np.where(denominator == 0, epsilon, denominator)\n",
        "    return np.sqrt(sums_of_squares, dtype='float64') / denominator\n",
        "\n",
        "# Determine processing mode based on source directory\n",
        "use_uncertainty = source_dir == uncertainty_dir\n",
        "\n",
        "# Progress tracking\n",
        "total_operations = len(disturbance_since) + len(degradation_since_dictionary) + len(deforestation_since_dictionary) + len(before_dictionary) + len(area_based_dictionary)\n",
        "progress_index = 0\n",
        "progress_label = widgets.Label(f\"Disturbance calculation progress: {progress_index}/{total_operations}\")\n",
        "\n",
        "display(progress_label)\n",
        "\n",
        "# 1. Process disturbance_since calculations\n",
        "for (scenario1, scenario2), disturbance_name in disturbance_since.items():\n",
        "    if use_uncertainty:\n",
        "        # Define filenames and paths for disturbance mean and uncertainty\n",
        "        mean_filename = f\"mean__{disturbance_name}__{selected_model}.tif\"\n",
        "        mean_path = join(disturbance_dir, mean_filename)\n",
        "        uncertainty_filename = f\"uncertainty__{disturbance_name}__{selected_model}.tif\"\n",
        "        uncertainty_path = join(disturbance_dir, uncertainty_filename)\n",
        "        # Skip if both files already exist\n",
        "        if exists(mean_path) and exists(uncertainty_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "\n",
        "        scenario1_base = f\"{scenario1}__{selected_model}\"\n",
        "        scenario2_base = f\"{scenario2}__{selected_model}\"\n",
        "        # Define scenario paths, assert that both exist for both scenarios\n",
        "        scenario1_mean_path = join(predictions_dir, f\"mean__{scenario1_base}.tif\")\n",
        "        scenario1_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario1_base}.tif\")\n",
        "        scenario2_mean_path = join(predictions_dir, f\"mean__{scenario2_base}.tif\")\n",
        "        scenario2_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario2_base}.tif\")\n",
        "        assert exists(scenario1_mean_path), f\"mean__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario1_uncertainty_path), f\"uncertainty__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_mean_path), f\"mean__{scenario2_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_uncertainty_path), f\"uncertainty__{scenario2_base}.tif does not exist.\"\n",
        "        # Read arrays\n",
        "        scenario1_mean = gdal.Open(scenario1_mean_path).ReadAsArray()\n",
        "        scenario1_uncertainty = gdal.Open(scenario1_uncertainty_path).ReadAsArray()\n",
        "        scenario2_mean = gdal.Open(scenario2_mean_path).ReadAsArray()\n",
        "        scenario2_uncertainty = gdal.Open(scenario2_uncertainty_path).ReadAsArray()\n",
        "        # Fill scenario nodata values with 0 if they are not nodatavalues in the other scenario\n",
        "        scenario1_mean = np.where((scenario1_mean == nodatavalue) & (scenario2_mean != nodatavalue), 0, scenario1_mean)\n",
        "        scenario1_uncertainty = np.where((scenario1_uncertainty == nodatavalue) & (scenario2_uncertainty != nodatavalue), 0, scenario1_uncertainty)\n",
        "        scenario2_mean = np.where((scenario2_mean == nodatavalue) & (scenario1_mean != nodatavalue), 0, scenario2_mean)\n",
        "        scenario2_uncertainty = np.where((scenario2_uncertainty == nodatavalue) & (scenario1_uncertainty != nodatavalue), 0, scenario2_uncertainty)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        dist_mean_array = np.where(scenario1_mean == nodatavalue, nodatavalue, subtract_arrays(scenario1_mean, scenario2_mean))\n",
        "        dist_uncertainty_array = np.where(scenario1_mean == nodatavalue, nodatavalue,\n",
        "                                         propagate_uncertainty(scenario1_mean, scenario1_uncertainty, scenario2_mean, scenario2_uncertainty))\n",
        "        # Set uncertainty to 0 where mean disturbance is 0\n",
        "        dist_uncertainty_array = np.where(dist_mean_array == 0, 0, dist_uncertainty_array)\n",
        "        # Export disturbance rasters\n",
        "        export_array_as_tif(dist_mean_array, mean_path, template=scenario1_mean_path)\n",
        "        export_array_as_tif(dist_uncertainty_array, uncertainty_path, template=scenario1_mean_path)\n",
        "    else:\n",
        "        # Define filenames and paths for disturbance\n",
        "        dist_filename = f\"{disturbance_name}__{selected_model}.tif\"\n",
        "        dist_path = join(disturbance_dir, dist_filename)\n",
        "        # Skip if file already exists\n",
        "        if exists(dist_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define scenario paths, assert that both exist for both scenarios\n",
        "        scenario1_path = join(predictions_dir, f\"{scenario1}__{selected_model}.tif\")\n",
        "        assert exists(scenario1_path), f\"{scenario1_path} does not exist.\"\n",
        "        scenario2_path = join(predictions_dir, f\"{scenario2}__{selected_model}.tif\")\n",
        "        assert exists(scenario2_path), f\"{scenario2_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        scenario1_array_temp = gdal.Open(scenario1_path).ReadAsArray()\n",
        "        scenario2_array_temp = gdal.Open(scenario2_path).ReadAsArray()\n",
        "        # Fill scenario nodata values with 0 if they are not nodatavalues in the other scenario\n",
        "        scenario1_array = np.where((scenario1_array_temp == nodatavalue) & (scenario2_array_temp != nodatavalue), 0, scenario1_array_temp)\n",
        "        scenario2_array = np.where((scenario2_array_temp == nodatavalue) & (scenario1_array != nodatavalue), 0, scenario2_array_temp)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        dist_array = np.where(scenario1_array==nodatavalue, nodatavalue, subtract_arrays(scenario1_array, scenario2_array))\n",
        "        # Export disturbance raster\n",
        "        export_array_as_tif(dist_array, dist_path, template = scenario1_path)\n",
        "\n",
        "    # Update progress\n",
        "    progress_index += 1\n",
        "    progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "\n",
        "# 2. Process degradation_since calculations\n",
        "for (scenario1, scenario2), disturbance_name in degradation_since_dictionary.items():\n",
        "    if use_uncertainty:\n",
        "        # Define filenames and paths for disturbance mean and uncertainty\n",
        "        mean_filename = f\"mean__{disturbance_name}__{selected_model}.tif\"\n",
        "        mean_path = join(disturbance_dir, mean_filename)\n",
        "        uncertainty_filename = f\"uncertainty__{disturbance_name}__{selected_model}.tif\"\n",
        "        uncertainty_path = join(disturbance_dir, uncertainty_filename)\n",
        "        # Skip if both files already exist\n",
        "        if exists(mean_path) and exists(uncertainty_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "\n",
        "        scenario1_base = f\"{scenario1}__{selected_model}\"\n",
        "        scenario2_base = f\"{scenario2}__{selected_model}\"\n",
        "        # Define scenario paths, assert that both exist for both scenarios\n",
        "        scenario1_mean_path = join(predictions_dir, f\"mean__{scenario1_base}.tif\")\n",
        "        scenario1_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario1_base}.tif\")\n",
        "        scenario2_mean_path = join(predictions_dir, f\"mean__{scenario2_base}.tif\")\n",
        "        scenario2_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario2_base}.tif\")\n",
        "        assert exists(scenario1_mean_path), f\"mean__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario1_uncertainty_path), f\"uncertainty__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_mean_path), f\"mean__{scenario2_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_uncertainty_path), f\"uncertainty__{scenario2_base}.tif does not exist.\"\n",
        "        # Read arrays\n",
        "        scenario1_mean = gdal.Open(scenario1_mean_path).ReadAsArray()\n",
        "        scenario1_uncertainty = gdal.Open(scenario1_uncertainty_path).ReadAsArray()\n",
        "        scenario2_mean = gdal.Open(scenario2_mean_path).ReadAsArray()\n",
        "        scenario2_uncertainty = gdal.Open(scenario2_uncertainty_path).ReadAsArray()\n",
        "        # Fill scenario nodata values with 0 if they are not nodatavalues in the other scenario\n",
        "        scenario1_mean = np.where((scenario1_mean == nodatavalue) & (scenario2_mean != nodatavalue), 0, scenario1_mean)\n",
        "        scenario1_uncertainty = np.where((scenario1_uncertainty == nodatavalue) & (scenario2_uncertainty != nodatavalue), 0, scenario1_uncertainty)\n",
        "        scenario2_mean = np.where((scenario2_mean == nodatavalue) & (scenario1_mean != nodatavalue), 0, scenario2_mean)\n",
        "        scenario2_uncertainty = np.where((scenario2_uncertainty == nodatavalue) & (scenario1_uncertainty != nodatavalue), 0, scenario2_uncertainty)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        dist_mean_array = np.where(scenario1_mean == nodatavalue, nodatavalue, subtract_arrays(scenario1_mean, scenario2_mean))\n",
        "        dist_uncertainty_array = np.where(scenario1_mean == nodatavalue, nodatavalue,\n",
        "                                         propagate_uncertainty(scenario1_mean, scenario1_uncertainty, scenario2_mean, scenario2_uncertainty))\n",
        "        # Set uncertainty to 0 where mean disturbance is 0\n",
        "        dist_uncertainty_array = np.where(dist_mean_array == 0, 0, dist_uncertainty_array)\n",
        "        # Export disturbance rasters\n",
        "        export_array_as_tif(dist_mean_array, mean_path, template=scenario1_mean_path)\n",
        "        export_array_as_tif(dist_uncertainty_array, uncertainty_path, template=scenario1_mean_path)\n",
        "    else:\n",
        "        # Define filenames and paths for disturbance\n",
        "        dist_filename = f\"{disturbance_name}__{selected_model}.tif\"\n",
        "        dist_path = join(disturbance_dir, dist_filename)\n",
        "        # Skip if file already exists\n",
        "        if exists(dist_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define scenario paths, assert that both exist for both scenarios\n",
        "        scenario1_path = join(predictions_dir, f\"{scenario1}__{selected_model}.tif\")\n",
        "        assert exists(scenario1_path), f\"{scenario1_path} does not exist.\"\n",
        "        scenario2_path = join(predictions_dir, f\"{scenario2}__{selected_model}.tif\")\n",
        "        assert exists(scenario2_path), f\"{scenario2_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        scenario1_array_temp = gdal.Open(scenario1_path).ReadAsArray()\n",
        "        scenario2_array_temp = gdal.Open(scenario2_path).ReadAsArray()\n",
        "        # Fill scenario nodata values with 0 if they are not nodatavalues in the other scenario\n",
        "        scenario1_array = np.where((scenario1_array_temp == nodatavalue) & (scenario2_array_temp != nodatavalue), 0, scenario1_array_temp)\n",
        "        scenario2_array = np.where((scenario2_array_temp == nodatavalue) & (scenario1_array != nodatavalue), 0, scenario2_array_temp)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        dist_array = np.where(scenario1_array==nodatavalue, nodatavalue, subtract_arrays(scenario1_array, scenario2_array))\n",
        "        # Export disturbance raster\n",
        "        export_array_as_tif(dist_array, dist_path, template = scenario1_path)\n",
        "\n",
        "    # Update progress\n",
        "    progress_index += 1\n",
        "    progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "\n",
        "# 3. Process deforestation_since calculations\n",
        "for (dist1_name, dist2_name), disturbance_name in deforestation_since_dictionary.items():\n",
        "    if use_uncertainty:\n",
        "        # Define filenames and paths of disturbance .tifs\n",
        "        mean_filename = f\"mean__{disturbance_name}__{selected_model}.tif\"\n",
        "        mean_path = join(disturbance_dir, mean_filename)\n",
        "        uncertainty_filename = f\"uncertainty__{disturbance_name}__{selected_model}.tif\"\n",
        "        uncertainty_path = join(disturbance_dir, uncertainty_filename)\n",
        "        # Skip if both files already exist\n",
        "        if exists(mean_path) and exists(uncertainty_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define disturbance paths, assert that both exist\n",
        "        dist1_mean_path = join(disturbance_dir, f\"mean__{dist1_name}__{selected_model}.tif\")\n",
        "        dist1_uncertainty_path = join(disturbance_dir, f\"uncertainty__{dist1_name}__{selected_model}.tif\")\n",
        "        dist2_mean_path = join(disturbance_dir, f\"mean__{dist2_name}__{selected_model}.tif\")\n",
        "        dist2_uncertainty_path = join(disturbance_dir, f\"uncertainty__{dist2_name}__{selected_model}.tif\")\n",
        "        assert exists(dist1_mean_path), f\"{dist1_mean_path} does not exist.\"\n",
        "        assert exists(dist1_uncertainty_path), f\"{dist1_uncertainty_path} does not exist.\"\n",
        "        assert exists(dist2_mean_path), f\"{dist2_mean_path} does not exist.\"\n",
        "        assert exists(dist2_uncertainty_path), f\"{dist2_uncertainty_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        dist1_mean = gdal.Open(dist1_mean_path).ReadAsArray()\n",
        "        dist1_uncertainty = gdal.Open(dist1_uncertainty_path).ReadAsArray()\n",
        "        dist2_mean = gdal.Open(dist2_mean_path).ReadAsArray()\n",
        "        dist2_uncertainty = gdal.Open(dist2_uncertainty_path).ReadAsArray()\n",
        "        # Fill disturbance nodata values with 0 if they are not nodatavalues in the other disturbance\n",
        "        dist1_mean = np.where((dist1_mean == nodatavalue) & (dist2_mean != nodatavalue), 0, dist1_mean)\n",
        "        dist1_uncertainty = np.where((dist1_uncertainty == nodatavalue) & (dist2_uncertainty != nodatavalue), 0, dist1_uncertainty)\n",
        "        dist2_mean = np.where((dist2_mean == nodatavalue) & (dist1_mean != nodatavalue), 0, dist2_mean)\n",
        "        dist2_uncertainty = np.where((dist2_uncertainty == nodatavalue) & (dist1_uncertainty != nodatavalue), 0, dist2_uncertainty)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in disturbance (second array)\n",
        "        result_mean = np.where(dist2_mean == nodatavalue, nodatavalue, subtract_arrays(dist2_mean, dist1_mean))\n",
        "        result_uncertainty = np.where(dist2_mean == nodatavalue, nodatavalue,\n",
        "                                     propagate_uncertainty(dist2_mean, dist2_uncertainty, dist1_mean, dist1_uncertainty))\n",
        "        # Set uncertainty to 0 where mean disturbance is 0\n",
        "        result_uncertainty = np.where(result_mean == 0, 0, result_uncertainty)\n",
        "        # Export disturbance rasters\n",
        "        export_array_as_tif(result_mean, mean_path, template=dist2_mean_path)\n",
        "        export_array_as_tif(result_uncertainty, uncertainty_path, template=dist2_mean_path)\n",
        "    else:\n",
        "        # Define filenames and paths of disturbance .tifs\n",
        "        output_filename = f\"{disturbance_name}__{selected_model}.tif\"\n",
        "        output_path = join(disturbance_dir, output_filename)\n",
        "        # Skip if file already exists\n",
        "        if exists(output_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define disturbance paths, assert that both exist\n",
        "        dist1_path = join(disturbance_dir, f\"{dist1_name}__{selected_model}.tif\")\n",
        "        assert exists(dist1_path), f\"{dist1_path} does not exist.\"\n",
        "        dist2_path = join(disturbance_dir, f\"{dist2_name}__{selected_model}.tif\")\n",
        "        assert exists(dist2_path), f\"{dist2_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        dist1_array_temp = gdal.Open(dist1_path).ReadAsArray()\n",
        "        dist2_array_temp = gdal.Open(dist2_path).ReadAsArray()\n",
        "        # Fill disturbance nodata values with 0 if they are not nodatavalues in the other disturbance\n",
        "        dist1_array = np.where((dist1_array_temp == nodatavalue) & (dist2_array_temp != nodatavalue), 0, dist1_array_temp)\n",
        "        dist2_array = np.where((dist2_array_temp == nodatavalue) & (dist1_array != nodatavalue), 0, dist2_array_temp)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in disturbance (second array)\n",
        "        result_array = np.where(dist2_array==nodatavalue, nodatavalue, subtract_arrays(dist2_array, dist1_array))\n",
        "        # Export disturbance raster\n",
        "        export_array_as_tif(result_array, output_path, template = dist2_path)\n",
        "\n",
        "    # Update progress\n",
        "    progress_index += 1\n",
        "    progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "\n",
        "# 4. Process before baseline disturbances\n",
        "for (dist1_name, dist2_name), disturbance_name in before_dictionary.items():\n",
        "    if use_uncertainty:\n",
        "        # Define filenames and paths of disturbance .tifs\n",
        "        mean_filename = f\"mean__{disturbance_name}__{selected_model}.tif\"\n",
        "        mean_path = join(disturbance_dir, mean_filename)\n",
        "        uncertainty_filename = f\"uncertainty__{disturbance_name}__{selected_model}.tif\"\n",
        "        uncertainty_path = join(disturbance_dir, uncertainty_filename)\n",
        "        # Skip if both files already exist\n",
        "        if exists(mean_path) and exists(uncertainty_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define disturbance paths, assert that both exist\n",
        "        dist1_mean_path = join(disturbance_dir, f\"mean__{dist1_name}__{selected_model}.tif\")\n",
        "        dist1_uncertainty_path = join(disturbance_dir, f\"uncertainty__{dist1_name}__{selected_model}.tif\")\n",
        "        dist2_mean_path = join(disturbance_dir, f\"mean__{dist2_name}__{selected_model}.tif\")\n",
        "        dist2_uncertainty_path = join(disturbance_dir, f\"uncertainty__{dist2_name}__{selected_model}.tif\")\n",
        "        assert exists(dist1_mean_path), f\"{dist1_mean_path} does not exist.\"\n",
        "        assert exists(dist1_uncertainty_path), f\"{dist1_uncertainty_path} does not exist.\"\n",
        "        assert exists(dist2_mean_path), f\"{dist2_mean_path} does not exist.\"\n",
        "        assert exists(dist2_uncertainty_path), f\"{dist2_uncertainty_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        dist1_mean = gdal.Open(dist1_mean_path).ReadAsArray()\n",
        "        dist1_uncertainty = gdal.Open(dist1_uncertainty_path).ReadAsArray()\n",
        "        dist2_mean = gdal.Open(dist2_mean_path).ReadAsArray()\n",
        "        dist2_uncertainty = gdal.Open(dist2_uncertainty_path).ReadAsArray()\n",
        "        # Fill disturbance nodata values with 0 if they are not nodatavalues in the other disturbance\n",
        "        dist1_mean = np.where((dist1_mean == nodatavalue) & (dist2_mean != nodatavalue), 0, dist1_mean)\n",
        "        dist1_uncertainty = np.where((dist1_uncertainty == nodatavalue) & (dist2_uncertainty != nodatavalue), 0, dist1_uncertainty)\n",
        "        dist2_mean = np.where((dist2_mean == nodatavalue) & (dist1_mean != nodatavalue), 0, dist2_mean)\n",
        "        dist2_uncertainty = np.where((dist2_uncertainty == nodatavalue) & (dist1_uncertainty != nodatavalue), 0, dist2_uncertainty)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        result_mean = np.where(dist1_mean == nodatavalue, nodatavalue, subtract_arrays(dist1_mean, dist2_mean))\n",
        "        result_uncertainty = np.where(dist1_mean == nodatavalue, nodatavalue,\n",
        "                                     propagate_uncertainty(dist1_mean, dist1_uncertainty, dist2_mean, dist2_uncertainty))\n",
        "        # Set uncertainty to 0 where mean disturbance is 0\n",
        "        result_uncertainty = np.where(result_mean == 0, 0, result_uncertainty)\n",
        "        # Export disturbance rasters\n",
        "        export_array_as_tif(result_mean, mean_path, template=dist1_mean_path)\n",
        "        export_array_as_tif(result_uncertainty, uncertainty_path, template=dist1_mean_path)\n",
        "    else:\n",
        "        # Define filenames and paths of disturbance .tifs\n",
        "        output_filename = f\"{disturbance_name}__{selected_model}.tif\"\n",
        "        output_path = join(disturbance_dir, output_filename)\n",
        "        # Skip if file already exists\n",
        "        if exists(output_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "        # Define disturbance paths, assert that both exist\n",
        "        dist1_path = join(disturbance_dir, f\"{dist1_name}__{selected_model}.tif\")\n",
        "        assert exists(dist1_path), f\"{dist1_path} does not exist.\"\n",
        "        dist2_path = join(disturbance_dir, f\"{dist2_name}__{selected_model}.tif\")\n",
        "        assert exists(dist2_path), f\"{dist2_path} does not exist.\"\n",
        "        # Read arrays\n",
        "        dist1_array_temp = gdal.Open(dist1_path).ReadAsArray()\n",
        "        dist2_array_temp = gdal.Open(dist2_path).ReadAsArray()\n",
        "        # Fill disturbance nodata values with 0 if they are not nodatavalues in the other disturbance\n",
        "        dist1_array = np.where((dist1_array_temp == nodatavalue) & (dist2_array_temp != nodatavalue), 0, dist1_array_temp)\n",
        "        dist2_array = np.where((dist2_array_temp == nodatavalue) & (dist1_array != nodatavalue), 0, dist2_array_temp)\n",
        "        # Create disturbance arrays where the value is not 'nodatavalue' in both scenarios\n",
        "        result_array = np.where(dist1_array==nodatavalue, nodatavalue, subtract_arrays(dist1_array, dist2_array))\n",
        "        # Export disturbance raster\n",
        "        export_array_as_tif(result_array, output_path, template = dist1_path)\n",
        "\n",
        "    # Update progress\n",
        "    progress_index += 1\n",
        "    progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "\n",
        "# 5. Process area-based disturbances\n",
        "for (scenario1, scenario2), disturbance_name in area_based_dictionary.items():\n",
        "    if use_uncertainty:\n",
        "        mean_filename = f\"mean__{disturbance_name}__{selected_model}.tif\"\n",
        "        mean_path = join(disturbance_dir, mean_filename)\n",
        "        uncertainty_filename = f\"uncertainty__{disturbance_name}__{selected_model}.tif\"\n",
        "        uncertainty_path = join(disturbance_dir, uncertainty_filename)\n",
        "        if exists(mean_path) and exists(uncertainty_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "\n",
        "        scenario1_base = f\"{scenario1}__{selected_model}\"\n",
        "        scenario2_base = f\"{scenario2}__{selected_model}\"\n",
        "        scenario1_mean_path = join(predictions_dir, f\"mean__{scenario1_base}.tif\")\n",
        "        scenario1_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario1_base}.tif\")\n",
        "        scenario2_mean_path = join(predictions_dir, f\"mean__{scenario2_base}.tif\")\n",
        "        scenario2_uncertainty_path = join(predictions_dir, f\"uncertainty__{scenario2_base}.tif\")\n",
        "        assert exists(scenario1_mean_path), f\"mean__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario1_uncertainty_path), f\"uncertainty__{scenario1_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_mean_path), f\"mean__{scenario2_base}.tif does not exist.\"\n",
        "        assert exists(scenario2_uncertainty_path), f\"uncertainty__{scenario2_base}.tif does not exist.\"\n",
        "\n",
        "        scenario1_mean = gdal.Open(scenario1_mean_path).ReadAsArray()\n",
        "        scenario1_uncertainty = gdal.Open(scenario1_uncertainty_path).ReadAsArray()\n",
        "        scenario2_mean = gdal.Open(scenario2_mean_path).ReadAsArray()\n",
        "        scenario2_uncertainty = gdal.Open(scenario2_uncertainty_path).ReadAsArray()\n",
        "\n",
        "        scenario1_mean = np.where((scenario1_mean == nodatavalue) & (scenario2_mean != nodatavalue), 0, scenario1_mean)\n",
        "        scenario1_uncertainty = np.where((scenario1_uncertainty == nodatavalue) & (scenario2_uncertainty != nodatavalue), 0, scenario1_uncertainty)\n",
        "        scenario2_mean = np.where((scenario2_mean == nodatavalue) & (scenario1_mean != nodatavalue), 0, scenario2_mean)\n",
        "        scenario2_uncertainty = np.where((scenario2_uncertainty == nodatavalue) & (scenario1_uncertainty != nodatavalue), 0, scenario2_uncertainty)\n",
        "\n",
        "        dist_mean_array = np.where(scenario1_mean == nodatavalue, nodatavalue, subtract_arrays(scenario1_mean, scenario2_mean))\n",
        "        dist_uncertainty_array = np.where(scenario1_mean == nodatavalue, nodatavalue,\n",
        "                                         propagate_uncertainty(scenario1_mean, scenario1_uncertainty, scenario2_mean, scenario2_uncertainty))\n",
        "        dist_uncertainty_array = np.where(dist_mean_array == 0, 0, dist_uncertainty_array)\n",
        "\n",
        "        export_array_as_tif(dist_mean_array, mean_path, template=scenario1_mean_path)\n",
        "        export_array_as_tif(dist_uncertainty_array, uncertainty_path, template=scenario1_mean_path)\n",
        "    else:\n",
        "        dist_filename = f\"{disturbance_name}__{selected_model}.tif\"\n",
        "        dist_path = join(disturbance_dir, dist_filename)\n",
        "        if exists(dist_path):\n",
        "            progress_index += 1\n",
        "            progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "            continue\n",
        "\n",
        "        scenario1_path = join(predictions_dir, f\"{scenario1}__{selected_model}.tif\")\n",
        "        assert exists(scenario1_path), f\"{scenario1_path} does not exist.\"\n",
        "        scenario2_path = join(predictions_dir, f\"{scenario2}__{selected_model}.tif\")\n",
        "        assert exists(scenario2_path), f\"{scenario2_path} does not exist.\"\n",
        "\n",
        "        scenario1_array_temp = gdal.Open(scenario1_path).ReadAsArray()\n",
        "        scenario2_array_temp = gdal.Open(scenario2_path).ReadAsArray()\n",
        "\n",
        "        scenario1_array = np.where((scenario1_array_temp == nodatavalue) & (scenario2_array_temp != nodatavalue), 0, scenario1_array_temp)\n",
        "        scenario2_array = np.where((scenario2_array_temp == nodatavalue) & (scenario1_array != nodatavalue), 0, scenario2_array_temp)\n",
        "\n",
        "        dist_array = np.where(scenario1_array==nodatavalue, nodatavalue, subtract_arrays(scenario1_array, scenario2_array))\n",
        "        export_array_as_tif(dist_array, dist_path, template = scenario1_path)\n",
        "\n",
        "    progress_index += 1\n",
        "    progress_label.value = f\"Disturbance calculation progress: {progress_index}/{total_operations}\"\n",
        "\n",
        "print(\"All disturbances calculated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81OCJi98NDwj"
      },
      "source": [
        "# Intactness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsend_eeNIll"
      },
      "outputs": [],
      "source": [
        "# Intactness is measured as relative percentage loss of AGBD within an area of interest\n",
        "\n",
        "# Select which baseline and disturbance raster to use for calculating intactness\n",
        "# percentage and relative intactness. Ideally this is the scenario with the least disturbance\n",
        "# and the difference between that and the current reality.\n",
        "\n",
        "for baseline in os.listdir(predictions_dir):\n",
        "  if source_dir == scenarios_dir: print(f\"selected_baseline = '{baseline}'\")\n",
        "  if source_dir == uncertainty_dir:\n",
        "    if 'mean' in baseline: print(f\"selected_baseline = '{baseline}'\")\n",
        "for dist in os.listdir(disturbance_dir):\n",
        "  if source_dir == scenarios_dir: print(f\"selected_dist = '{dist}'\")\n",
        "  if source_dir == uncertainty_dir:\n",
        "    if 'mean' in dist:print(f\"selected_dist = '{dist}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87Q6aMSdNIye"
      },
      "outputs": [],
      "source": [
        "# selected_baseline = '2021_oldgrowth_all_land__agbd_tekai_250625_003858.tif'\n",
        "selected_baseline = '2021_no_degradation_since_1993__agbd_tekai_250625_003858.tif'\n",
        "# selected_dist = '2021_degradation_deforestation_total__agbd_tekai_250625_003858.tif'\n",
        "selected_dist = '2021_degradation_since_1993__agbd_tekai_250625_003858.tif'\n",
        "\n",
        "forest_mask_year = '2021'\n",
        "\n",
        "# Define the baseline name based on source directory\n",
        "if source_dir == scenarios_dir:\n",
        "  base_dist_name = f\"{selected_baseline.split('__')[0]}__{selected_dist.split('__')[0]}\"\n",
        "if source_dir == uncertainty_dir:\n",
        "  base_dist_name = f\"{selected_baseline.split('__')[1]}__{selected_dist.split('__')[1]}\"\n",
        "\n",
        "intactness_baseline_dist_dir = join(intactness_dir, base_dist_name)\n",
        "makedirs(intactness_baseline_dist_dir, exist_ok=True)\n",
        "\n",
        "percentage_filename = f\"percentage_change__{base_dist_name}__{selected_model}.tif\"\n",
        "percentage_path = join(intactness_baseline_dist_dir, percentage_filename)\n",
        "\n",
        "if not exists(percentage_path):\n",
        "  # Define filenames and directories\n",
        "  selected_baseline_path = join(predictions_dir, selected_baseline)\n",
        "  selected_dist_path = join(disturbance_dir, selected_dist)\n",
        "  selected_mask_path = join(masks_dir, f\"mask_forest_{forest_mask_year}.tif\")\n",
        "\n",
        "  # Convert to arrays\n",
        "  selected_baseline_array = gdal.Open(selected_baseline_path).ReadAsArray()\n",
        "  selected_dist_array = gdal.Open(selected_dist_path).ReadAsArray()\n",
        "  selected_mask_array = gdal.Open(selected_mask_path).ReadAsArray()\n",
        "\n",
        "  # Create percentage array where the value is not 'nodatavalue' in any of the inputs\n",
        "  percentage_array = np.where((selected_mask_array==nodatavalue) | (selected_baseline_array==nodatavalue) | (selected_dist_array==nodatavalue), nodatavalue,\n",
        "                              selected_dist_array/selected_baseline_array*100)\n",
        "  export_array_as_tif(percentage_array, percentage_path, template = selected_baseline_path)\n",
        "  print(f\"{percentage_filename} has been exported.\")\n",
        "\n",
        "else: print(f\"{percentage_filename} already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwXRZTew1r39"
      },
      "outputs": [],
      "source": [
        "# Use additional polygons for masking relative intactness quantiles\n",
        "polygons_to_exclude = ['template.gpkg', 'project_area_buffered_bbox.gpkg']\n",
        "\n",
        "# Select baseline / disturbance pairs to measure relative intactness\n",
        "print(\"baseline_disturbance_pairs = [\")\n",
        "for dir in os.listdir(intactness_dir):\n",
        "  print(f\"'{dir}',\")\n",
        "print(\"]\\n\")\n",
        "\n",
        "# Select polygons to mask and calculate quantiles\n",
        "print(\"mask_polygons = [\")\n",
        "for polygon in os.listdir(polygons_dir):\n",
        "  if polygon not in polygons_to_exclude:\n",
        "    if 'inverse' not in polygon:\n",
        "      print(f\"'{polygon}',\")\n",
        "print(None)\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru_UDUkAPw-8"
      },
      "outputs": [],
      "source": [
        "baseline_disturbance_pairs = [\n",
        "'2021_oldgrowth_all_land__2021_degradation_deforestation_total',\n",
        "'2021_no_degradation_since_1993__2021_degradation_since_1993',\n",
        "]\n",
        "\n",
        "mask_polygons = [\n",
        "# 'project_area.gpkg',\n",
        "# 'peninsular_malaysia.gpkg',\n",
        "# 'lu_yong.gpkg',\n",
        "# 'lu_yong_lipis.gpkg',\n",
        "# 'lu_berkelah_jerantut.gpkg',\n",
        "# 'lu_tekai_tembeling.gpkg',\n",
        "# 'lu_ais.gpkg',\n",
        "# 'lu_pa_taman_negara_krau.gpkg',\n",
        "# 'lu_tekam.gpkg',\n",
        "# 'lu_berkelah_temerloh.gpkg',\n",
        "# 'lu_remen_chereh.gpkg',\n",
        "# 'lu_berkelah_kuantan.gpkg',\n",
        "'forest_reserves.gpkg',\n",
        "# 'gedi_area.gpkg',\n",
        "# None\n",
        "]\n",
        "\n",
        "# Define number of quantiles for intactness rating (e.g. 10 for 1 - 10)\n",
        "num_quantiles = 10\n",
        "\n",
        "\n",
        "for mask_polygon in mask_polygons:\n",
        "  if mask_polygon is not None:\n",
        "    # Create an inverse project area path for masking\n",
        "    template_polygon_path = join(polygons_dir, \"template.gpkg\")\n",
        "    inverse_polygon_path = join(polygons_dir, f\"{mask_polygon[:-5]}_inverse.gpkg\")\n",
        "    if not exists(inverse_polygon_path):\n",
        "      polygon_path = join(polygons_dir, mask_polygon)\n",
        "      template_polygon = gpd.read_file(template_polygon_path)\n",
        "      polygon_read = gpd.read_file(polygon_path)\n",
        "      polygon_crs = polygon_read.crs.to_epsg()\n",
        "      inverse_polygon = template_polygon['geometry'].difference(polygon_read['geometry']).iloc[0]\n",
        "      inverse_polygon_gdf = gpd.GeoDataFrame({'geometry': [inverse_polygon]}, crs=f\"EPSG:{polygon_crs}\")\n",
        "      inverse_polygon_gdf.to_file(inverse_polygon_path, driver=\"GPKG\")\n",
        "      print(f\"An inverse masking polygon for {mask_polygon} has been created in {polygons_dir}.\")\n",
        "    else: print(f\"An inverse masking polygon for {mask_polygon} already exists.\")\n",
        "\n",
        "for base_dist_name in baseline_disturbance_pairs:\n",
        "  intactness_baseline_dist_dir = join(intactness_dir, base_dist_name)\n",
        "  percentage_filename = f\"percentage_change__{base_dist_name}__{selected_model}\"\n",
        "  percentage_path = join(intactness_baseline_dist_dir, f\"{percentage_filename}.tif\")\n",
        "\n",
        "  for mask_polygon in mask_polygons:\n",
        "\n",
        "    if mask_polygon is not None:\n",
        "      # Copy the percentage raster for potential masking\n",
        "      percentage_masked_filename = f\"{percentage_filename}__masked_{mask_polygon[:-5]}.tif\"\n",
        "      percentage_masked_path = join(intactness_baseline_dist_dir, percentage_masked_filename)\n",
        "      if not exists(percentage_masked_path):\n",
        "        print(f\"Copying {percentage_filename} for masking...\")\n",
        "        copyfile(percentage_path, percentage_masked_path)\n",
        "        print(f\"Masking {percentage_filename} with {mask_polygon}...\")\n",
        "        inverse_polygon_path = join(polygons_dir, f\"{mask_polygon[:-5]}_inverse.gpkg\")\n",
        "        burn_polygon_to_raster(percentage_masked_path, inverse_polygon_path, fixed_value=nodatavalue, all_touched=False)\n",
        "        # Recompress the prediction after burning the polygon masks\n",
        "        percentage_masked_array = gdal.Open(percentage_masked_path).ReadAsArray()\n",
        "        export_array_as_tif(percentage_masked_array, percentage_masked_path, compress = True)\n",
        "        print(f\"{percentage_filename} masked.\")\n",
        "      else: print(f\"{percentage_masked_filename} already exists.\")\n",
        "\n",
        "    # Define paths and arrays\n",
        "    if mask_polygon is None: relative_intactness_name = f'intactness__{num_quantiles}_quantiles__{base_dist_name}__{selected_model}'\n",
        "    else: relative_intactness_name = f'intactness__{mask_polygon[:-5]}_{num_quantiles}_quantiles__{base_dist_name}__{selected_model}'\n",
        "    relative_intactness_path = join(intactness_baseline_dist_dir, f'{relative_intactness_name}.tif')\n",
        "    if not exists(relative_intactness_path):\n",
        "      if mask_polygon is None: percentage_array = gdal.Open(percentage_path).ReadAsArray()\n",
        "      else: percentage_array = gdal.Open(percentage_masked_path).ReadAsArray()\n",
        "      relative_intactness_array = np.empty_like(percentage_array, dtype=object)\n",
        "\n",
        "      # Set all values above 0 to 0, assuming negative values are not intact\n",
        "      percentage_array[percentage_array > 0] = 0\n",
        "\n",
        "      # Separate valid and invalid (nodatavalue) elements\n",
        "      valid_elements = percentage_array[percentage_array != nodatavalue]\n",
        "      invalid_elements = percentage_array == nodatavalue\n",
        "\n",
        "      # Calculate quantiles for valid elements\n",
        "      quantiles = np.percentile(valid_elements, np.linspace(0, 100, num_quantiles + 1)[1:-1]) if len(valid_elements) > 0 else []\n",
        "      for i in range(1, num_quantiles + 1):\n",
        "          lower_bound = quantiles[i-2] if i > 1 and len(quantiles) >= i-1 else float('-inf')\n",
        "          upper_bound = quantiles[i-1] if len(quantiles) >= i else float('inf')\n",
        "          relative_intactness_array[(percentage_array > lower_bound) & (percentage_array <= upper_bound)] = i\n",
        "          relative_intactness_array[invalid_elements] = nodatavalue\n",
        "          # Set all perfectly intact pixels (0 % change) to max score\n",
        "          relative_intactness_array[percentage_array == 0] = num_quantiles\n",
        "      export_array_as_tif(relative_intactness_array, relative_intactness_path)\n",
        "\n",
        "      # Prepare data for CSV: Collect lower and upper bounds for each category\n",
        "      ranges_data = {'Lower_Bound': [], 'Upper_Bound': []}\n",
        "      for i in range(1, num_quantiles + 1):\n",
        "          lower_bound = quantiles[i-2] if i > 1 and len(quantiles) >= i-1 else float('-inf')\n",
        "          upper_bound = quantiles[i-1] if len(quantiles) >= i else float('inf')\n",
        "          ranges_data['Lower_Bound'].append(lower_bound)\n",
        "          ranges_data['Upper_Bound'].append(upper_bound)\n",
        "\n",
        "      # Create DataFrame and save to CSV\n",
        "      relative_intactness_df = pd.DataFrame(ranges_data)\n",
        "      relative_intactness_csv_path = os.path.join(intactness_baseline_dist_dir, f'{relative_intactness_name}.csv')\n",
        "      relative_intactness_df.to_csv(relative_intactness_csv_path, index=False)\n",
        "\n",
        "      # Generate and save histogram as .png\n",
        "      histogram_path = join(intactness_baseline_dist_dir, f'{relative_intactness_name}.png')\n",
        "      plt.figure()\n",
        "      plt.hist(valid_elements.flatten(), bins='auto')\n",
        "      plt.title(f'{relative_intactness_name} Histogram')\n",
        "      plt.xlabel('Value')\n",
        "      plt.ylabel('Frequency')\n",
        "      plt.savefig(histogram_path)\n",
        "      plt.close()\n",
        "\n",
        "    else: print(f\"{relative_intactness_name} already exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN-7ctfgdoF2"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcuArY00N9Mc"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "QJ8jLRKRSfgb",
        "y_OkHaUkTCyB",
        "ECHaTfrs0n7i",
        "81OCJi98NDwj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}