{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/main/4_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mdTQzOHb9Ra"
      },
      "source": [
        "# Imports, directories and global functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpxFKWdWVgX6"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "\n",
        "# Mount Google Drive and set base directory\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "eAPopw3StVzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRFq9zEQr2C8"
      },
      "outputs": [],
      "source": [
        "# Reload imports, replacing those in the cache\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# Imports\n",
        "from datetime import datetime\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import operator\n",
        "from os import makedirs\n",
        "from os.path import exists, join\n",
        "from osgeo import gdal\n",
        "import pandas as pd\n",
        "import requests\n",
        "from shapely.geometry import Point\n",
        "from shapely.ops import unary_union\n",
        "from shutil import copyfile\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHEzVXynr6SN"
      },
      "outputs": [],
      "source": [
        "# 1_areas directories\n",
        "areas_dir = join(base_dir, '1_areas')\n",
        "polygons_dir = join(areas_dir, 'polygons')\n",
        "template_dir = join(areas_dir, \"template.tif\")\n",
        "\n",
        "# 2_variates directories\n",
        "variates_final_dir = join(base_dir, \"2_variates/pkl_final\")\n",
        "\n",
        "# 3_predictors directories\n",
        "predictors_dir = join(base_dir, \"3_predictors\")\n",
        "edge_effects_dir = join(predictors_dir, \"binary_edge_effects\")\n",
        "continuous_final_dir = join(predictors_dir, \"continuous_final\")\n",
        "topography_final_dir = join(predictors_dir, \"topo_final\")\n",
        "topography_corrected_final_dir = join(predictors_dir, \"topo_corrected_final\")\n",
        "coast_dir = join(predictors_dir, 'coast')\n",
        "predictor_final_dir = join(predictors_dir, \"final\")\n",
        "\n",
        "# 4_datasets directories\n",
        "datasets_dir = join(base_dir, \"4_datasets\")\n",
        "datasets_var_dir = join(datasets_dir, \"variates\")\n",
        "datasets_add_pre_dir = join(datasets_dir, \"add_predictors\")\n",
        "datasets_filtered_dir = join(datasets_dir, \"filtered\")\n",
        "datasets_final_dir = join(datasets_dir, \"final\")\n",
        "datasets_gpkg_dir = join(datasets_dir, \"gpkg\")\n",
        "\n",
        "# Create directories\n",
        "makedirs(predictor_final_dir, exist_ok=True)\n",
        "makedirs(datasets_dir, exist_ok=True)\n",
        "makedirs(datasets_var_dir, exist_ok=True)\n",
        "makedirs(datasets_add_pre_dir, exist_ok=True)\n",
        "makedirs(datasets_filtered_dir, exist_ok=True)\n",
        "makedirs(datasets_final_dir, exist_ok=True)\n",
        "makedirs(datasets_gpkg_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_lgjEC_LoRZ"
      },
      "outputs": [],
      "source": [
        "# export_array_as_tif function\n",
        "nodatavalue = -1111111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_dir, nodatavalue=nodatavalue, compress=compress):\n",
        "  template = gdal.Open(template)\n",
        "  template_band = template.GetRasterBand(1)\n",
        "  template_dimensions, template_projection = template.GetGeoTransform(), template.GetProjection()\n",
        "  if compress: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32,\n",
        "                                                options=[\"COMPRESS=DEFLATE\",\"PREDICTOR=2\",\"ZLEVEL=9\"])\n",
        "  if compress == False: driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, bands=1, eType=gdal.GDT_Float32)\n",
        "  driver.GetRasterBand(1).WriteArray(input_array)\n",
        "  driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "  driver.SetGeoTransform(template_dimensions)\n",
        "  driver.SetProjection(template_projection)\n",
        "\n",
        "\n",
        "def sample_raster_values(pd_dataframe, raster_path, predictor=False, geometry_column='geometry'):\n",
        "    raster_name = raster_path.split('/')[-1][:-4]\n",
        "    if predictor: raster_name = 'pre_' + raster_name\n",
        "    # Read raster array and dimensions\n",
        "    raster = gdal.Open(raster_path)\n",
        "    band = raster.GetRasterBand(1)\n",
        "    geotransform = raster.GetGeoTransform()\n",
        "    raster_array = band.ReadAsArray()\n",
        "    # Compute x and y indices for raster sampling\n",
        "    x_values = [(geom.x - geotransform[0]) / geotransform[1] for geom in pd_dataframe[geometry_column]]\n",
        "    y_values = [(geom.y - geotransform[3]) / geotransform[5] for geom in pd_dataframe[geometry_column]]\n",
        "    # Sample values from the raster array\n",
        "    sampled_values = [raster_array[int(y), int(x)] for x, y in zip(x_values, y_values)]\n",
        "    # Add the sampled values as a new column to the DataFrame\n",
        "    pd_dataframe[raster_name] = sampled_values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalise predictors"
      ],
      "metadata": {
        "id": "DkcwIQ7npXLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Round latitude and longitude rasters and finalise\n",
        "# These help account for ecological spatial patterns we do not have predictor rasters for.\n",
        "# Precision should strike a balance between accuracy and overfitting/model training time\n",
        "precision = 3 # 3 is equivalent to a precision of ~111 m at the equator, i.e. every three to four 30 m pixels\n",
        "coordinates = ['latitude.tif', 'longitude.tif']\n",
        "for coordinate in coordinates:\n",
        "  coordinate_path = join(areas_dir, coordinate)\n",
        "  coordinate_rounded_path = join(predictor_final_dir, coordinate)\n",
        "  if not exists(coordinate_rounded_path):\n",
        "    coordinate_array = gdal.Open(coordinate_path).ReadAsArray()\n",
        "    coordinate_array_round = np.round(coordinate_array, precision)\n",
        "    export_array_as_tif(coordinate_array_round, coordinate_rounded_path)\n",
        "    print(f\"{coordinate} has been rounded and exported to {predictor_final_dir}\")\n",
        "  else: print(f\"{coordinate} already exists in {predictor_final_dir}\")"
      ],
      "metadata": {
        "id": "8Hswr5edpZgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and verify final predictor list\n",
        "predictor_list = [join(coast_dir,'coast_proximity_km.tif')]\n",
        "for predictor in os.listdir(continuous_final_dir):\n",
        "    predictor_list.append(join(continuous_final_dir, predictor))\n",
        "for predictor in os.listdir(edge_effects_dir):\n",
        "  predictor_list.append(join(edge_effects_dir, predictor))\n",
        "for predictor in os.listdir(topography_final_dir):\n",
        "  predictor_list.append(join(topography_final_dir, predictor))\n",
        "if exists(topography_corrected_final_dir):\n",
        "  for predictor in os.listdir(topography_corrected_final_dir):\n",
        "    predictor_list.append(join(topography_corrected_final_dir, predictor))\n",
        "predictor_list = sorted(predictor_list)\n",
        "\n",
        "print(\"predictor_list = [\")\n",
        "for predictor in predictor_list:\n",
        "  print(f\"'{predictor}',\")\n",
        "print(']')"
      ],
      "metadata": {
        "id": "DiE5HJHKpeiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_list = [\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1990.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1991.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1992.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1993.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1994.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1995.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1996.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1997.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1998.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_1999.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2000.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2001.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2002.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2003.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2004.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2005.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2006.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2007.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2008.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2009.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2010.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2011.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2012.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2013.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2014.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2015.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2016.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2017.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2018.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2019.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2020.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2021.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2022.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/disturbance_with_edge_effects_2023.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1990.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1991.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1992.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1993.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1994.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1995.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1996.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1997.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1998.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_1999.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2000.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2001.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2002.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2003.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2004.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2005.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2006.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2007.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2008.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2009.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2010.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2011.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2012.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2013.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2014.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2015.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2016.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2017.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2018.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2019.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2020.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2021.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2022.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/forest_with_edge_effects_2023.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_ais_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_berkelah_jerantut_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_berkelah_kuantan_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_berkelah_temerloh_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_pa_taman_negara_krau_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_remen_chereh_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_tekai_tembeling_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_tekam_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_yong_lipis_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/binary_edge_effects/lu_yong_with_edge_effects.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/coast/coast_proximity_km.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_aspect_cosine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_aspect_sine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_circular_variance_aspect_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_circular_variance_aspect_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_circular_variance_aspect_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_deviation_mean_elevation_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_deviation_mean_elevation_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_deviation_mean_elevation_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_eastness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_elevation.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_northness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_profile_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_roughness_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_roughness_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_roughness_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_slope.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_stream_power_index_log10.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_surface_area_ratio.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_tangential_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_topographic_position_index_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_topographic_position_index_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_topographic_position_index_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_topographic_ruggedness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_smooth_topographic_wetness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_aspect_cosine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_aspect_sine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_circular_variance_aspect_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_circular_variance_aspect_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_circular_variance_aspect_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_deviation_mean_elevation_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_deviation_mean_elevation_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_deviation_mean_elevation_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_eastness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_elevation.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_northness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_profile_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_roughness_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_roughness_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_roughness_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_slope.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_stream_power_index_log10.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_surface_area_ratio.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_tangential_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_topographic_position_index_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_topographic_position_index_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_topographic_position_index_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_topographic_ruggedness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_corrected_final/topo_cor_unsmooth_topographic_wetness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_aspect_cosine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_aspect_sine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_circular_variance_aspect_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_circular_variance_aspect_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_circular_variance_aspect_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_deviation_mean_elevation_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_deviation_mean_elevation_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_deviation_mean_elevation_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_eastness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_elevation.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_northness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_profile_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_roughness_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_roughness_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_roughness_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_slope.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_stream_power_index_log10.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_surface_area_ratio.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_tangential_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_topographic_position_index_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_topographic_position_index_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_topographic_position_index_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_topographic_ruggedness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_smooth_topographic_wetness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_aspect_cosine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_aspect_sine.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_circular_variance_aspect_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_circular_variance_aspect_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_circular_variance_aspect_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_deviation_mean_elevation_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_deviation_mean_elevation_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_deviation_mean_elevation_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_eastness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_elevation.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_northness.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_profile_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_roughness_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_roughness_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_roughness_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_slope.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_stream_power_index_log10.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_surface_area_ratio.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_tangential_curvature.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_topographic_position_index_03.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_topographic_position_index_07.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_topographic_position_index_11.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_topographic_ruggedness_index.tif',\n",
        "'/gdrive/Shareddrives/masfi/3_predictors/topo_final/topo_uncor_unsmooth_topographic_wetness_index.tif',\n",
        "]"
      ],
      "metadata": {
        "id": "cKOVNRZfphF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for predictor in predictor_list:\n",
        "  predictor_name = predictor.split('/')[-1]\n",
        "  predictor_destination = join(predictor_final_dir, predictor_name)\n",
        "  if not exists(predictor_destination):\n",
        "    copyfile(predictor, predictor_destination)\n",
        "print(\"All predictors finalised.\")"
      ],
      "metadata": {
        "id": "nFeLZBOOpkyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bboEe-LBXVCQ"
      },
      "source": [
        "# Compile GEDI elevation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvz5wSeDXUf7"
      },
      "outputs": [],
      "source": [
        "# Correct GEDI elevation data\n",
        "\n",
        "# Download Earth Gravitation Model (EGM) from https://www.agisoft.com/downloads/geoids/\n",
        "earth_gravitational_model_url = 'https://download.agisoft.com/gtg/us_nga_egm2008_1.tif'\n",
        "earth_gravitational_model_path = join(datasets_var_dir, 'earth_gravitational_model.tif')\n",
        "if not exists(earth_gravitational_model_path):\n",
        "  request = requests.get(earth_gravitational_model_url, allow_redirects=True)\n",
        "  open(earth_gravitational_model_path, 'wb').write(request.content)\n",
        "  print(f'EGM raster downloaded to: {earth_gravitational_model_path}')\n",
        "else: print(f'EGM raster already exists at: {earth_gravitational_model_path}')\n",
        "\n",
        "# Select the GEDI .pkl with elevation ('lon_lowestmode') data\n",
        "for pkl in os.listdir(variates_final_dir):\n",
        "    print(f\"variates_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy8BrS2gihA-"
      },
      "outputs": [],
      "source": [
        "variates_pkl = 'GEDI04_A.pkl'\n",
        "\n",
        "use_gedi_area_polygon = True\n",
        "\n",
        "variates_read_pkl = pd.read_pickle(join(variates_final_dir, variates_pkl))\n",
        "\n",
        "# Ensure all points are in the training area\n",
        "if use_gedi_area_polygon: project_area_polygon = gpd.read_file(join(polygons_dir, 'gedi_area.gpkg'))\n",
        "else: gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "variates_geodataframe = gpd.GeoDataFrame(variates_read_pkl, geometry='geometry')\n",
        "clipped_variates_gdf = gpd.clip(variates_geodataframe, project_area_polygon)\n",
        "clipped_variates_df = pd.DataFrame(clipped_variates_gdf)\n",
        "print(f\"{len(variates_read_pkl) - len(clipped_variates_df)} out of {len(variates_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_variates_df.isna().any(axis=1).sum()\n",
        "dataset_variates = clipped_variates_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")\n",
        "\n",
        "dataset_variates = variates_read_pkl.copy()\n",
        "columns_to_keep = ['shot_number','beam','geometry','elev_lowestmode','sensitivity']\n",
        "dataset_variates.drop(columns=[col for col in dataset_variates.columns.values if col not in columns_to_keep], inplace=True)\n",
        "\n",
        "# Sample EGM values\n",
        "sample_raster_values(dataset_variates, earth_gravitational_model_path)\n",
        "\n",
        "# Correct elevation\n",
        "dataset_variates['elevation_corrected'] = dataset_variates['elev_lowestmode'] - dataset_variates['earth_gravitational_model']\n",
        "\n",
        "# Sample base DEM values\n",
        "base_dem_path = join(areas_dir, 'base_dem.tif')\n",
        "sample_raster_values(dataset_variates, base_dem_path)\n",
        "\n",
        "# Calculate elevation difference\n",
        "dataset_variates['elevation_corrected_diff'] = dataset_variates['elevation_corrected'] - dataset_variates['base_dem']\n",
        "\n",
        "# Evaluate difference for filtering. Outliers are usually GEDI measurement errors\n",
        "elev_corr_diff_array = np.array(dataset_variates['elevation_corrected_diff'])\n",
        "first_percentile = np.percentile(elev_corr_diff_array, 1)\n",
        "ninety_ninth_percentile = np.percentile(elev_corr_diff_array, 99)\n",
        "random_selection = np.random.choice(elev_corr_diff_array, size = min(100_000, len(dataset_variates)), replace = False)\n",
        "_ = plt.hist(random_selection, bins='auto')  # arguments are passed to np.histogram\n",
        "plt.title(\"Base DEM - GEDI corrected elevation\")\n",
        "plt.show()\n",
        "print(f'The ninety-ninth percentile is {ninety_ninth_percentile} while the first percentile is {first_percentile}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDBFHtS8lFF_"
      },
      "outputs": [],
      "source": [
        "override_bounds = False\n",
        "upper_bound, lower_bound = 20, -70\n",
        "if not override_bounds:\n",
        "  upper_bound, lower_bound = ninety_ninth_percentile, first_percentile\n",
        "\n",
        "dataset_variates_filtered = dataset_variates[(dataset_variates['elevation_corrected_diff'] >= lower_bound) & (dataset_variates['elevation_corrected_diff'] <= upper_bound)]\n",
        "print(f'{len(dataset_variates) - len(dataset_variates_filtered)} data points were filtered from {len(dataset_variates)} original points.')\n",
        "\n",
        "# Drop correction and filtering columns\n",
        "dataset_variates_filtered = dataset_variates_filtered.drop(columns=['elev_lowestmode','earth_gravitational_model','base_dem','elevation_corrected_diff'])\n",
        "\n",
        "# Export to .pkl\n",
        "dataset_variates_path = join(datasets_var_dir, 'elevation_corrected.pkl')\n",
        "dataset_variates_filtered.to_pickle(dataset_variates_path)\n",
        "dataset_variates_filtered = pd.read_pickle(dataset_variates_path)\n",
        "print(f\"The GEDI corrected elevation dataset has been processed and exported to: {dataset_variates_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFua9JVxZ-67"
      },
      "source": [
        "# Compile GEDI vegetation indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K5cvW9baXDS"
      },
      "outputs": [],
      "source": [
        "# Select the GEDI .pkl with aboveground biomass density / ha ('agbd') data\n",
        "for pkl in os.listdir(variates_final_dir):\n",
        "    print(f\"variates_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hju0dyR_YzK"
      },
      "outputs": [],
      "source": [
        "variates_pkl = 'GEDI04_A.pkl'\n",
        "\n",
        "dataset_name = 'agbd'\n",
        "use_gedi_area_polygon = True\n",
        "\n",
        "variates_read_pkl = pd.read_pickle(join(variates_final_dir, variates_pkl))\n",
        "\n",
        "# Ensure all points are in the training area\n",
        "if use_gedi_area_polygon: project_area_polygon = gpd.read_file(join(polygons_dir, 'gedi_area.gpkg'))\n",
        "else: gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "variates_geodataframe = gpd.GeoDataFrame(variates_read_pkl, geometry='geometry')\n",
        "clipped_variates_gdf = gpd.clip(variates_geodataframe, project_area_polygon)\n",
        "clipped_variates_df = pd.DataFrame(clipped_variates_gdf)\n",
        "print(f\"{len(variates_read_pkl) - len(clipped_variates_df)} out of {len(variates_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_variates_df.isna().any(axis=1).sum()\n",
        "dataset_variates = clipped_variates_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")\n",
        "\n",
        "# Create 'year' column from timestamp\n",
        "dataset_variates['year'] = dataset_variates['timestamp'].astype(str).str[:4].astype(int)\n",
        "\n",
        "# Drop uneeded columns\n",
        "dataset_variates = dataset_variates.drop(columns=['elev_lowestmode','timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVVmgz2TXK9"
      },
      "outputs": [],
      "source": [
        "# Filter with TMF data\n",
        "filter_with_tmf = True\n",
        "\n",
        "dataset_variates_filtered = dataset_variates.copy()\n",
        "if filter_with_tmf:\n",
        "  # Create list of GEDI collection years\n",
        "  gedi_year_list = dataset_variates['year'].unique().tolist()\n",
        "  # Add year before first collection date to detect disturbance change\n",
        "  gedi_year_list.append(min(gedi_year_list) - 1)\n",
        "\n",
        "  # Filter non-forest and 'new changes' (with single pixel 8 connectedness edge) in the collection year\n",
        "  # The timing of the disturbance within the year (whether before or after collection) is not known from TMF data.\n",
        "  # These will also be excluded as predictors for training, as there's only a ~50 % chance the information is valid.\n",
        "  # The edge / disturbance data will be added to the previous year at the prediction stage to simulate its effect.\n",
        "  print(f\"There are {len(dataset_variates)} data points in the unfiltered dataset.\")\n",
        "\n",
        "  # Sample relevant forest and disturbance rasters\n",
        "  for year in gedi_year_list:\n",
        "    for predictor_type in ['forest_with_edge_effects', 'disturbance_with_edge_effects']:\n",
        "      predictor_path = join(edge_effects_dir, f\"{predictor_type}_{year}.tif\")\n",
        "      if not exists(predictor_path):\n",
        "        print(f\"{predictor_type}_{year}.tif does not exist, so GEDI data from this year have been removed.\")\n",
        "        dataset_variates_filtered = dataset_variates_filtered[dataset_variates_filtered['year'] != year]\n",
        "      else:\n",
        "        sample_raster_values(dataset_variates_filtered, predictor_path)\n",
        "\n",
        "  print(f\"{len(dataset_variates) - len(dataset_variates_filtered)} data points were dropped due to missing TMF years.\")\n",
        "\n",
        "  # Filter non-forest (negative values)\n",
        "  indices_to_filter_non_forest = []\n",
        "  for index, row in dataset_variates_filtered.iterrows():\n",
        "    if row[f\"forest_with_edge_effects_{row['year']}\"] < 0:\n",
        "      indices_to_filter_non_forest.append(index)\n",
        "  dataset_variates_filtered.drop(indices_to_filter_non_forest, inplace=True)\n",
        "  print(f\"{len(indices_to_filter_non_forest)} non-forest data points were dropped.\")\n",
        "\n",
        "  # Filter new disturbance with a 1 within a 1 pixel edge effect (between > -2 with 8-connectedness)\n",
        "  indices_to_filter_new_disturbance = []\n",
        "  for index, row in dataset_variates_filtered.iterrows():\n",
        "    if row[f\"disturbance_with_edge_effects_{row['year']}\"] > -2:\n",
        "      if row[f\"disturbance_with_edge_effects_{row['year'] -1}\"] <= -2:\n",
        "        indices_to_filter_new_disturbance.append(index)\n",
        "  dataset_variates_filtered.drop(indices_to_filter_new_disturbance, inplace=True)\n",
        "  print(f\"{len(indices_to_filter_new_disturbance)} 'new disturbance' data points were dropped.\")\n",
        "\n",
        "  # Filter new forest edge effects within 1 pixel (between 0 and 2 with 8-connectedness)\n",
        "  indices_to_filter_new_forest_edge = []\n",
        "  for index, row in dataset_variates_filtered.iterrows():\n",
        "    if row[f\"forest_with_edge_effects_{row['year']}\"] < 2:\n",
        "      if row[f\"disturbance_with_edge_effects_{row['year'] -1}\"] >= 2:\n",
        "        indices_to_filter_new_forest_edge.append(index)\n",
        "  dataset_variates_filtered.drop(indices_to_filter_new_forest_edge, inplace=True)\n",
        "  print(f\"{len(indices_to_filter_new_forest_edge)} 'new forest edge' data points were dropped.\")\n",
        "\n",
        "  print(f\"There are {len(dataset_variates_filtered)} data points remaining in the filtered dataset.\")\n",
        "\n",
        "  # Drop filtering columns\n",
        "  dataset_variates_filtered = dataset_variates_filtered.loc[:,~dataset_variates_filtered.columns.str.contains('forest|disturbance')].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gjrrhGFmCPp"
      },
      "outputs": [],
      "source": [
        "# Export to .pkl\n",
        "dataset_variates_path = join(datasets_var_dir, f'{dataset_name}.pkl')\n",
        "dataset_variates_filtered.to_pickle(dataset_variates_path)\n",
        "dataset_variates_filtered = pd.read_pickle(dataset_variates_path)\n",
        "print(f\"The GEDI AGBD dataset has been processed and exported to: {dataset_variates_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile uploaded CSV variates"
      ],
      "metadata": {
        "id": "0kmsuZmurPMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the GEDI .pkl with aboveground biomass density / ha ('agbd') data\n",
        "for pkl in os.listdir(variates_final_dir):\n",
        "    print(f\"variates_pkl = '{pkl}'\")"
      ],
      "metadata": {
        "id": "zMBHzsYRrfzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variates_pkl = 'GEDI02_A.pkl'\n",
        "\n",
        "variates_read_pkl = pd.read_pickle(join(variates_final_dir, variates_pkl))\n",
        "\n",
        "# Ensure all ppoints are in the training area\n",
        "project_area_polygon = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "variates_geodataframe = gpd.GeoDataFrame(variates_read_pkl, geometry='geometry')\n",
        "clipped_variates_gdf = gpd.clip(variates_geodataframe, project_area_polygon)\n",
        "clipped_variates_df = pd.DataFrame(clipped_variates_gdf)\n",
        "print(f\"{len(variates_read_pkl) - len(clipped_variates_df)} out of {len(variates_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_variates_df.isna().any(axis=1).sum()\n",
        "dataset_variates = clipped_variates_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")"
      ],
      "metadata": {
        "id": "IwNe2mqgrWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'rh_intact.pkl'\n",
        "\n",
        "# Export to .pkl\n",
        "dataset_variates_path = join(datasets_var_dir, dataset_name)\n",
        "dataset_variates.to_pickle(dataset_variates_path)\n",
        "dataset_variates = pd.read_pickle(dataset_variates_path)\n",
        "print(f\"The GEDI AGBD dataset has been processed and exported to: {dataset_variates_path}.\")"
      ],
      "metadata": {
        "id": "QX625nOeraCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p91jvg0TnJlh"
      },
      "source": [
        "# Add predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT44UjwpJcN3"
      },
      "source": [
        "WARNING: This will add all predictors in '\\3_predictors\\final' to the user training and validation datasets. Remove these files first if you only wish to move the datasets to the final folder for use in a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY6LwQ9IZRVE"
      },
      "outputs": [],
      "source": [
        "# Select the dataset variates .pkl to add predictors\n",
        "for pkl in os.listdir(datasets_var_dir):\n",
        "  if pkl.endswith('.pkl'):\n",
        "    print(f\"dataset_variates_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qvw-SiXQO9s"
      },
      "outputs": [],
      "source": [
        "dataset_variates_pkl = 'agbd.pkl'\n",
        "\n",
        "# Create list of predictors in 'final' directory\n",
        "predictor_list = []\n",
        "for predictor in os.listdir(predictor_final_dir):\n",
        "  predictor_list.append(predictor)\n",
        "\n",
        "# Select predictors to add to the dataset.\n",
        "# NOTE FOR CORRECTED ELEVATION:\n",
        "# Land-cover more recent than the base DEM shouldn't be used, as it's intended for discrepencies between the base surface data and GEDI terrain data.\n",
        "# In the case of Copernicus DEM, this is > 2014.\n",
        "# NOTE FOR AGBD:\n",
        "# Land-cover more recent than or the same year as the most recent GEDI data (e.g. 2022) will be removed at the finalisation stage.\n",
        "print('predictor_list = [')\n",
        "for predictor in sorted(predictor_list):\n",
        "  print(f\"'{predictor}',\")\n",
        "print(']')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNqEIFp4RQTx"
      },
      "outputs": [],
      "source": [
        "predictor_list = [\n",
        "'coast_proximity_km.tif',\n",
        "'disturbance_with_edge_effects_1990.tif',\n",
        "'disturbance_with_edge_effects_1991.tif',\n",
        "'disturbance_with_edge_effects_1992.tif',\n",
        "'disturbance_with_edge_effects_1993.tif',\n",
        "'disturbance_with_edge_effects_1994.tif',\n",
        "'disturbance_with_edge_effects_1995.tif',\n",
        "'disturbance_with_edge_effects_1996.tif',\n",
        "'disturbance_with_edge_effects_1997.tif',\n",
        "'disturbance_with_edge_effects_1998.tif',\n",
        "'disturbance_with_edge_effects_1999.tif',\n",
        "'disturbance_with_edge_effects_2000.tif',\n",
        "'disturbance_with_edge_effects_2001.tif',\n",
        "'disturbance_with_edge_effects_2002.tif',\n",
        "'disturbance_with_edge_effects_2003.tif',\n",
        "'disturbance_with_edge_effects_2004.tif',\n",
        "'disturbance_with_edge_effects_2005.tif',\n",
        "'disturbance_with_edge_effects_2006.tif',\n",
        "'disturbance_with_edge_effects_2007.tif',\n",
        "'disturbance_with_edge_effects_2008.tif',\n",
        "'disturbance_with_edge_effects_2009.tif',\n",
        "'disturbance_with_edge_effects_2010.tif',\n",
        "'disturbance_with_edge_effects_2011.tif',\n",
        "'disturbance_with_edge_effects_2012.tif',\n",
        "'disturbance_with_edge_effects_2013.tif',\n",
        "'disturbance_with_edge_effects_2014.tif',\n",
        "'disturbance_with_edge_effects_2015.tif',\n",
        "'disturbance_with_edge_effects_2016.tif',\n",
        "'disturbance_with_edge_effects_2017.tif',\n",
        "'disturbance_with_edge_effects_2018.tif',\n",
        "'disturbance_with_edge_effects_2019.tif',\n",
        "'disturbance_with_edge_effects_2020.tif',\n",
        "'disturbance_with_edge_effects_2021.tif',\n",
        "'disturbance_with_edge_effects_2022.tif',\n",
        "'disturbance_with_edge_effects_2023.tif',\n",
        "'forest_with_edge_effects_1990.tif',\n",
        "'forest_with_edge_effects_1991.tif',\n",
        "'forest_with_edge_effects_1992.tif',\n",
        "'forest_with_edge_effects_1993.tif',\n",
        "'forest_with_edge_effects_1994.tif',\n",
        "'forest_with_edge_effects_1995.tif',\n",
        "'forest_with_edge_effects_1996.tif',\n",
        "'forest_with_edge_effects_1997.tif',\n",
        "'forest_with_edge_effects_1998.tif',\n",
        "'forest_with_edge_effects_1999.tif',\n",
        "'forest_with_edge_effects_2000.tif',\n",
        "'forest_with_edge_effects_2001.tif',\n",
        "'forest_with_edge_effects_2002.tif',\n",
        "'forest_with_edge_effects_2003.tif',\n",
        "'forest_with_edge_effects_2004.tif',\n",
        "'forest_with_edge_effects_2005.tif',\n",
        "'forest_with_edge_effects_2006.tif',\n",
        "'forest_with_edge_effects_2007.tif',\n",
        "'forest_with_edge_effects_2008.tif',\n",
        "'forest_with_edge_effects_2009.tif',\n",
        "'forest_with_edge_effects_2010.tif',\n",
        "'forest_with_edge_effects_2011.tif',\n",
        "'forest_with_edge_effects_2012.tif',\n",
        "'forest_with_edge_effects_2013.tif',\n",
        "'forest_with_edge_effects_2014.tif',\n",
        "'forest_with_edge_effects_2015.tif',\n",
        "'forest_with_edge_effects_2016.tif',\n",
        "'forest_with_edge_effects_2017.tif',\n",
        "'forest_with_edge_effects_2018.tif',\n",
        "'forest_with_edge_effects_2019.tif',\n",
        "'forest_with_edge_effects_2020.tif',\n",
        "'forest_with_edge_effects_2021.tif',\n",
        "'forest_with_edge_effects_2022.tif',\n",
        "'forest_with_edge_effects_2023.tif',\n",
        "'latitude.tif',\n",
        "'longitude.tif',\n",
        "'lu_ais_with_edge_effects.tif',\n",
        "'lu_berkelah_jerantut_with_edge_effects.tif',\n",
        "'lu_berkelah_kuantan_with_edge_effects.tif',\n",
        "'lu_berkelah_temerloh_with_edge_effects.tif',\n",
        "'lu_pa_taman_negara_krau_with_edge_effects.tif',\n",
        "'lu_remen_chereh_with_edge_effects.tif',\n",
        "'lu_tekai_tembeling_with_edge_effects.tif',\n",
        "'lu_tekam_with_edge_effects.tif',\n",
        "'lu_yong_lipis_with_edge_effects.tif',\n",
        "'lu_yong_with_edge_effects.tif',\n",
        "'topo_cor_smooth_aspect_cosine.tif',\n",
        "'topo_cor_smooth_aspect_sine.tif',\n",
        "'topo_cor_smooth_circular_variance_aspect_03.tif',\n",
        "'topo_cor_smooth_circular_variance_aspect_07.tif',\n",
        "'topo_cor_smooth_circular_variance_aspect_11.tif',\n",
        "'topo_cor_smooth_deviation_mean_elevation_03.tif',\n",
        "'topo_cor_smooth_deviation_mean_elevation_07.tif',\n",
        "'topo_cor_smooth_deviation_mean_elevation_11.tif',\n",
        "'topo_cor_smooth_eastness.tif',\n",
        "'topo_cor_smooth_elevation.tif',\n",
        "'topo_cor_smooth_northness.tif',\n",
        "'topo_cor_smooth_profile_curvature.tif',\n",
        "'topo_cor_smooth_roughness_03.tif',\n",
        "'topo_cor_smooth_roughness_07.tif',\n",
        "'topo_cor_smooth_roughness_11.tif',\n",
        "'topo_cor_smooth_slope.tif',\n",
        "'topo_cor_smooth_stream_power_index_log10.tif',\n",
        "'topo_cor_smooth_surface_area_ratio.tif',\n",
        "'topo_cor_smooth_tangential_curvature.tif',\n",
        "'topo_cor_smooth_topographic_position_index_03.tif',\n",
        "'topo_cor_smooth_topographic_position_index_07.tif',\n",
        "'topo_cor_smooth_topographic_position_index_11.tif',\n",
        "'topo_cor_smooth_topographic_ruggedness_index.tif',\n",
        "'topo_cor_smooth_topographic_wetness_index.tif',\n",
        "'topo_cor_unsmooth_aspect_cosine.tif',\n",
        "'topo_cor_unsmooth_aspect_sine.tif',\n",
        "'topo_cor_unsmooth_circular_variance_aspect_03.tif',\n",
        "'topo_cor_unsmooth_circular_variance_aspect_07.tif',\n",
        "'topo_cor_unsmooth_circular_variance_aspect_11.tif',\n",
        "'topo_cor_unsmooth_deviation_mean_elevation_03.tif',\n",
        "'topo_cor_unsmooth_deviation_mean_elevation_07.tif',\n",
        "'topo_cor_unsmooth_deviation_mean_elevation_11.tif',\n",
        "'topo_cor_unsmooth_eastness.tif',\n",
        "'topo_cor_unsmooth_elevation.tif',\n",
        "'topo_cor_unsmooth_northness.tif',\n",
        "'topo_cor_unsmooth_profile_curvature.tif',\n",
        "'topo_cor_unsmooth_roughness_03.tif',\n",
        "'topo_cor_unsmooth_roughness_07.tif',\n",
        "'topo_cor_unsmooth_roughness_11.tif',\n",
        "'topo_cor_unsmooth_slope.tif',\n",
        "'topo_cor_unsmooth_stream_power_index_log10.tif',\n",
        "'topo_cor_unsmooth_surface_area_ratio.tif',\n",
        "'topo_cor_unsmooth_tangential_curvature.tif',\n",
        "'topo_cor_unsmooth_topographic_position_index_03.tif',\n",
        "'topo_cor_unsmooth_topographic_position_index_07.tif',\n",
        "'topo_cor_unsmooth_topographic_position_index_11.tif',\n",
        "'topo_cor_unsmooth_topographic_ruggedness_index.tif',\n",
        "'topo_cor_unsmooth_topographic_wetness_index.tif',\n",
        "# 'topo_uncor_smooth_aspect_cosine.tif',\n",
        "# 'topo_uncor_smooth_aspect_sine.tif',\n",
        "# 'topo_uncor_smooth_circular_variance_aspect_03.tif',\n",
        "# 'topo_uncor_smooth_circular_variance_aspect_07.tif',\n",
        "# 'topo_uncor_smooth_circular_variance_aspect_11.tif',\n",
        "# 'topo_uncor_smooth_deviation_mean_elevation_03.tif',\n",
        "# 'topo_uncor_smooth_deviation_mean_elevation_07.tif',\n",
        "# 'topo_uncor_smooth_deviation_mean_elevation_11.tif',\n",
        "# 'topo_uncor_smooth_eastness.tif',\n",
        "# 'topo_uncor_smooth_elevation.tif',\n",
        "# 'topo_uncor_smooth_northness.tif',\n",
        "# 'topo_uncor_smooth_profile_curvature.tif',\n",
        "# 'topo_uncor_smooth_roughness_03.tif',\n",
        "# 'topo_uncor_smooth_roughness_07.tif',\n",
        "# 'topo_uncor_smooth_roughness_11.tif',\n",
        "# 'topo_uncor_smooth_slope.tif',\n",
        "# 'topo_uncor_smooth_stream_power_index_log10.tif',\n",
        "# 'topo_uncor_smooth_surface_area_ratio.tif',\n",
        "# 'topo_uncor_smooth_tangential_curvature.tif',\n",
        "# 'topo_uncor_smooth_topographic_position_index_03.tif',\n",
        "# 'topo_uncor_smooth_topographic_position_index_07.tif',\n",
        "# 'topo_uncor_smooth_topographic_position_index_11.tif',\n",
        "# 'topo_uncor_smooth_topographic_ruggedness_index.tif',\n",
        "# 'topo_uncor_smooth_topographic_wetness_index.tif',\n",
        "# 'topo_uncor_unsmooth_aspect_cosine.tif',\n",
        "# 'topo_uncor_unsmooth_aspect_sine.tif',\n",
        "# 'topo_uncor_unsmooth_circular_variance_aspect_03.tif',\n",
        "# 'topo_uncor_unsmooth_circular_variance_aspect_07.tif',\n",
        "# 'topo_uncor_unsmooth_circular_variance_aspect_11.tif',\n",
        "# 'topo_uncor_unsmooth_deviation_mean_elevation_03.tif',\n",
        "# 'topo_uncor_unsmooth_deviation_mean_elevation_07.tif',\n",
        "# 'topo_uncor_unsmooth_deviation_mean_elevation_11.tif',\n",
        "# 'topo_uncor_unsmooth_eastness.tif',\n",
        "# 'topo_uncor_unsmooth_elevation.tif',\n",
        "# 'topo_uncor_unsmooth_northness.tif',\n",
        "# 'topo_uncor_unsmooth_profile_curvature.tif',\n",
        "# 'topo_uncor_unsmooth_roughness_03.tif',\n",
        "# 'topo_uncor_unsmooth_roughness_07.tif',\n",
        "# 'topo_uncor_unsmooth_roughness_11.tif',\n",
        "# 'topo_uncor_unsmooth_slope.tif',\n",
        "# 'topo_uncor_unsmooth_stream_power_index_log10.tif',\n",
        "# 'topo_uncor_unsmooth_surface_area_ratio.tif',\n",
        "# 'topo_uncor_unsmooth_tangential_curvature.tif',\n",
        "# 'topo_uncor_unsmooth_topographic_position_index_03.tif',\n",
        "# 'topo_uncor_unsmooth_topographic_position_index_07.tif',\n",
        "# 'topo_uncor_unsmooth_topographic_position_index_11.tif',\n",
        "# 'topo_uncor_unsmooth_topographic_ruggedness_index.tif',\n",
        "# 'topo_uncor_unsmooth_topographic_wetness_index.tif',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U57MrBw4b7PB"
      },
      "outputs": [],
      "source": [
        "cache = True\n",
        "\n",
        "dataset_variates_path = join(datasets_var_dir, dataset_variates_pkl)\n",
        "dataset_variates = pd.read_pickle(dataset_variates_path)\n",
        "dataset_add_pre_path = join(datasets_add_pre_dir, dataset_variates_pkl)\n",
        "\n",
        "# Handle caching\n",
        "if cache: print(\"Cache enabled.\")\n",
        "if not exists(dataset_add_pre_path):\n",
        "  dataset_variates.to_pickle(dataset_add_pre_path)\n",
        "  dataset_add_pre = pd.read_pickle(dataset_add_pre_path)\n",
        "else:\n",
        "  print(f\"An 'add predictors' dataset already exists: {dataset_add_pre_path}\")\n",
        "  if cache:\n",
        "    print(\"Continuing to add predictors to existing dataset. Delete it to start again.\")\n",
        "    dataset_add_pre = pd.read_pickle(dataset_add_pre_path)\n",
        "  else:\n",
        "    print(\"Cache disabled. The 'add predictors' dataset will be overwritten in 10 seconds (interrupt if unintended).\")\n",
        "    sleep(10)\n",
        "    dataset_variates.to_pickle(dataset_add_pre_path)\n",
        "    dataset_add_pre = pd.read_pickle(dataset_add_pre_path)\n",
        "\n",
        "# Predictor progress\n",
        "predictor_progress_index = 0\n",
        "predictor_progress_label = widgets.Label(f\"Predictor progress: {predictor_progress_index}/{len(predictor_list)}\")\n",
        "display(predictor_progress_label)\n",
        "\n",
        "for predictor in predictor_list:\n",
        "  if f\"pre_{predictor}\"[:-4] not in dataset_add_pre.columns:\n",
        "    # Read the backup if the last save was corrupted\n",
        "    if cache: dataset_add_pre = pd.read_pickle(dataset_add_pre_path)\n",
        "    # Sample raster values\n",
        "    predictor_path = join(predictor_final_dir, predictor)\n",
        "    sample_raster_values(dataset_add_pre, predictor_path, predictor=True)\n",
        "    # Save cached 'add_predictors' dataset if enabled\n",
        "    if cache:\n",
        "      dataset_add_pre_save = dataset_add_pre.copy() # Defragments the dataframe\n",
        "      dataset_add_pre_save.to_pickle(dataset_add_pre_path)\n",
        "  # Update predictor progress\n",
        "  predictor_progress_index += 1\n",
        "  predictor_progress_label.value = f\"Predictor progress: {predictor_progress_index}/{len(predictor_list)}\"\n",
        "\n",
        "# Export completed 'add predictors' dataset if no cache\n",
        "if not cache: dataset_add_pre.to_pickle(dataset_add_pre_path)\n",
        "\n",
        "print(f\"All predictors have been added to {dataset_add_pre_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s54en9tJWI_J"
      },
      "source": [
        "# Drop columns (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1nf5UUh2MyO"
      },
      "outputs": [],
      "source": [
        "# Select the 'add predictors' dataset to drop columns\n",
        "for pkl in os.listdir(datasets_add_pre_dir):\n",
        "  print(f\"dataset_drop_columns = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsaqSAELO2Wd"
      },
      "outputs": [],
      "source": [
        "add_pre_dataset_name = 'elevation_corrected.pkl'\n",
        "\n",
        "add_pre_dataset_path = join(datasets_add_pre_dir, add_pre_dataset_name)\n",
        "add_pre_dataset = pd.read_pickle(add_pre_dataset_path)\n",
        "\n",
        "# Inspect existing columns\n",
        "sorted(add_pre_dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_6EVMnNmtts"
      },
      "outputs": [],
      "source": [
        "drop_dataset_columns = True\n",
        "\n",
        "if drop_dataset_columns:\n",
        "  dropped_columns = 'longitude'\n",
        "  # Drop columns\n",
        "  dropped_columns_dataset = add_pre_dataset.loc[:,~add_pre_dataset.columns.str.contains(dropped_columns)]\n",
        "  dropped_columns_dataset.to_pickle(add_pre_dataset_path)\n",
        "  # Inspect columns again\n",
        "  add_pre_dataset = pd.read_pickle(add_pre_dataset_path)\n",
        "sorted(add_pre_dataset.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3qaR5lBnqmY"
      },
      "source": [
        "# Finalise GEDI corrected topography"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piV4j6Dtnsgy"
      },
      "outputs": [],
      "source": [
        "# Select the corrected elevation dataset to finalise.\n",
        "for pkl in os.listdir(datasets_add_pre_dir):\n",
        "    print(f'final_dataset_name = \"{pkl}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xilq4FkonwMi"
      },
      "outputs": [],
      "source": [
        "final_dataset_name = \"elevation_corrected.pkl\"\n",
        "\n",
        "final_dataset_path = join(datasets_add_pre_dir, final_dataset_name)\n",
        "final_dataset = pd.read_pickle(final_dataset_path)\n",
        "\n",
        "# Drop the geometry column and reset index\n",
        "final_dataset = final_dataset.drop(columns=['geometry'])\n",
        "\n",
        "# Add 'var_' prefix to non-predictors\n",
        "final_dataset.columns = ['var_' + col if not col.startswith('pre_') else col for col in final_dataset.columns]\n",
        "\n",
        "# Sort columns alphabetically\n",
        "variate_columns = [col for col in final_dataset.columns if col.startswith('var_')]\n",
        "predictor_columns = [col for col in final_dataset.columns if col.startswith('pre_')]\n",
        "sorted_columns = sorted(variate_columns) + sorted(predictor_columns)\n",
        "\n",
        "# Reindex the DataFrame with the sorted column order\n",
        "final_dataset = final_dataset.reindex(columns=sorted_columns)\n",
        "\n",
        "# Export and check final dataset\n",
        "final_dataset_path = join(datasets_final_dir, final_dataset_name)\n",
        "final_dataset.to_pickle(final_dataset_path)\n",
        "pd.read_pickle(final_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-l4ofcaD48"
      },
      "source": [
        "# Finalise GEDI vegetation indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDTqLPi37kmD"
      },
      "outputs": [],
      "source": [
        "# Select the corrected elevation dataset to finalise.\n",
        "for pkl in os.listdir(datasets_add_pre_dir):\n",
        "    print(f'final_dataset_name = \"{pkl}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_5HtJ7YCFj9"
      },
      "outputs": [],
      "source": [
        "final_dataset_name = \"agbd.pkl\"\n",
        "\n",
        "filter_with_tmf = True\n",
        "\n",
        "# load 'add predictors' dataset\n",
        "dataset_add_pre_path = join(datasets_add_pre_dir, final_dataset_name)\n",
        "dataset_add_pre = pd.read_pickle(dataset_add_pre_path)\n",
        "\n",
        "if filter_with_tmf:\n",
        "  # Define yearly predictors, add others if necessary (usually land-cover)\n",
        "  yearly_predictors = ['forest_with_edge_effects', 'disturbance_with_edge_effects']\n",
        "\n",
        "  # load 'add predictors' dataset columns\n",
        "  dataset_add_pre_column_list = sorted(dataset_add_pre.columns, reverse=True)\n",
        "\n",
        "  # Get list of GEDI years\n",
        "  gedi_year_list = dataset_add_pre['year'].unique().tolist()\n",
        "  gedi_year_list = [int(x) for x in gedi_year_list]\n",
        "  gedi_year_max = np.max(gedi_year_list)\n",
        "\n",
        "  # Create an index identifier\n",
        "  dataset_add_pre['index_record'] = dataset_add_pre.index\n",
        "\n",
        "  # Create an empty list for storing GEDI yearly sub-datasets\n",
        "  dataset_gedi_year_list = []\n",
        "\n",
        "  # Iterate through each GEDI year and shift the sample to appropriate predictor year\n",
        "  # Column names are kept the same to avoid issues when ordering features in model training/prediction\n",
        "  # However, e.g., a '2021' predictor for a 2022 GEDI point will actually be a 2019 predictor for a 2020 GEDI point\n",
        "  for gedi_year in gedi_year_list:\n",
        "      dataset_gedi_year = dataset_add_pre[dataset_add_pre['year'] == gedi_year].copy()\n",
        "      sample_year_modifier = gedi_year_max - gedi_year\n",
        "      for col in dataset_add_pre_column_list:\n",
        "          for yearly_predictor in yearly_predictors:\n",
        "              if yearly_predictor in col:\n",
        "                  predictor_year = int(col[-4:])\n",
        "                  original_sample = f\"pre_{yearly_predictor}_{str(predictor_year)}\"\n",
        "                  corrected_sample = f\"pre_{yearly_predictor}_{str(predictor_year + sample_year_modifier)}\"\n",
        "                  dataset_gedi_year.rename(columns={original_sample: corrected_sample}, inplace=True)\n",
        "      dataset_gedi_year_list.append(dataset_gedi_year)\n",
        "\n",
        "  # Concatenate dataframes and sort\n",
        "  final_dataset = pd.concat(dataset_gedi_year_list, ignore_index=True)\n",
        "  final_dataset.sort_values('index_record', inplace=True)\n",
        "  final_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  # Drop predictor years out of the data range for one of the GEDI years\n",
        "  final_dataset.dropna(axis=1, how='any', inplace=True)\n",
        "\n",
        "  # Drop predictors from the most recent GEDI collection year (as timing cannot be certain)\n",
        "  for yearly_predictor in yearly_predictors:\n",
        "    yearly_predictor_max = f\"pre_{yearly_predictor}_{str(gedi_year_max)}\"\n",
        "    for column in final_dataset.columns:\n",
        "      if column == yearly_predictor_max:\n",
        "        final_dataset.drop(columns=[yearly_predictor_max], inplace=True)\n",
        "\n",
        "  # Drop the index identifier\n",
        "  final_dataset.drop(columns=['index_record'], inplace=True)\n",
        "\n",
        "else: final_dataset = dataset_add_pre.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsh_FxdHCD0J"
      },
      "outputs": [],
      "source": [
        "# Add 'var_' prefix to non-predictors\n",
        "final_dataset.columns = ['var_' + col if not col.startswith('pre_') else col for col in final_dataset.columns]\n",
        "\n",
        "# Sort columns alphabetically\n",
        "variate_columns = [col for col in final_dataset.columns if col.startswith('var_')]\n",
        "predictor_columns = [col for col in final_dataset.columns if col.startswith('pre_')]\n",
        "sorted_columns = sorted(variate_columns) + sorted(predictor_columns)\n",
        "\n",
        "# Reindex the DataFrame with the sorted column order\n",
        "final_dataset = final_dataset.reindex(columns=sorted_columns)\n",
        "\n",
        "# Export and check final dataset\n",
        "final_dataset_path = join(datasets_final_dir, final_dataset_name)\n",
        "final_dataset.to_pickle(final_dataset_path)\n",
        "pd.read_pickle(final_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalise uploaded CSV dataset"
      ],
      "metadata": {
        "id": "VIy7eJdEuIoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the corrected elevation dataset to finalise.\n",
        "for pkl in os.listdir(datasets_add_pre_dir):\n",
        "    print(f'final_dataset_name = \"{pkl}\"')"
      ],
      "metadata": {
        "id": "DgLJwk5ZuM04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_name = \"rh_intact.pkl\"\n",
        "\n",
        "# load 'add predictors' dataset\n",
        "dataset_add_pre_path = join(datasets_add_pre_dir, final_dataset_name)\n",
        "final_dataset = pd.read_pickle(dataset_add_pre_path)\n",
        "\n",
        "# Add 'var_' prefix to non-predictors\n",
        "final_dataset.columns = ['var_' + col if not col.startswith('pre_') else col for col in final_dataset.columns]\n",
        "\n",
        "# Sort columns alphabetically\n",
        "variate_columns = [col for col in final_dataset.columns if col.startswith('var_')]\n",
        "predictor_columns = [col for col in final_dataset.columns if col.startswith('pre_')]\n",
        "sorted_columns = sorted(variate_columns) + sorted(predictor_columns)\n",
        "\n",
        "# Reindex the DataFrame with the sorted column order\n",
        "final_dataset = final_dataset.reindex(columns=sorted_columns)\n",
        "\n",
        "# Export and check final dataset\n",
        "final_dataset_path = join(datasets_final_dir, final_dataset_name)\n",
        "final_dataset.to_pickle(final_dataset_path)\n",
        "pd.read_pickle(final_dataset_path)"
      ],
      "metadata": {
        "id": "RRbJJC4SuTdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM3XltPTYK_F"
      },
      "source": [
        "# Export to .gpkg (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLKmYPoVYZGt"
      },
      "outputs": [],
      "source": [
        "# Select the dataset .pkl to export as a .gpkg\n",
        "for pkl in os.listdir(datasets_final_dir):\n",
        "  print(f'dataset_gpkg_name = \"{pkl}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfMwAOY1Y8v4"
      },
      "outputs": [],
      "source": [
        "dataset_gpkg_name = \"agbd.pkl\"\n",
        "\n",
        "dataset_gpkg_pkl_path = join(datasets_add_pre_dir, dataset_gpkg_name)\n",
        "dataset_gpkg_pkl = pd.read_pickle(dataset_gpkg_pkl_path)\n",
        "\n",
        "# Print columns that can be included\n",
        "print(\"selected_gpkg_columns = [\")\n",
        "for col in sorted(dataset_gpkg_pkl.columns):\n",
        "  if col != \"geometry\":\n",
        "    print(f'  \"{col}\",')\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saC1b9Aibv_j"
      },
      "outputs": [],
      "source": [
        "selected_gpkg_columns = [\n",
        "  \"agbd\",\n",
        "  \"beam\",\n",
        "  \"pre_topo_cor_unsmooth_elevation\",\n",
        "  \"shot_number\",\n",
        "]\n",
        "\n",
        "selected_gpkg_columns = selected_gpkg_columns + ['geometry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06atJbnEaE8x"
      },
      "outputs": [],
      "source": [
        "dataset_gpkg_geodataframe = gpd.GeoDataFrame(dataset_gpkg_pkl[selected_gpkg_columns], geometry='geometry')\n",
        "\n",
        "dataset_gpkg_export = join(datasets_gpkg_dir, f\"{dataset_gpkg_name[:-4]}.gpkg\")\n",
        "dataset_gpkg_geodataframe.to_file(dataset_gpkg_export, driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FJKCE5qpJYZ"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHgZy_mxjvjD"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SFua9JVxZ-67",
        "0kmsuZmurPMY",
        "s54en9tJWI_J",
        "O3qaR5lBnqmY",
        "Ni-l4ofcaD48",
        "VIy7eJdEuIoK",
        "dM3XltPTYK_F"
      ],
      "gpuType": "V28",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}