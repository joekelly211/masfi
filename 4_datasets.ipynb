{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/main/4_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mdTQzOHb9Ra"
      },
      "source": [
        "# Imports, directories and global functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpxFKWdWVgX6"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "# Use '/content/drive/MyDrive/' for a personal drive\n",
        "# Use '/gdrive/Shareddrives/' for a shared drive (must be created first)\n",
        "\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "# base_dir = '/content/drive/MyDrive/masfi'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "if base_dir.startswith('/gdrive/Shareddrives/'):\n",
        "  drive.mount('/gdrive', force_remount=True)\n",
        "elif base_dir.startswith('/content/drive/MyDrive/'):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "else: print(\"Create a base_dir beginning with '/gdrive/Shareddrives/' or '/content/drive/MyDrive/'.\")\n",
        "\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "eAPopw3StVzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRFq9zEQr2C8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import makedirs\n",
        "from os.path import exists, join\n",
        "from osgeo import gdal\n",
        "gdal.UseExceptions()\n",
        "import pandas as pd\n",
        "import requests\n",
        "from scipy.stats import norm\n",
        "from shutil import copyfile, move\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHEzVXynr6SN"
      },
      "outputs": [],
      "source": [
        "# 1_areas directories\n",
        "areas_dir = join(base_dir, '1_areas')\n",
        "polygons_dir = join(areas_dir, 'polygons')\n",
        "template_dir = join(areas_dir, \"template.tif\")\n",
        "\n",
        "# 2_targets directories\n",
        "targets_final_dir = join(base_dir, \"2_targets/pkl_final\")\n",
        "\n",
        "# 3_features directories\n",
        "features_dir = join(base_dir, \"3_features\")\n",
        "alpha_earth_dir = join(features_dir, \"alpha_earth\")\n",
        "edge_effects_dir = join(features_dir, \"binary_edge_effects\")\n",
        "continuous_final_dir = join(features_dir, \"continuous_final\")\n",
        "topo_dsm_final_dir = join(features_dir, \"topo_dsm_final\")\n",
        "topo_dtm_final_dir = join(features_dir, \"topo_dtm_final\")\n",
        "coast_dir = join(features_dir, 'coast')\n",
        "feature_final_dir = join(features_dir, \"final\")\n",
        "\n",
        "# 4_datasets directories\n",
        "datasets_dir = join(base_dir, \"4_datasets\")\n",
        "datasets_tar_dir = join(datasets_dir, \"targets\")\n",
        "datasets_add_fea_dir = join(datasets_dir, \"add_features\")\n",
        "datasets_final_dir = join(datasets_dir, \"final\")\n",
        "datasets_gpkg_dir = join(datasets_dir, \"gpkg\")\n",
        "\n",
        "# Create directories\n",
        "makedirs(feature_final_dir, exist_ok=True)\n",
        "makedirs(datasets_dir, exist_ok=True)\n",
        "makedirs(datasets_tar_dir, exist_ok=True)\n",
        "makedirs(datasets_add_fea_dir, exist_ok=True)\n",
        "makedirs(datasets_final_dir, exist_ok=True)\n",
        "makedirs(datasets_gpkg_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_lgjEC_LoRZ"
      },
      "outputs": [],
      "source": [
        "# Global function: export an array as a .tif\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "nodatavalue = -11111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_tif_path, nodatavalue=nodatavalue, compress=compress, dtype=gdal.GDT_Float32):\n",
        "    template_ds = gdal.Open(template)\n",
        "    template_band = template_ds.GetRasterBand(1)\n",
        "    template_dimensions, template_projection = template_ds.GetGeoTransform(), template_ds.GetProjection()\n",
        "    if compress: options = ['COMPRESS=ZSTD', 'ZSTD_LEVEL=1'] # Good speed / size ratio\n",
        "    else: options = []\n",
        "    if input_array.dtype == 'int16': dtype = gdal.GDT_Int16\n",
        "    driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, 1, dtype, options=options)\n",
        "    driver.GetRasterBand(1).WriteArray(input_array)\n",
        "    driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "    driver.SetGeoTransform(template_dimensions)\n",
        "    driver.SetProjection(template_projection)\n",
        "    template_ds = driver = None\n",
        "\n",
        "# Global function: sample raster values\n",
        "def sample_raster_values(pd_dataframe, raster_path, feature=False, geometry_column='geometry'):\n",
        "    raster_name = raster_path.split('/')[-1][:-4]\n",
        "    if feature: raster_name = 'fea_' + raster_name\n",
        "    raster = gdal.Open(raster_path)\n",
        "    band = raster.GetRasterBand(1)\n",
        "    geotransform = raster.GetGeoTransform()\n",
        "    raster_array = band.ReadAsArray()\n",
        "    nodata = band.GetNoDataValue()\n",
        "    rows, cols = raster_array.shape\n",
        "    sampled_values = []\n",
        "    for geom in pd_dataframe[geometry_column]:\n",
        "        x_idx = int((geom.x - geotransform[0]) / geotransform[1])\n",
        "        y_idx = int((geom.y - geotransform[3]) / geotransform[5])\n",
        "        # bounds check\n",
        "        if 0 <= x_idx < cols and 0 <= y_idx < rows: sampled_values.append(raster_array[y_idx, x_idx])\n",
        "        else: sampled_values.append(nodata if nodata is not None else np.nan)\n",
        "    pd_dataframe[raster_name] = sampled_values\n",
        "    raster = band = None\n",
        "\n",
        "# Global function: histogram-based density outlier bounds\n",
        "# Filters sparse regions at distribution extremes based on bin counts\n",
        "# Dense regions kept regardless of distance from median, only isolated tail values flagged\n",
        "def histogram_outlier_bounds(data, title, sparse_threshold_percent=0.01):\n",
        "    min_bin_count = max(10, int(len(data) * sparse_threshold_percent / 100))\n",
        "    counts, bin_edges = np.histogram(data, bins='auto')\n",
        "    # Scan inward from each tail until a dense bin is found\n",
        "    first_dense_bin = next(i for i, c in enumerate(counts) if c >= min_bin_count)\n",
        "    last_dense_bin = next(i for i, c in enumerate(reversed(counts)) if c >= min_bin_count)\n",
        "    last_dense_bin = len(counts) - 1 - last_dense_bin\n",
        "    # Bounds from dense bin edges\n",
        "    lower_bound = bin_edges[first_dense_bin]\n",
        "    upper_bound = bin_edges[last_dense_bin + 1]\n",
        "    # Count filtered points\n",
        "    n_below_lower = np.sum(data < lower_bound)\n",
        "    n_above_upper = np.sum(data > upper_bound)\n",
        "    n_remaining = len(data) - n_below_lower - n_above_upper\n",
        "    # Plot distribution with bounds\n",
        "    random_selection = np.random.choice(data, size=min(100_000, len(data)), replace=False)\n",
        "    plt.hist(random_selection, bins='auto')\n",
        "    plt.axvline(lower_bound, color='red', linestyle='--', label=f'Lower: {lower_bound:.1f}')\n",
        "    plt.axvline(upper_bound, color='red', linestyle='--', label=f'Upper: {upper_bound:.1f}')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(f\"Histogram density bounds (tails only): [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
        "    print(f\"Filtered below lower bound: {n_below_lower:,}\")\n",
        "    print(f\"Filtered above upper bound: {n_above_upper:,}\")\n",
        "    print(f\"Remaining points: {n_remaining:,} out of {len(data):,} ({100 * (1 - n_remaining / len(data)):.2f}% removed)\")\n",
        "    return lower_bound, upper_bound"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalise targets"
      ],
      "metadata": {
        "id": "v_FDzLXc5EAd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bboEe-LBXVCQ"
      },
      "source": [
        "## GEDI elevation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvz5wSeDXUf7"
      },
      "outputs": [],
      "source": [
        "# GEDI DTM (Digital Terrain Model) dataset preparation\n",
        "\n",
        "# GEDI elev_lowestmode is WGS84 ellipsoidal height\n",
        "# Copernicus DEM is EGM2008 orthometric height\n",
        "# Geoid correction applied: H = h - N (ellipsoidal to orthometric)\n",
        "\n",
        "# Outlier filtering compares Geoid corrected GEDI elevation to Copernicus DSM\n",
        "# GEDI typically lower than DSM in forest (ground vs canopy surface)\n",
        "# Extreme differences indicate measurement error or cloud contamination\n",
        "\n",
        "# Download EGM2008 geoid model\n",
        "earth_gravitational_model_url = 'https://download.agisoft.com/gtg/us_nga_egm2008_1.tif'\n",
        "earth_gravitational_model_path = join(datasets_tar_dir, 'earth_gravitational_model.tif')\n",
        "if not exists(earth_gravitational_model_path):\n",
        "  request = requests.get(earth_gravitational_model_url, allow_redirects=True)\n",
        "  open(earth_gravitational_model_path, 'wb').write(request.content)\n",
        "  print(f'EGM raster downloaded to: {earth_gravitational_model_path}')\n",
        "else: print(f'EGM raster already exists at: {earth_gravitational_model_path}')\n",
        "\n",
        "# Select GEDI .pkl containing elev_lowestmode\n",
        "for pkl in os.listdir(targets_final_dir):\n",
        "    print(f\"targets_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy8BrS2gihA-"
      },
      "outputs": [],
      "source": [
        "targets_pkl = 'GEDI04_A.pkl'\n",
        "\n",
        "# Use the rectangular GEDI area extent, instead of the potentially complex project area\n",
        "use_gedi_area_polygon = True\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "histogram_based_outlier_filtering = True\n",
        "# Bins with fewer than this percentage of total data are considered sparse\n",
        "sparse_threshold_percent = 0.01\n",
        "\n",
        "targets_read_pkl = pd.read_pickle(join(targets_final_dir, targets_pkl))\n",
        "\n",
        "# Ensure all points are in the training area\n",
        "if use_gedi_area_polygon: project_area_polygon = gpd.read_file(join(polygons_dir, 'gedi_area.gpkg'))\n",
        "else: project_area_polygon = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "targets_geodataframe = gpd.GeoDataFrame(targets_read_pkl, geometry='geometry')\n",
        "clipped_targets_gdf = gpd.clip(targets_geodataframe, project_area_polygon)\n",
        "clipped_targets_df = pd.DataFrame(clipped_targets_gdf)\n",
        "print(f\"{len(targets_read_pkl) - len(clipped_targets_df)} out of {len(targets_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_targets_df.isna().any(axis=1).sum()\n",
        "dataset_targets = clipped_targets_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")\n",
        "columns_to_keep = ['shot_number','beam','geometry','elev_lowestmode','sensitivity']\n",
        "dataset_targets = dataset_targets[[col for col in columns_to_keep if col in dataset_targets.columns]]\n",
        "\n",
        "# Sample EGM values\n",
        "sample_raster_values(dataset_targets, earth_gravitational_model_path)\n",
        "dataset_targets['gedi_elevation'] = dataset_targets['elev_lowestmode'] - dataset_targets['earth_gravitational_model']\n",
        "\n",
        "# Sample base DEM values\n",
        "base_dem_path = join(areas_dir, 'base_dem_dsm.tif')\n",
        "sample_raster_values(dataset_targets, base_dem_path)\n",
        "\n",
        "# Calculate elevation difference\n",
        "dataset_targets['gedi_elevation_diff'] = dataset_targets['gedi_elevation'] - dataset_targets['base_dem_dsm']\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "if histogram_based_outlier_filtering:\n",
        "  elevation_diff_lower_bound, elevation_diff_upper_bound = histogram_outlier_bounds(\n",
        "      np.array(dataset_targets['gedi_elevation_diff']),\n",
        "      title=\"GEDI âˆ’ Base DEM elevation\",\n",
        "      sparse_threshold_percent=sparse_threshold_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDBFHtS8lFF_"
      },
      "outputs": [],
      "source": [
        "# Manual override if histogram bounds are unsuitable\n",
        "override_bounds = False\n",
        "if override_bounds: elevation_diff_lower_bound, elevation_diff_upper_bound = -50, 5\n",
        "\n",
        "dataset_targets_filtered = dataset_targets[(dataset_targets['gedi_elevation_diff'] >= elevation_diff_lower_bound) & (dataset_targets['gedi_elevation_diff'] <= elevation_diff_upper_bound)]\n",
        "# Drop correction and filtering columns\n",
        "dataset_targets_filtered = dataset_targets_filtered.drop(columns=['elev_lowestmode','earth_gravitational_model','base_dem_dsm','gedi_elevation_diff'])\n",
        "\n",
        "# Export to .pkl\n",
        "dataset_targets_path = join(datasets_tar_dir, 'gedi_elevation.pkl')\n",
        "dataset_targets_filtered.to_pickle(dataset_targets_path)\n",
        "dataset_targets_filtered = pd.read_pickle(dataset_targets_path)\n",
        "print(f\"The GEDI elevation dataset has been processed and exported to: {dataset_targets_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFua9JVxZ-67"
      },
      "source": [
        "## GEDI vegetation indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K5cvW9baXDS"
      },
      "outputs": [],
      "source": [
        "# Select the GEDI .pkl with the desired vegetation index (e.g. 'agbd')\n",
        "for pkl in os.listdir(targets_final_dir):\n",
        "    print(f\"targets_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hju0dyR_YzK"
      },
      "outputs": [],
      "source": [
        "targets_pkl = 'GEDI04_A.pkl'\n",
        "dataset_name = 'agbd'\n",
        "\n",
        "# Use the rectangular GEDI area extent, instead of the potentially complex project area\n",
        "use_gedi_area_polygon = True\n",
        "\n",
        "targets_read_pkl = pd.read_pickle(join(targets_final_dir, targets_pkl))\n",
        "\n",
        "# Ensure all points are in the training area\n",
        "if use_gedi_area_polygon: project_area_polygon = gpd.read_file(join(polygons_dir, 'gedi_area.gpkg'))\n",
        "else: project_area_polygon = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "targets_geodataframe = gpd.GeoDataFrame(targets_read_pkl, geometry='geometry')\n",
        "clipped_targets_gdf = gpd.clip(targets_geodataframe, project_area_polygon)\n",
        "clipped_targets_df = pd.DataFrame(clipped_targets_gdf)\n",
        "print(f\"{len(targets_read_pkl) - len(clipped_targets_df)} out of {len(targets_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_targets_df.isna().any(axis=1).sum()\n",
        "dataset_targets = clipped_targets_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")\n",
        "\n",
        "# Create 'year' column from timestamp\n",
        "dataset_targets['year'] = dataset_targets['timestamp'].astype(str).str[:4].astype(int)\n",
        "\n",
        "# Drop uneeded columns\n",
        "dataset_targets = dataset_targets.drop(columns=['elev_lowestmode','timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVVmgz2TXK9"
      },
      "outputs": [],
      "source": [
        "# Filter with TMF data\n",
        "# Filter non-forest and 'new changes' in the collection year\n",
        "# TMF provides annual disturbance,  sub-annual timing relative to GEDI collection is unknown\n",
        "# Points with same-year land-cover changes excluded due to temporal ambiguity\n",
        "# Predictions use the previous year's disturbance state (Dec 31st of year prior to prediction)\n",
        "filter_with_tmf = True\n",
        "\n",
        "# Distance threshold in metres for edge effect filtering\n",
        "# Ecological edge effects take several years to appear\n",
        "# Threshold mainly accounts for GEDI footprint geolocation inaccuracy\n",
        "edge_distance_threshold = 30\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "histogram_based_outlier_filtering = True\n",
        "# Bins with fewer than this percentage of total data are considered sparse\n",
        "sparse_threshold_percent = 0.01\n",
        "\n",
        "dataset_targets_filtered = dataset_targets.copy()\n",
        "\n",
        "if filter_with_tmf:\n",
        "    gedi_year_list = dataset_targets['year'].unique().tolist()\n",
        "    gedi_year_list.append(min(gedi_year_list) - 1)\n",
        "    print(f\"There are {len(dataset_targets)} data points in the unfiltered dataset.\")\n",
        "\n",
        "    # Sample relevant forest and disturbance rasters\n",
        "    for year in gedi_year_list:\n",
        "        for feature_type in ['forest_edge_distance', 'disturbance_edge_distance']:\n",
        "            feature_path = join(edge_effects_dir, f\"{feature_type}_{year}.tif\")\n",
        "            if not exists(feature_path):\n",
        "                print(f\"{feature_type}_{year}.tif does not exist, so GEDI data from this year have been removed.\")\n",
        "                dataset_targets_filtered = dataset_targets_filtered[dataset_targets_filtered['year'] != year]\n",
        "            else: sample_raster_values(dataset_targets_filtered, feature_path)\n",
        "    print(f\"{len(dataset_targets) - len(dataset_targets_filtered)} data points were dropped due to missing TMF years.\")\n",
        "\n",
        "    # Filter non-forest (negative edge_distance = outside forest class)\n",
        "    indices_to_filter_non_forest = []\n",
        "    for index, row in dataset_targets_filtered.iterrows():\n",
        "        if row[f\"forest_edge_distance_{row['year']}\"] < 0:\n",
        "            indices_to_filter_non_forest.append(index)\n",
        "    dataset_targets_filtered.drop(indices_to_filter_non_forest, inplace=True)\n",
        "    print(f\"{len(indices_to_filter_non_forest)} non-forest data points were dropped.\")\n",
        "\n",
        "    # Filter new disturbance within threshold distance of disturbance edge\n",
        "    # Positive or small negative edge_distance = close to or inside disturbance\n",
        "    indices_to_filter_new_disturbance = []\n",
        "    for index, row in dataset_targets_filtered.iterrows():\n",
        "        if row[f\"disturbance_edge_distance_{row['year']}\"] >= -edge_distance_threshold:\n",
        "            if row[f\"disturbance_edge_distance_{row['year'] -1}\"] < -edge_distance_threshold:\n",
        "                indices_to_filter_new_disturbance.append(index)\n",
        "    dataset_targets_filtered.drop(indices_to_filter_new_disturbance, inplace=True)\n",
        "    print(f\"{len(indices_to_filter_new_disturbance)} 'new disturbance' data points were dropped.\")\n",
        "\n",
        "    # Filter new forest edge effects within threshold distance of forest edge\n",
        "    # Small positive edge_distance = near forest edge (interior side)\n",
        "    indices_to_filter_new_forest_edge = []\n",
        "    for index, row in dataset_targets_filtered.iterrows():\n",
        "        if row[f\"forest_edge_distance_{row['year']}\"] <= edge_distance_threshold:\n",
        "            if row[f\"forest_edge_distance_{row['year'] -1}\"] > edge_distance_threshold:\n",
        "                indices_to_filter_new_forest_edge.append(index)\n",
        "    dataset_targets_filtered.drop(indices_to_filter_new_forest_edge, inplace=True)\n",
        "    print(f\"{len(indices_to_filter_new_forest_edge)} 'new forest edge' data points were dropped.\")\n",
        "    print(f\"There are {len(dataset_targets_filtered)} data points remaining in the filtered dataset.\")\n",
        "\n",
        "    # Drop filtering columns\n",
        "    dataset_targets_filtered = dataset_targets_filtered.loc[:,~dataset_targets_filtered.columns.str.contains(\n",
        "        'forest_edge_distance|disturbance_edge_distance')].reset_index(drop=True)\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "if histogram_based_outlier_filtering:\n",
        "  vegetation_lower_bound, vegetation_upper_bound = histogram_outlier_bounds(\n",
        "      np.array(dataset_targets_filtered[dataset_name]),\n",
        "      title=f\"GEDI {dataset_name.upper()} distribution\",\n",
        "      sparse_threshold_percent=sparse_threshold_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gjrrhGFmCPp"
      },
      "outputs": [],
      "source": [
        "# Manual override if histogram bounds are unsuitable\n",
        "override_bounds = False\n",
        "if override_bounds: vegetation_lower_bound, vegetation_upper_bound = 0, 800\n",
        "\n",
        "# Apply bounds\n",
        "dataset_targets_filtered = dataset_targets_filtered[\n",
        "    (dataset_targets_filtered[dataset_name] >= vegetation_lower_bound) &\n",
        "    (dataset_targets_filtered[dataset_name] <= vegetation_upper_bound)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Export to .pkl\n",
        "dataset_targets_path = join(datasets_tar_dir, f'{dataset_name}.pkl')\n",
        "dataset_targets_filtered.to_pickle(dataset_targets_path)\n",
        "dataset_targets_filtered = pd.read_pickle(dataset_targets_path)\n",
        "print(f\"The GEDI {dataset_name.upper()} dataset has been processed and exported to: {dataset_targets_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploaded data"
      ],
      "metadata": {
        "id": "0kmsuZmurPMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the uploaded target dataset to compile\n",
        "for pkl in os.listdir(targets_final_dir):\n",
        "    print(f\"targets_pkl = '{pkl}'\")"
      ],
      "metadata": {
        "id": "zMBHzsYRrfzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_pkl = 'user_upload.pkl'\n",
        "\n",
        "# Name of target column for outlier filtering\n",
        "target_column = 'target'\n",
        "\n",
        "# Use the rectangular GEDI area extent, instead of the potentially complex project area\n",
        "use_gedi_area_polygon = True\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "histogram_based_outlier_filtering = True\n",
        "# Bins with fewer than this percentage of total data are considered sparse\n",
        "sparse_threshold_percent = 0.01\n",
        "\n",
        "targets_read_pkl = pd.read_pickle(join(targets_final_dir, targets_pkl))\n",
        "\n",
        "# Ensure all points are in the training area\n",
        "if use_gedi_area_polygon: project_area_polygon = gpd.read_file(join(polygons_dir, 'gedi_area.gpkg'))\n",
        "else: project_area_polygon = gpd.read_file(join(polygons_dir, 'project_area.gpkg'))\n",
        "targets_geodataframe = gpd.GeoDataFrame(targets_read_pkl, geometry='geometry')\n",
        "clipped_targets_gdf = gpd.clip(targets_geodataframe, project_area_polygon)\n",
        "clipped_targets_df = pd.DataFrame(clipped_targets_gdf)\n",
        "print(f\"{len(targets_read_pkl) - len(clipped_targets_df)} out of {len(targets_read_pkl)} data points were outside the training area and removed.\")\n",
        "\n",
        "# Drop NA values, if any\n",
        "dataset_na_values = clipped_targets_df.isna().any(axis=1).sum()\n",
        "dataset_targets = clipped_targets_df.dropna().reset_index(drop=True)\n",
        "print(f\"{dataset_na_values} data points had NA values and were removed.\")\n",
        "\n",
        "# Histogram-based outlier filtering\n",
        "if histogram_based_outlier_filtering:\n",
        "    target_lower_bound, target_upper_bound = histogram_outlier_bounds(\n",
        "        np.array(dataset_targets[target_column]),\n",
        "        title=f\"{target_column} distribution\",\n",
        "        sparse_threshold_percent=sparse_threshold_percent)"
      ],
      "metadata": {
        "id": "IwNe2mqgrWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'user_upload'\n",
        "\n",
        "# Manual override if histogram bounds are unsuitable\n",
        "override_bounds = False\n",
        "if override_bounds: target_lower_bound, target_upper_bound = 0, 100\n",
        "\n",
        "# Apply bounds\n",
        "if histogram_based_outlier_filtering:\n",
        "    dataset_targets = dataset_targets[\n",
        "        (dataset_targets[target_column] >= target_lower_bound) &\n",
        "        (dataset_targets[target_column] <= target_upper_bound)\n",
        "    ].reset_index(drop=True)\n",
        "    print(f\"{len(dataset_targets)} data points remaining after outlier filtering.\")\n",
        "\n",
        "# Export to .pkl\n",
        "dataset_targets_path = join(datasets_tar_dir, f'{dataset_name}.pkl')\n",
        "dataset_targets.to_pickle(dataset_targets_path)\n",
        "dataset_targets = pd.read_pickle(dataset_targets_path)\n",
        "print(f\"The {dataset_name} dataset has been processed and exported to: {dataset_targets_path}.\")"
      ],
      "metadata": {
        "id": "QX625nOeraCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalise features"
      ],
      "metadata": {
        "id": "DkcwIQ7npXLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Round latitude and longitude rasters and finalise\n",
        "# These help account for ecological spatial patterns we do not have feature rasters for.\n",
        "# Precision should strike a balance between accuracy and overfitting/model training time\n",
        "precision = 3 # 3 is equivalent to a precision of ~111 m at the equator, i.e. every three to four 30 m pixels\n",
        "coordinates = ['latitude.tif', 'longitude.tif']\n",
        "for coordinate in coordinates:\n",
        "  coordinate_path = join(areas_dir, coordinate)\n",
        "  coordinate_rounded_path = join(feature_final_dir, coordinate)\n",
        "  if not exists(coordinate_rounded_path):\n",
        "    coordinate_array = gdal.Open(coordinate_path).ReadAsArray()\n",
        "    coordinate_array_round = np.round(coordinate_array, precision)\n",
        "    export_array_as_tif(coordinate_array_round, coordinate_rounded_path)\n",
        "    print(f\"{coordinate} has been rounded and exported to {feature_final_dir}\")\n",
        "  else: print(f\"{coordinate} already exists in {feature_final_dir}\")"
      ],
      "metadata": {
        "id": "8Hswr5edpZgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_alpha_earth_features = False\n",
        "\n",
        "# Compile and verify final feature list\n",
        "feature_list = []\n",
        "\n",
        "# Add Alpha Earth features if enabled\n",
        "if use_alpha_earth_features:\n",
        "  for feature in os.listdir(alpha_earth_dir): feature_list.append(join(alpha_earth_dir, feature))\n",
        "else:\n",
        "  # Add DSM topographic features\n",
        "  for feature in os.listdir(topo_dsm_final_dir): feature_list.append(join(topo_dsm_final_dir, feature))\n",
        "  # Add DTM topographic features, if they exist\n",
        "  if exists(topo_dtm_final_dir):\n",
        "    for feature in os.listdir(topo_dtm_final_dir): feature_list.append(join(topo_dtm_final_dir, feature))\n",
        "  # Add coast proximity if it exists\n",
        "  cost_proximity_path = join(coast_dir,'coast_proximity_km.tif')\n",
        "  if exists(cost_proximity_path): feature_list.append(cost_proximity_path)\n",
        "  # Add LCLUC continuous features\n",
        "  for feature in os.listdir(continuous_final_dir): feature_list.append(join(continuous_final_dir, feature))\n",
        "  # Add LCLUC binary edge effect features\n",
        "  for feature in os.listdir(edge_effects_dir): feature_list.append(join(edge_effects_dir, feature))\n",
        "\n",
        "feature_list = sorted(feature_list)\n",
        "\n",
        "print(\"feature_list = [\")\n",
        "for feature in feature_list:\n",
        "  print(f\"'{feature.split('/')[-2]}/{feature.split('/')[-1][:-4]}',\")\n",
        "print(']')"
      ],
      "metadata": {
        "id": "DiE5HJHKpeiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = [\n",
        "'binary_edge_effects/disturbance_edge_distance_1990',\n",
        "'binary_edge_effects/disturbance_edge_distance_1991',\n",
        "'binary_edge_effects/disturbance_edge_distance_1992',\n",
        "'binary_edge_effects/disturbance_edge_distance_1993',\n",
        "'binary_edge_effects/disturbance_edge_distance_1994',\n",
        "'binary_edge_effects/disturbance_edge_distance_1995',\n",
        "'binary_edge_effects/disturbance_edge_distance_1996',\n",
        "'binary_edge_effects/disturbance_edge_distance_1997',\n",
        "'binary_edge_effects/disturbance_edge_distance_1998',\n",
        "'binary_edge_effects/disturbance_edge_distance_1999',\n",
        "'binary_edge_effects/disturbance_edge_distance_2000',\n",
        "'binary_edge_effects/disturbance_edge_distance_2001',\n",
        "'binary_edge_effects/disturbance_edge_distance_2002',\n",
        "'binary_edge_effects/disturbance_edge_distance_2003',\n",
        "'binary_edge_effects/disturbance_edge_distance_2004',\n",
        "'binary_edge_effects/disturbance_edge_distance_2005',\n",
        "'binary_edge_effects/disturbance_edge_distance_2006',\n",
        "'binary_edge_effects/disturbance_edge_distance_2007',\n",
        "'binary_edge_effects/disturbance_edge_distance_2008',\n",
        "'binary_edge_effects/disturbance_edge_distance_2009',\n",
        "'binary_edge_effects/disturbance_edge_distance_2010',\n",
        "'binary_edge_effects/disturbance_edge_distance_2011',\n",
        "'binary_edge_effects/disturbance_edge_distance_2012',\n",
        "'binary_edge_effects/disturbance_edge_distance_2013',\n",
        "'binary_edge_effects/disturbance_edge_distance_2014',\n",
        "'binary_edge_effects/disturbance_edge_distance_2015',\n",
        "'binary_edge_effects/disturbance_edge_distance_2016',\n",
        "'binary_edge_effects/disturbance_edge_distance_2017',\n",
        "'binary_edge_effects/disturbance_edge_distance_2018',\n",
        "'binary_edge_effects/disturbance_edge_distance_2019',\n",
        "'binary_edge_effects/disturbance_edge_distance_2020',\n",
        "'binary_edge_effects/disturbance_edge_distance_2021',\n",
        "'binary_edge_effects/disturbance_edge_distance_2022',\n",
        "'binary_edge_effects/disturbance_edge_distance_2023',\n",
        "'binary_edge_effects/disturbance_edge_distance_2024',\n",
        "'binary_edge_effects/disturbance_local_density_1990',\n",
        "'binary_edge_effects/disturbance_local_density_1991',\n",
        "'binary_edge_effects/disturbance_local_density_1992',\n",
        "'binary_edge_effects/disturbance_local_density_1993',\n",
        "'binary_edge_effects/disturbance_local_density_1994',\n",
        "'binary_edge_effects/disturbance_local_density_1995',\n",
        "'binary_edge_effects/disturbance_local_density_1996',\n",
        "'binary_edge_effects/disturbance_local_density_1997',\n",
        "'binary_edge_effects/disturbance_local_density_1998',\n",
        "'binary_edge_effects/disturbance_local_density_1999',\n",
        "'binary_edge_effects/disturbance_local_density_2000',\n",
        "'binary_edge_effects/disturbance_local_density_2001',\n",
        "'binary_edge_effects/disturbance_local_density_2002',\n",
        "'binary_edge_effects/disturbance_local_density_2003',\n",
        "'binary_edge_effects/disturbance_local_density_2004',\n",
        "'binary_edge_effects/disturbance_local_density_2005',\n",
        "'binary_edge_effects/disturbance_local_density_2006',\n",
        "'binary_edge_effects/disturbance_local_density_2007',\n",
        "'binary_edge_effects/disturbance_local_density_2008',\n",
        "'binary_edge_effects/disturbance_local_density_2009',\n",
        "'binary_edge_effects/disturbance_local_density_2010',\n",
        "'binary_edge_effects/disturbance_local_density_2011',\n",
        "'binary_edge_effects/disturbance_local_density_2012',\n",
        "'binary_edge_effects/disturbance_local_density_2013',\n",
        "'binary_edge_effects/disturbance_local_density_2014',\n",
        "'binary_edge_effects/disturbance_local_density_2015',\n",
        "'binary_edge_effects/disturbance_local_density_2016',\n",
        "'binary_edge_effects/disturbance_local_density_2017',\n",
        "'binary_edge_effects/disturbance_local_density_2018',\n",
        "'binary_edge_effects/disturbance_local_density_2019',\n",
        "'binary_edge_effects/disturbance_local_density_2020',\n",
        "'binary_edge_effects/disturbance_local_density_2021',\n",
        "'binary_edge_effects/disturbance_local_density_2022',\n",
        "'binary_edge_effects/disturbance_local_density_2023',\n",
        "'binary_edge_effects/disturbance_local_density_2024',\n",
        "'binary_edge_effects/forest_edge_distance_1990',\n",
        "'binary_edge_effects/forest_edge_distance_1991',\n",
        "'binary_edge_effects/forest_edge_distance_1992',\n",
        "'binary_edge_effects/forest_edge_distance_1993',\n",
        "'binary_edge_effects/forest_edge_distance_1994',\n",
        "'binary_edge_effects/forest_edge_distance_1995',\n",
        "'binary_edge_effects/forest_edge_distance_1996',\n",
        "'binary_edge_effects/forest_edge_distance_1997',\n",
        "'binary_edge_effects/forest_edge_distance_1998',\n",
        "'binary_edge_effects/forest_edge_distance_1999',\n",
        "'binary_edge_effects/forest_edge_distance_2000',\n",
        "'binary_edge_effects/forest_edge_distance_2001',\n",
        "'binary_edge_effects/forest_edge_distance_2002',\n",
        "'binary_edge_effects/forest_edge_distance_2003',\n",
        "'binary_edge_effects/forest_edge_distance_2004',\n",
        "'binary_edge_effects/forest_edge_distance_2005',\n",
        "'binary_edge_effects/forest_edge_distance_2006',\n",
        "'binary_edge_effects/forest_edge_distance_2007',\n",
        "'binary_edge_effects/forest_edge_distance_2008',\n",
        "'binary_edge_effects/forest_edge_distance_2009',\n",
        "'binary_edge_effects/forest_edge_distance_2010',\n",
        "'binary_edge_effects/forest_edge_distance_2011',\n",
        "'binary_edge_effects/forest_edge_distance_2012',\n",
        "'binary_edge_effects/forest_edge_distance_2013',\n",
        "'binary_edge_effects/forest_edge_distance_2014',\n",
        "'binary_edge_effects/forest_edge_distance_2015',\n",
        "'binary_edge_effects/forest_edge_distance_2016',\n",
        "'binary_edge_effects/forest_edge_distance_2017',\n",
        "'binary_edge_effects/forest_edge_distance_2018',\n",
        "'binary_edge_effects/forest_edge_distance_2019',\n",
        "'binary_edge_effects/forest_edge_distance_2020',\n",
        "'binary_edge_effects/forest_edge_distance_2021',\n",
        "'binary_edge_effects/forest_edge_distance_2022',\n",
        "'binary_edge_effects/forest_edge_distance_2023',\n",
        "'binary_edge_effects/forest_edge_distance_2024',\n",
        "'binary_edge_effects/forest_local_density_1990',\n",
        "'binary_edge_effects/forest_local_density_1991',\n",
        "'binary_edge_effects/forest_local_density_1992',\n",
        "'binary_edge_effects/forest_local_density_1993',\n",
        "'binary_edge_effects/forest_local_density_1994',\n",
        "'binary_edge_effects/forest_local_density_1995',\n",
        "'binary_edge_effects/forest_local_density_1996',\n",
        "'binary_edge_effects/forest_local_density_1997',\n",
        "'binary_edge_effects/forest_local_density_1998',\n",
        "'binary_edge_effects/forest_local_density_1999',\n",
        "'binary_edge_effects/forest_local_density_2000',\n",
        "'binary_edge_effects/forest_local_density_2001',\n",
        "'binary_edge_effects/forest_local_density_2002',\n",
        "'binary_edge_effects/forest_local_density_2003',\n",
        "'binary_edge_effects/forest_local_density_2004',\n",
        "'binary_edge_effects/forest_local_density_2005',\n",
        "'binary_edge_effects/forest_local_density_2006',\n",
        "'binary_edge_effects/forest_local_density_2007',\n",
        "'binary_edge_effects/forest_local_density_2008',\n",
        "'binary_edge_effects/forest_local_density_2009',\n",
        "'binary_edge_effects/forest_local_density_2010',\n",
        "'binary_edge_effects/forest_local_density_2011',\n",
        "'binary_edge_effects/forest_local_density_2012',\n",
        "'binary_edge_effects/forest_local_density_2013',\n",
        "'binary_edge_effects/forest_local_density_2014',\n",
        "'binary_edge_effects/forest_local_density_2015',\n",
        "'binary_edge_effects/forest_local_density_2016',\n",
        "'binary_edge_effects/forest_local_density_2017',\n",
        "'binary_edge_effects/forest_local_density_2018',\n",
        "'binary_edge_effects/forest_local_density_2019',\n",
        "'binary_edge_effects/forest_local_density_2020',\n",
        "'binary_edge_effects/forest_local_density_2021',\n",
        "'binary_edge_effects/forest_local_density_2022',\n",
        "'binary_edge_effects/forest_local_density_2023',\n",
        "'binary_edge_effects/forest_local_density_2024',\n",
        "'binary_edge_effects/lu_ais_edge_distance',\n",
        "'binary_edge_effects/lu_ais_local_density',\n",
        "'binary_edge_effects/lu_berkelah_jerantut_edge_distance',\n",
        "# 'binary_edge_effects/lu_berkelah_jerantut_local_density',\n",
        "'binary_edge_effects/lu_berkelah_kuantan_edge_distance',\n",
        "# 'binary_edge_effects/lu_berkelah_kuantan_local_density',\n",
        "'binary_edge_effects/lu_berkelah_temerloh_edge_distance',\n",
        "# 'binary_edge_effects/lu_berkelah_temerloh_local_density',\n",
        "'binary_edge_effects/lu_old-growth_protected_areas_edge_distance',\n",
        "# 'binary_edge_effects/lu_old-growth_protected_areas_local_density',\n",
        "'binary_edge_effects/lu_remen_chereh_edge_distance',\n",
        "# 'binary_edge_effects/lu_remen_chereh_local_density',\n",
        "'binary_edge_effects/lu_tekai_tembeling_edge_distance',\n",
        "# 'binary_edge_effects/lu_tekai_tembeling_local_density',\n",
        "'binary_edge_effects/lu_tekam_edge_distance',\n",
        "# 'binary_edge_effects/lu_tekam_local_density',\n",
        "'binary_edge_effects/lu_yong_edge_distance',\n",
        "'binary_edge_effects/lu_yong_lipis_edge_distance',\n",
        "# 'binary_edge_effects/lu_yong_lipis_local_density',\n",
        "# 'binary_edge_effects/lu_yong_local_density',\n",
        "'coast/coast_proximity_km',\n",
        "'topo_dsm_final/topo_dsm_smooth_aspect_cosine',\n",
        "'topo_dsm_final/topo_dsm_smooth_aspect_sine',\n",
        "'topo_dsm_final/topo_dsm_smooth_circular_variance_aspect_03',\n",
        "'topo_dsm_final/topo_dsm_smooth_circular_variance_aspect_07',\n",
        "'topo_dsm_final/topo_dsm_smooth_circular_variance_aspect_11',\n",
        "'topo_dsm_final/topo_dsm_smooth_deviation_mean_elevation_03',\n",
        "'topo_dsm_final/topo_dsm_smooth_deviation_mean_elevation_07',\n",
        "'topo_dsm_final/topo_dsm_smooth_deviation_mean_elevation_11',\n",
        "'topo_dsm_final/topo_dsm_smooth_eastness',\n",
        "'topo_dsm_final/topo_dsm_smooth_elevation',\n",
        "'topo_dsm_final/topo_dsm_smooth_northness',\n",
        "'topo_dsm_final/topo_dsm_smooth_profile_curvature',\n",
        "'topo_dsm_final/topo_dsm_smooth_roughness_03',\n",
        "'topo_dsm_final/topo_dsm_smooth_roughness_07',\n",
        "'topo_dsm_final/topo_dsm_smooth_roughness_11',\n",
        "'topo_dsm_final/topo_dsm_smooth_slope',\n",
        "'topo_dsm_final/topo_dsm_smooth_stream_power_index_log10',\n",
        "'topo_dsm_final/topo_dsm_smooth_surface_area_ratio',\n",
        "'topo_dsm_final/topo_dsm_smooth_tangential_curvature',\n",
        "'topo_dsm_final/topo_dsm_smooth_topographic_position_index_03',\n",
        "'topo_dsm_final/topo_dsm_smooth_topographic_position_index_07',\n",
        "'topo_dsm_final/topo_dsm_smooth_topographic_position_index_11',\n",
        "'topo_dsm_final/topo_dsm_smooth_topographic_ruggedness_index',\n",
        "'topo_dsm_final/topo_dsm_smooth_topographic_wetness_index',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_aspect_cosine',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_aspect_sine',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_circular_variance_aspect_03',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_circular_variance_aspect_07',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_circular_variance_aspect_11',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_deviation_mean_elevation_03',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_deviation_mean_elevation_07',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_deviation_mean_elevation_11',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_eastness',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_elevation',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_northness',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_profile_curvature',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_roughness_03',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_roughness_07',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_roughness_11',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_slope',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_stream_power_index_log10',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_surface_area_ratio',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_tangential_curvature',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_topographic_position_index_03',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_topographic_position_index_07',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_topographic_position_index_11',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_topographic_ruggedness_index',\n",
        "'topo_dsm_final/topo_dsm_unsmooth_topographic_wetness_index',\n",
        "]"
      ],
      "metadata": {
        "id": "cKOVNRZfphF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "move_files = False  # Set to True to move instead of copy\n",
        "# Set to True to move only if 'alpha_earth' is in filename (can be large files)\n",
        "move_if_alpha_earth = True\n",
        "\n",
        "# Feature transfer progress\n",
        "feature_progress_index = 0\n",
        "feature_progress_label = widgets.Label(f\"Feature transfer progress: {feature_progress_index}/{len(feature_list)}\")\n",
        "display(feature_progress_label)\n",
        "\n",
        "for feature in feature_list:\n",
        "    feature_path = join(features_dir, f\"{feature}.tif\")\n",
        "    feature_destination = join(feature_final_dir, f\"{feature.split('/')[-1]}.tif\")\n",
        "    if not exists(feature_destination):\n",
        "        # Determine whether to move or copy\n",
        "        should_move = move_files or (move_if_alpha_earth and 'alpha_earth' in feature)\n",
        "        if should_move:\n",
        "            move(feature_path, feature_destination)\n",
        "        else:\n",
        "            copyfile(feature_path, feature_destination)\n",
        "\n",
        "    # update feature progress\n",
        "    feature_progress_index += 1\n",
        "    feature_progress_label.value = f\"Feature transfer progress: {feature_progress_index}/{len(feature_list)}\"\n",
        "\n",
        "print(\"All features finalised.\")"
      ],
      "metadata": {
        "id": "nFeLZBOOpkyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p91jvg0TnJlh"
      },
      "source": [
        "# Spatial joining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY6LwQ9IZRVE"
      },
      "outputs": [],
      "source": [
        "# Select the dataset targets .pkl to add features\n",
        "for pkl in os.listdir(datasets_tar_dir):\n",
        "  if pkl.endswith('.pkl'):\n",
        "    print(f\"dataset_targets_pkl = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qvw-SiXQO9s"
      },
      "outputs": [],
      "source": [
        "dataset_targets_pkl = 'gedi_elevation.pkl'\n",
        "\n",
        "# Modify this if experimenting with incompatible feature sets\n",
        "# E.g. TMF or Alpha Earth\n",
        "dataset_add_features_pkl_name = 'gedi_elevation.pkl'\n",
        "\n",
        "# Create list of features in 'final' directory\n",
        "feature_list = []\n",
        "for feature in os.listdir(feature_final_dir):\n",
        "  feature_list.append(feature)\n",
        "\n",
        "# Select features to add to the dataset.\n",
        "# NOTE FOR GEDI DTM:\n",
        "# Land-cover more recent than the base DSM shouldn't be used, as it's intended to\n",
        "# measure discrepencies between the base surface data and GEDI terrain data.\n",
        "# In the case of Copernicus DEM, this is > 2015.\n",
        "# NOTE FOR AGBD:\n",
        "# Land-cover more recent than or the same year as the most recent GEDI data (e.g. 2024) will be removed at the finalisation stage.\n",
        "print('feature_list = [')\n",
        "for feature in sorted(feature_list):\n",
        "  print(f\"'{feature}',\")\n",
        "print(']')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNqEIFp4RQTx"
      },
      "outputs": [],
      "source": [
        "feature_list = [\n",
        "'coast_proximity_km.tif',\n",
        "'disturbance_edge_distance_1990.tif',\n",
        "'disturbance_edge_distance_1991.tif',\n",
        "'disturbance_edge_distance_1992.tif',\n",
        "'disturbance_edge_distance_1993.tif',\n",
        "'disturbance_edge_distance_1994.tif',\n",
        "'disturbance_edge_distance_1995.tif',\n",
        "'disturbance_edge_distance_1996.tif',\n",
        "'disturbance_edge_distance_1997.tif',\n",
        "'disturbance_edge_distance_1998.tif',\n",
        "'disturbance_edge_distance_1999.tif',\n",
        "'disturbance_edge_distance_2000.tif',\n",
        "'disturbance_edge_distance_2001.tif',\n",
        "'disturbance_edge_distance_2002.tif',\n",
        "'disturbance_edge_distance_2003.tif',\n",
        "'disturbance_edge_distance_2004.tif',\n",
        "'disturbance_edge_distance_2005.tif',\n",
        "'disturbance_edge_distance_2006.tif',\n",
        "'disturbance_edge_distance_2007.tif',\n",
        "'disturbance_edge_distance_2008.tif',\n",
        "'disturbance_edge_distance_2009.tif',\n",
        "'disturbance_edge_distance_2010.tif',\n",
        "'disturbance_edge_distance_2011.tif',\n",
        "'disturbance_edge_distance_2012.tif',\n",
        "'disturbance_edge_distance_2013.tif',\n",
        "'disturbance_edge_distance_2014.tif',\n",
        "'disturbance_edge_distance_2015.tif',\n",
        "# 'disturbance_edge_distance_2016.tif',\n",
        "# 'disturbance_edge_distance_2017.tif',\n",
        "# 'disturbance_edge_distance_2018.tif',\n",
        "# 'disturbance_edge_distance_2019.tif',\n",
        "# 'disturbance_edge_distance_2020.tif',\n",
        "# 'disturbance_edge_distance_2021.tif',\n",
        "# 'disturbance_edge_distance_2022.tif',\n",
        "# 'disturbance_edge_distance_2023.tif',\n",
        "# 'disturbance_edge_distance_2024.tif',\n",
        "'disturbance_local_density_1990.tif',\n",
        "'disturbance_local_density_1991.tif',\n",
        "'disturbance_local_density_1992.tif',\n",
        "'disturbance_local_density_1993.tif',\n",
        "'disturbance_local_density_1994.tif',\n",
        "'disturbance_local_density_1995.tif',\n",
        "'disturbance_local_density_1996.tif',\n",
        "'disturbance_local_density_1997.tif',\n",
        "'disturbance_local_density_1998.tif',\n",
        "'disturbance_local_density_1999.tif',\n",
        "'disturbance_local_density_2000.tif',\n",
        "'disturbance_local_density_2001.tif',\n",
        "'disturbance_local_density_2002.tif',\n",
        "'disturbance_local_density_2003.tif',\n",
        "'disturbance_local_density_2004.tif',\n",
        "'disturbance_local_density_2005.tif',\n",
        "'disturbance_local_density_2006.tif',\n",
        "'disturbance_local_density_2007.tif',\n",
        "'disturbance_local_density_2008.tif',\n",
        "'disturbance_local_density_2009.tif',\n",
        "'disturbance_local_density_2010.tif',\n",
        "'disturbance_local_density_2011.tif',\n",
        "'disturbance_local_density_2012.tif',\n",
        "'disturbance_local_density_2013.tif',\n",
        "'disturbance_local_density_2014.tif',\n",
        "'disturbance_local_density_2015.tif',\n",
        "# 'disturbance_local_density_2016.tif',\n",
        "# 'disturbance_local_density_2017.tif',\n",
        "# 'disturbance_local_density_2018.tif',\n",
        "# 'disturbance_local_density_2019.tif',\n",
        "# 'disturbance_local_density_2020.tif',\n",
        "# 'disturbance_local_density_2021.tif',\n",
        "# 'disturbance_local_density_2022.tif',\n",
        "# 'disturbance_local_density_2023.tif',\n",
        "# 'disturbance_local_density_2024.tif',\n",
        "'forest_edge_distance_1990.tif',\n",
        "# 'forest_edge_distance_1991.tif',\n",
        "# 'forest_edge_distance_1992.tif',\n",
        "# 'forest_edge_distance_1993.tif',\n",
        "# 'forest_edge_distance_1994.tif',\n",
        "# 'forest_edge_distance_1995.tif',\n",
        "# 'forest_edge_distance_1996.tif',\n",
        "# 'forest_edge_distance_1997.tif',\n",
        "# 'forest_edge_distance_1998.tif',\n",
        "# 'forest_edge_distance_1999.tif',\n",
        "'forest_edge_distance_2000.tif',\n",
        "# 'forest_edge_distance_2001.tif',\n",
        "# 'forest_edge_distance_2002.tif',\n",
        "# 'forest_edge_distance_2003.tif',\n",
        "# 'forest_edge_distance_2004.tif',\n",
        "# 'forest_edge_distance_2005.tif',\n",
        "# 'forest_edge_distance_2006.tif',\n",
        "# 'forest_edge_distance_2007.tif',\n",
        "# 'forest_edge_distance_2008.tif',\n",
        "# 'forest_edge_distance_2009.tif',\n",
        "'forest_edge_distance_2010.tif',\n",
        "'forest_edge_distance_2011.tif',\n",
        "'forest_edge_distance_2012.tif',\n",
        "'forest_edge_distance_2013.tif',\n",
        "'forest_edge_distance_2014.tif',\n",
        "'forest_edge_distance_2015.tif',\n",
        "# 'forest_edge_distance_2016.tif',\n",
        "# 'forest_edge_distance_2017.tif',\n",
        "# 'forest_edge_distance_2018.tif',\n",
        "# 'forest_edge_distance_2019.tif',\n",
        "# 'forest_edge_distance_2020.tif',\n",
        "# 'forest_edge_distance_2021.tif',\n",
        "# 'forest_edge_distance_2022.tif',\n",
        "# 'forest_edge_distance_2023.tif',\n",
        "# 'forest_edge_distance_2024.tif',\n",
        "'forest_local_density_1990.tif',\n",
        "# 'forest_local_density_1991.tif',\n",
        "# 'forest_local_density_1992.tif',\n",
        "# 'forest_local_density_1993.tif',\n",
        "# 'forest_local_density_1994.tif',\n",
        "# 'forest_local_density_1995.tif',\n",
        "# 'forest_local_density_1996.tif',\n",
        "# 'forest_local_density_1997.tif',\n",
        "# 'forest_local_density_1998.tif',\n",
        "# 'forest_local_density_1999.tif',\n",
        "'forest_local_density_2000.tif',\n",
        "# 'forest_local_density_2001.tif',\n",
        "# 'forest_local_density_2002.tif',\n",
        "# 'forest_local_density_2003.tif',\n",
        "# 'forest_local_density_2004.tif',\n",
        "# 'forest_local_density_2005.tif',\n",
        "# 'forest_local_density_2006.tif',\n",
        "# 'forest_local_density_2007.tif',\n",
        "# 'forest_local_density_2008.tif',\n",
        "# 'forest_local_density_2009.tif',\n",
        "'forest_local_density_2010.tif',\n",
        "'forest_local_density_2011.tif',\n",
        "'forest_local_density_2012.tif',\n",
        "'forest_local_density_2013.tif',\n",
        "'forest_local_density_2014.tif',\n",
        "'forest_local_density_2015.tif',\n",
        "# 'forest_local_density_2016.tif',\n",
        "# 'forest_local_density_2017.tif',\n",
        "# 'forest_local_density_2018.tif',\n",
        "# 'forest_local_density_2019.tif',\n",
        "# 'forest_local_density_2020.tif',\n",
        "# 'forest_local_density_2021.tif',\n",
        "# 'forest_local_density_2022.tif',\n",
        "# 'forest_local_density_2023.tif',\n",
        "# 'forest_local_density_2024.tif',\n",
        "'latitude.tif',\n",
        "'longitude.tif',\n",
        "'lu_ais_edge_distance.tif',\n",
        "'lu_berkelah_jerantut_edge_distance.tif',\n",
        "'lu_berkelah_kuantan_edge_distance.tif',\n",
        "'lu_berkelah_temerloh_edge_distance.tif',\n",
        "'lu_old-growth_protected_areas_edge_distance.tif',\n",
        "'lu_remen_chereh_edge_distance.tif',\n",
        "'lu_tekai_tembeling_edge_distance.tif',\n",
        "'lu_tekam_edge_distance.tif',\n",
        "'lu_yong_edge_distance.tif',\n",
        "'lu_yong_lipis_edge_distance.tif',\n",
        "'topo_dsm_smooth_aspect_cosine.tif',\n",
        "'topo_dsm_smooth_aspect_sine.tif',\n",
        "'topo_dsm_smooth_circular_variance_aspect_03.tif',\n",
        "'topo_dsm_smooth_circular_variance_aspect_07.tif',\n",
        "'topo_dsm_smooth_circular_variance_aspect_11.tif',\n",
        "'topo_dsm_smooth_deviation_mean_elevation_03.tif',\n",
        "'topo_dsm_smooth_deviation_mean_elevation_07.tif',\n",
        "'topo_dsm_smooth_deviation_mean_elevation_11.tif',\n",
        "'topo_dsm_smooth_eastness.tif',\n",
        "'topo_dsm_smooth_elevation.tif',\n",
        "'topo_dsm_smooth_northness.tif',\n",
        "'topo_dsm_smooth_profile_curvature.tif',\n",
        "'topo_dsm_smooth_roughness_03.tif',\n",
        "'topo_dsm_smooth_roughness_07.tif',\n",
        "'topo_dsm_smooth_roughness_11.tif',\n",
        "'topo_dsm_smooth_slope.tif',\n",
        "'topo_dsm_smooth_stream_power_index_log10.tif',\n",
        "'topo_dsm_smooth_surface_area_ratio.tif',\n",
        "'topo_dsm_smooth_tangential_curvature.tif',\n",
        "'topo_dsm_smooth_topographic_position_index_03.tif',\n",
        "'topo_dsm_smooth_topographic_position_index_07.tif',\n",
        "'topo_dsm_smooth_topographic_position_index_11.tif',\n",
        "'topo_dsm_smooth_topographic_ruggedness_index.tif',\n",
        "'topo_dsm_smooth_topographic_wetness_index.tif',\n",
        "'topo_dsm_unsmooth_aspect_cosine.tif',\n",
        "'topo_dsm_unsmooth_aspect_sine.tif',\n",
        "'topo_dsm_unsmooth_circular_variance_aspect_03.tif',\n",
        "'topo_dsm_unsmooth_circular_variance_aspect_07.tif',\n",
        "'topo_dsm_unsmooth_circular_variance_aspect_11.tif',\n",
        "'topo_dsm_unsmooth_deviation_mean_elevation_03.tif',\n",
        "'topo_dsm_unsmooth_deviation_mean_elevation_07.tif',\n",
        "'topo_dsm_unsmooth_deviation_mean_elevation_11.tif',\n",
        "'topo_dsm_unsmooth_eastness.tif',\n",
        "'topo_dsm_unsmooth_elevation.tif',\n",
        "'topo_dsm_unsmooth_northness.tif',\n",
        "'topo_dsm_unsmooth_profile_curvature.tif',\n",
        "'topo_dsm_unsmooth_roughness_03.tif',\n",
        "'topo_dsm_unsmooth_roughness_07.tif',\n",
        "'topo_dsm_unsmooth_roughness_11.tif',\n",
        "'topo_dsm_unsmooth_slope.tif',\n",
        "'topo_dsm_unsmooth_stream_power_index_log10.tif',\n",
        "'topo_dsm_unsmooth_surface_area_ratio.tif',\n",
        "'topo_dsm_unsmooth_tangential_curvature.tif',\n",
        "'topo_dsm_unsmooth_topographic_position_index_03.tif',\n",
        "'topo_dsm_unsmooth_topographic_position_index_07.tif',\n",
        "'topo_dsm_unsmooth_topographic_position_index_11.tif',\n",
        "'topo_dsm_unsmooth_topographic_ruggedness_index.tif',\n",
        "'topo_dsm_unsmooth_topographic_wetness_index.tif',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cache = True\n",
        "\n",
        "dataset_targets_path = join(datasets_tar_dir, dataset_targets_pkl)\n",
        "dataset_targets = pd.read_pickle(dataset_targets_path)\n",
        "dataset_add_fea_path = join(datasets_add_fea_dir, dataset_add_features_pkl_name)\n",
        "\n",
        "# Handle caching\n",
        "if cache: print(\"Cache enabled.\")\n",
        "if not exists(dataset_add_fea_path):\n",
        "    dataset_targets.to_pickle(dataset_add_fea_path)\n",
        "    dataset_add_fea = pd.read_pickle(dataset_add_fea_path)\n",
        "else:\n",
        "    print(f\"An 'add features' dataset already exists: {dataset_add_fea_path}\")\n",
        "    if cache:\n",
        "        print(\"Continuing to add features to existing dataset. Delete it to start again.\")\n",
        "        dataset_add_fea = pd.read_pickle(dataset_add_fea_path)\n",
        "    else:\n",
        "        print(\"Cache disabled. The 'add features' dataset will be overwritten in 10 seconds (interrupt if unintended).\")\n",
        "        sleep(10)\n",
        "        dataset_targets.to_pickle(dataset_add_fea_path)\n",
        "        dataset_add_fea = pd.read_pickle(dataset_add_fea_path)\n",
        "\n",
        "# Feature progress\n",
        "feature_progress_index = 0\n",
        "feature_progress_label = widgets.Label(f\"feature progress: {feature_progress_index}/{len(feature_list)}\")\n",
        "display(feature_progress_label)\n",
        "\n",
        "for feature in feature_list:\n",
        "    feature_name = feature.replace('.tif', '')\n",
        "    if f\"fea_{feature_name}\" not in dataset_add_fea.columns:\n",
        "        feature_path = join(feature_final_dir, feature)\n",
        "        sample_raster_values(dataset_add_fea, feature_path, feature=True)\n",
        "        if cache: dataset_add_fea.to_pickle(dataset_add_fea_path)\n",
        "    feature_progress_index += 1\n",
        "    feature_progress_label.value = f\"feature progress: {feature_progress_index}/{len(feature_list)}\"\n",
        "    # defragment every 50 features\n",
        "    if feature_progress_index % 50 == 0:\n",
        "        dataset_add_fea = dataset_add_fea.copy()\n",
        "\n",
        "# Defragment and export\n",
        "dataset_add_fea = dataset_add_fea.copy()\n",
        "dataset_add_fea.to_pickle(dataset_add_fea_path)\n",
        "\n",
        "print(f\"All features have been added to {dataset_add_fea_path}.\")"
      ],
      "metadata": {
        "id": "oIEXbkOiSz4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s54en9tJWI_J"
      },
      "source": [
        "# Drop columns (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1nf5UUh2MyO"
      },
      "outputs": [],
      "source": [
        "# Targets and features can be removed from the dataset in case of any issues.\n",
        "# Select the 'add features' dataset.\n",
        "for pkl in os.listdir(datasets_add_fea_dir):\n",
        "  print(f\"dataset_drop_columns = '{pkl}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsaqSAELO2Wd"
      },
      "outputs": [],
      "source": [
        "add_fea_dataset_name = 'gedi_elevation.pkl'\n",
        "\n",
        "add_fea_dataset_path = join(datasets_add_fea_dir, add_fea_dataset_name)\n",
        "add_fea_dataset = pd.read_pickle(add_fea_dataset_path)\n",
        "\n",
        "# Inspect existing columns\n",
        "sorted(add_fea_dataset.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_6EVMnNmtts"
      },
      "outputs": [],
      "source": [
        "drop_dataset_columns = True\n",
        "\n",
        "if drop_dataset_columns:\n",
        "  # Anything containing the dropped_columns string will be removed\n",
        "  dropped_columns = 'fea_topo_dsm_'\n",
        "  # Drop columns\n",
        "  dropped_columns_dataset = add_fea_dataset.loc[:,~add_fea_dataset.columns.str.contains(dropped_columns)]\n",
        "  dropped_columns_dataset.to_pickle(add_fea_dataset_path)\n",
        "  # Inspect columns again\n",
        "  add_fea_dataset = pd.read_pickle(add_fea_dataset_path)\n",
        "sorted(add_fea_dataset.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3qaR5lBnqmY"
      },
      "source": [
        "# Finalise dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piV4j6Dtnsgy"
      },
      "outputs": [],
      "source": [
        "# Select the dataset to finalise.\n",
        "for pkl in os.listdir(datasets_add_fea_dir):\n",
        "    print(f'final_dataset_name = \"{pkl}\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset_name = \"gedi_elevation.pkl\"\n",
        "\n",
        "dataset_path = join(datasets_add_fea_dir, final_dataset_name)\n",
        "dataset = pd.read_pickle(dataset_path)\n",
        "\n",
        "# Precision reduction for histogram-based XGBoost\n",
        "# Fewer unique values = smaller max_bin = faster histogram construction\n",
        "# XGBoost bins continuous features, excess precision wastes computation\n",
        "\n",
        "print(\"precision_change_dict = {\")\n",
        "for col in sorted(dataset.columns):\n",
        "    series = dataset[col]\n",
        "    is_float = series.dtype in ['float32', 'float64']\n",
        "    is_geometry = 'geometry' in str(series.dtype).lower()\n",
        "    if is_geometry:\n",
        "        print(f'    \"{col}\": None,  # geometry')\n",
        "        continue\n",
        "    col_unique = series.nunique()\n",
        "    if not is_float: print(f'    \"{col}\": None,  # {series.dtype}, unique={col_unique:,}')\n",
        "    else:\n",
        "        col_min = series.min()\n",
        "        col_max = series.max()\n",
        "        # infer current decimal places from sample\n",
        "        sample = series.dropna().head(10000).astype(str)\n",
        "        decimals = sample.apply(lambda x: len(x.split('.')[-1]) if '.' in x else 0)\n",
        "        current_precision = int(decimals.max())\n",
        "        print(f'    \"{col}\": None,  # float, precision={current_precision}, min={col_min:.4g}, max={col_max:.4g}, unique={col_unique:,}')\n",
        "print(\"}\")"
      ],
      "metadata": {
        "id": "rlc-ftXKBEZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_change_dict = {\n",
        "    \"beam\": None,  # object, unique=8\n",
        "    \"fea_coast_proximity_km\": None,  # float, precision=1, min=18.6, max=148.9, unique=1,304\n",
        "    \"fea_disturbance_edge_distance_1990\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1991\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1992\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1993\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1994\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1995\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1996\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1997\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1998\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_1999\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2000\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2001\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2002\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2003\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2004\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2005\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2006\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2007\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2008\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2009\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2010\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2011\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2012\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2013\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2014\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_edge_distance_2015\": None,  # int16, unique=24\n",
        "    \"fea_disturbance_local_density_1990\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1991\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1992\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1993\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1994\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1995\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1996\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1997\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1998\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_1999\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2000\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2001\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2002\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2003\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2004\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2005\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2006\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2007\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2008\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2009\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2010\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2011\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2012\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2013\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2014\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_disturbance_local_density_2015\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_edge_distance_1990\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2000\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2010\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2011\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2012\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2013\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2014\": None,  # int16, unique=24\n",
        "    \"fea_forest_edge_distance_2015\": None,  # int16, unique=24\n",
        "    \"fea_forest_local_density_1990\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2000\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2010\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2011\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2012\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2013\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2014\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_forest_local_density_2015\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_latitude\": None,  # float, precision=3, min=3.586, max=4.948, unique=1,363\n",
        "    \"fea_longitude\": None,  # float, precision=3, min=102, max=103.2, unique=1,155\n",
        "    \"fea_lu_ais_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_berkelah_jerantut_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_berkelah_kuantan_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_berkelah_temerloh_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_old-growth_protected_areas_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_remen_chereh_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_tekai_tembeling_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_tekam_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_yong_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_lu_yong_lipis_edge_distance\": None,  # int16, unique=24\n",
        "    \"fea_topo_dsm_smooth_aspect_cosine\": None,  # float, precision=2, min=-1, max=1, unique=201\n",
        "    \"fea_topo_dsm_smooth_aspect_sine\": None,  # float, precision=2, min=-1, max=1, unique=201\n",
        "    \"fea_topo_dsm_smooth_circular_variance_aspect_03\": None,  # float, precision=2, min=0, max=0.72, unique=72\n",
        "    \"fea_topo_dsm_smooth_circular_variance_aspect_07\": None,  # float, precision=2, min=0, max=0.92, unique=93\n",
        "    \"fea_topo_dsm_smooth_circular_variance_aspect_11\": None,  # float, precision=2, min=0, max=0.96, unique=97\n",
        "    \"fea_topo_dsm_smooth_deviation_mean_elevation_03\": None,  # int16, unique=2\n",
        "    \"fea_topo_dsm_smooth_deviation_mean_elevation_07\": None,  # float, precision=1, min=-0.9, max=1, unique=20\n",
        "    \"fea_topo_dsm_smooth_deviation_mean_elevation_11\": None,  # float, precision=1, min=-1.4, max=1.6, unique=31\n",
        "    \"fea_topo_dsm_smooth_eastness\": None,  # float, precision=2, min=-0.76, max=0.81, unique=149\n",
        "    \"fea_topo_dsm_smooth_elevation\": None,  # int16, unique=1,942\n",
        "    \"fea_topo_dsm_smooth_northness\": None,  # float, precision=2, min=-0.74, max=0.79, unique=150\n",
        "    \"fea_topo_dsm_smooth_profile_curvature\": None,  # float, precision=3, min=-0.01, max=0.01, unique=21\n",
        "    \"fea_topo_dsm_smooth_roughness_03\": None,  # int16, unique=123\n",
        "    \"fea_topo_dsm_smooth_roughness_07\": None,  # int16, unique=284\n",
        "    \"fea_topo_dsm_smooth_roughness_11\": None,  # int16, unique=396\n",
        "    \"fea_topo_dsm_smooth_slope\": None,  # int16, unique=57\n",
        "    \"fea_topo_dsm_smooth_stream_power_index_log10\": None,  # int16, unique=20\n",
        "    \"fea_topo_dsm_smooth_surface_area_ratio\": None,  # float, precision=2, min=1, max=1.94, unique=82\n",
        "    \"fea_topo_dsm_smooth_tangential_curvature\": None,  # float, precision=3, min=-0.011, max=0.011, unique=23\n",
        "    \"fea_topo_dsm_smooth_topographic_position_index_03\": None,  # float, precision=1, min=-7.5, max=8.6, unique=125\n",
        "    \"fea_topo_dsm_smooth_topographic_position_index_07\": None,  # int16, unique=66\n",
        "    \"fea_topo_dsm_smooth_topographic_position_index_11\": None,  # int16, unique=116\n",
        "    \"fea_topo_dsm_smooth_topographic_ruggedness_index\": None,  # int16, unique=45\n",
        "    \"fea_topo_dsm_smooth_topographic_wetness_index\": None,  # int16, unique=41\n",
        "    \"fea_topo_dsm_unsmooth_aspect_cosine\": None,  # float, precision=2, min=-1, max=1, unique=201\n",
        "    \"fea_topo_dsm_unsmooth_aspect_sine\": None,  # float, precision=2, min=-1, max=1, unique=201\n",
        "    \"fea_topo_dsm_unsmooth_circular_variance_aspect_03\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_topo_dsm_unsmooth_circular_variance_aspect_07\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_topo_dsm_unsmooth_circular_variance_aspect_11\": None,  # float, precision=2, min=0, max=1, unique=101\n",
        "    \"fea_topo_dsm_unsmooth_deviation_mean_elevation_03\": None,  # int16, unique=7\n",
        "    \"fea_topo_dsm_unsmooth_deviation_mean_elevation_07\": None,  # float, precision=1, min=-3.6, max=3.9, unique=72\n",
        "    \"fea_topo_dsm_unsmooth_deviation_mean_elevation_11\": None,  # float, precision=1, min=-4.6, max=3.9, unique=74\n",
        "    \"fea_topo_dsm_unsmooth_eastness\": None,  # float, precision=2, min=-0.87, max=0.89, unique=169\n",
        "    \"fea_topo_dsm_unsmooth_elevation\": None,  # int16, unique=1,953\n",
        "    \"fea_topo_dsm_unsmooth_northness\": None,  # float, precision=2, min=-0.84, max=0.87, unique=168\n",
        "    \"fea_topo_dsm_unsmooth_profile_curvature\": None,  # float, precision=3, min=-0.052, max=0.032, unique=71\n",
        "    \"fea_topo_dsm_unsmooth_roughness_03\": None,  # int16, unique=142\n",
        "    \"fea_topo_dsm_unsmooth_roughness_07\": None,  # int16, unique=298\n",
        "    \"fea_topo_dsm_unsmooth_roughness_11\": None,  # int16, unique=403\n",
        "    \"fea_topo_dsm_unsmooth_slope\": None,  # int16, unique=67\n",
        "    \"fea_topo_dsm_unsmooth_stream_power_index_log10\": None,  # int16, unique=24\n",
        "    \"fea_topo_dsm_unsmooth_surface_area_ratio\": None,  # float, precision=2, min=1, max=2.52, unique=107\n",
        "    \"fea_topo_dsm_unsmooth_tangential_curvature\": None,  # float, precision=3, min=-0.039, max=0.035, unique=74\n",
        "    \"fea_topo_dsm_unsmooth_topographic_position_index_03\": None,  # int16, unique=40\n",
        "    \"fea_topo_dsm_unsmooth_topographic_position_index_07\": None,  # int16, unique=101\n",
        "    \"fea_topo_dsm_unsmooth_topographic_position_index_11\": None,  # int16, unique=157\n",
        "    \"fea_topo_dsm_unsmooth_topographic_ruggedness_index\": None,  # int16, unique=56\n",
        "    \"fea_topo_dsm_unsmooth_topographic_wetness_index\": None,  # int16, unique=52\n",
        "    \"gedi_elevation\": 0,  # float, precision=7, min=-20.26, max=2049, unique=863,822\n",
        "    \"geometry\": None,  # geometry\n",
        "    \"sensitivity\": 4,  # float, precision=8, min=0.95, max=0.9981, unique=484,671\n",
        "    \"shot_number\": None,  # object, unique=873,355\n",
        "}"
      ],
      "metadata": {
        "id": "xRUj3wfeblKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview precision changes before applying\n",
        "# Only columns wi,h integer values (not None) will be rounded\n",
        "# Review unique value reductions\n",
        "\n",
        "dataset_path = join(datasets_add_fea_dir, final_dataset_name)\n",
        "dataset = pd.read_pickle(dataset_path)\n",
        "dataset_preview = dataset.copy()\n",
        "\n",
        "print(f\"{'Column':<60} {'Old unique':>12} {'New unique':>12} {'Reduction':>10}\")\n",
        "print(\"-\" * 96)\n",
        "\n",
        "changed_columns = []\n",
        "for col, precision in precision_change_dict.items():\n",
        "    if precision is None:\n",
        "        continue\n",
        "    if dataset_preview[col].dtype not in ['float32', 'float64']:\n",
        "        print(f\"{col:<60} {'SKIPPED (not float)':<36}\")\n",
        "        continue\n",
        "\n",
        "    old_unique = dataset_preview[col].nunique()\n",
        "    dataset_preview[col] = dataset_preview[col].round(precision)\n",
        "    new_unique = dataset_preview[col].nunique()\n",
        "\n",
        "    reduction_pct = 100 * (1 - new_unique / old_unique) if old_unique > 0 else 0\n",
        "    print(f\"{col:<60} {old_unique:>12,} {new_unique:>12,} {reduction_pct:>9.1f}%\")\n",
        "    changed_columns.append(col)\n",
        "\n",
        "print(\"-\" * 96)\n",
        "print(f\"{len(changed_columns)} columns will be modified\")\n",
        "\n",
        "# max_bin estimate from preview\n",
        "feature_cols = [c for c in dataset_preview.columns if c.startswith('fea_')]\n",
        "max_unique = dataset_preview[feature_cols].nunique().max()\n",
        "print(f\"Max unique values across features: {max_unique:,} (use for max_bin)\")\n",
        "\n",
        "# preview not saved, run next block to apply changes,"
      ],
      "metadata": {
        "id": "cczvFneEEmI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xilq4FkonwMi"
      },
      "outputs": [],
      "source": [
        "# Whether targets have associated collection years requiring temporal feature alignment\n",
        "yearly_targets = False\n",
        "# Column containing the year for each observation (only used if yearly_targets = True)\n",
        "year_column = 'year'\n",
        "\n",
        "# Yearly features requiring temporal alignment\n",
        "# Multi-year features: multiple years retained for temporal context (e.g., TMF land-cover)\n",
        "yearly_features_multi = [\n",
        "    'forest_edge_distance',\n",
        "    'forest_local_density',\n",
        "    'disturbance_edge_distance',\n",
        "    'disturbance_local_density',\n",
        "]\n",
        "# Single-year features: only t-1 retained\n",
        "# Alpha Earth embeddings already encode landscape state; multi-year would cause feature bloat\n",
        "yearly_features_single = [\n",
        "    'alpha_earth',\n",
        "]\n",
        "\n",
        "# Load 'add features' dataset\n",
        "dataset_add_fea_path = join(datasets_add_fea_dir, final_dataset_name)\n",
        "dataset_add_fea = pd.read_pickle(dataset_add_fea_path)\n",
        "print(f\"Loaded dataset: {final_dataset_name} ({len(dataset_add_fea):,} rows, {len(dataset_add_fea.columns)} columns)\")\n",
        "\n",
        "# Apply precision reduction\n",
        "precision_changes = 0\n",
        "for col, precision in precision_change_dict.items():\n",
        "    if precision is None:\n",
        "        continue\n",
        "    if col in dataset_add_fea.columns and dataset_add_fea[col].dtype in ['float32', 'float64']:\n",
        "        dataset_add_fea[col] = dataset_add_fea[col].round(precision)\n",
        "        precision_changes += 1\n",
        "if precision_changes > 0:\n",
        "    print(f\"Applied precision reduction to {precision_changes} columns\")\n",
        "\n",
        "if yearly_targets:\n",
        "    print(f\"\\nYearly targets enabled. Year column: '{year_column}'\")\n",
        "\n",
        "    # Combine yearly feature lists for renaming\n",
        "    yearly_features = yearly_features_multi + yearly_features_single\n",
        "\n",
        "    # Check which yearly features are present\n",
        "    dataset_add_fea_column_list = sorted(dataset_add_fea.columns, reverse=True)\n",
        "\n",
        "    for yearly_feature in yearly_features_multi:\n",
        "        found = any(yearly_feature in col and col[-4:].isdigit() for col in dataset_add_fea_column_list)\n",
        "        if found: print(f\"  Multi-year feature found: {yearly_feature}\")\n",
        "        else: print(f\"  Multi-year feature NOT found: {yearly_feature}\")\n",
        "\n",
        "    for yearly_feature in yearly_features_single:\n",
        "        found = any(yearly_feature in col and col[-4:].isdigit() for col in dataset_add_fea_column_list)\n",
        "        if found: print(f\"  Single-year feature found: {yearly_feature}\")\n",
        "        else: print(f\"  Single-year feature NOT found: {yearly_feature}\")\n",
        "\n",
        "    # Get list of target years\n",
        "    target_year_list = dataset_add_fea[year_column].unique().tolist()\n",
        "    target_year_list = [int(x) for x in target_year_list]\n",
        "    target_year_max = np.max(target_year_list)\n",
        "    print(f\"\\nTarget years: {sorted(target_year_list)} (max: {target_year_max})\")\n",
        "\n",
        "    # Create an index identifier\n",
        "    dataset_add_fea['index_record'] = dataset_add_fea.index\n",
        "\n",
        "    # Create an empty list for storing yearly sub-datasets\n",
        "    dataset_year_list = []\n",
        "\n",
        "    # Iterate through each target year and shift the sample to appropriate feature year\n",
        "    # Column names are kept the same to avoid issues when ordering features in model training/prediction\n",
        "    # E.g. a '2021' feature for a 2022 target will actually be a 2019 feature for a 2020 target\n",
        "    for target_year in target_year_list:\n",
        "        dataset_year = dataset_add_fea[dataset_add_fea[year_column] == target_year].copy()\n",
        "        sample_year_modifier = target_year_max - target_year\n",
        "        for col in dataset_add_fea_column_list:\n",
        "            for yearly_feature in yearly_features:\n",
        "                # Check column contains feature name and ends with 4-digit year\n",
        "                if yearly_feature in col and col[-4:].isdigit():\n",
        "                    feature_year = int(col[-4:])\n",
        "                    col_prefix = col[:-4]\n",
        "                    corrected_sample = f\"{col_prefix}{feature_year + sample_year_modifier}\"\n",
        "                    dataset_year.rename(columns={col: corrected_sample}, inplace=True)\n",
        "                    break\n",
        "        dataset_year_list.append(dataset_year)\n",
        "\n",
        "    # Concatenate dataframes and sort\n",
        "    final_dataset = pd.concat(dataset_year_list, ignore_index=True)\n",
        "    final_dataset.sort_values('index_record', inplace=True)\n",
        "    final_dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Drop feature years out of the data range for one of the target years\n",
        "    cols_before_na = len(final_dataset.columns)\n",
        "    final_dataset.dropna(axis=1, how='any', inplace=True)\n",
        "    cols_dropped_na = cols_before_na - len(final_dataset.columns)\n",
        "    if cols_dropped_na > 0: print(f\"\\nDropped {cols_dropped_na} columns with NA values (out of range years)\")\n",
        "\n",
        "    # Drop multi-year features from the most recent target year (timing cannot be certain)\n",
        "    cols_to_drop = [col for col in final_dataset.columns\n",
        "                    for yearly_feature in yearly_features_multi\n",
        "                    if yearly_feature in col and col.endswith(str(target_year_max))]\n",
        "    if cols_to_drop:\n",
        "        final_dataset.drop(columns=cols_to_drop, inplace=True)\n",
        "        print(f\"Dropped {len(cols_to_drop)} multi-year feature columns from year {target_year_max}\")\n",
        "\n",
        "    # Drop single-year features except t-1\n",
        "    previous_year = target_year_max - 1\n",
        "    single_cols_to_drop = [col for col in final_dataset.columns\n",
        "                           for yearly_feature in yearly_features_single\n",
        "                           if yearly_feature in col and not col.endswith(str(previous_year))]\n",
        "    if single_cols_to_drop:\n",
        "        final_dataset.drop(columns=single_cols_to_drop, inplace=True)\n",
        "        print(f\"Dropped {len(single_cols_to_drop)} single-year feature columns (keeping only year {previous_year})\")\n",
        "\n",
        "    # Drop the index identifier\n",
        "    final_dataset.drop(columns=['index_record'], inplace=True)\n",
        "\n",
        "else:\n",
        "    print(\"\\nYearly targets disabled. No temporal feature alignment applied.\")\n",
        "    final_dataset = dataset_add_fea.copy()\n",
        "\n",
        "# Add 'tar_' prefix to non-features\n",
        "final_dataset.columns = ['tar_' + col if not col.startswith('fea_') else col for col in final_dataset.columns]\n",
        "\n",
        "# Sort columns alphabetically\n",
        "target_columns = [col for col in final_dataset.columns if col.startswith('tar_')]\n",
        "feature_columns = [col for col in final_dataset.columns if col.startswith('fea_')]\n",
        "sorted_columns = sorted(target_columns) + sorted(feature_columns)\n",
        "\n",
        "# Reindex the DataFrame with the sorted column order\n",
        "final_dataset = final_dataset.reindex(columns=sorted_columns)\n",
        "\n",
        "# Export and check final dataset\n",
        "final_dataset_path = join(datasets_final_dir, final_dataset_name)\n",
        "final_dataset.to_pickle(final_dataset_path)\n",
        "\n",
        "print(f\"\\nFinal dataset: {len(final_dataset):,} rows, {len(target_columns)} target columns, {len(feature_columns)} feature columns\")\n",
        "print(f\"Exported to: {final_dataset_path}\")\n",
        "\n",
        "pd.read_pickle(final_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM3XltPTYK_F"
      },
      "source": [
        "# Export to .gpkg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLKmYPoVYZGt"
      },
      "outputs": [],
      "source": [
        "# For verification and visualisation in GIS softaware.\n",
        "# Select the dataset .pkl to export as a .gpkg\n",
        "for pkl in os.listdir(datasets_final_dir):\n",
        "  print(f'dataset_gpkg_name = \"{pkl}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfMwAOY1Y8v4"
      },
      "outputs": [],
      "source": [
        "dataset_gpkg_name = \"gedi_elevation.pkl\"\n",
        "\n",
        "dataset_gpkg_pkl_path = join(datasets_final_dir, dataset_gpkg_name)\n",
        "dataset_gpkg_pkl = pd.read_pickle(dataset_gpkg_pkl_path)\n",
        "\n",
        "# Print columns that can be included\n",
        "print(\"selected_gpkg_columns = [\")\n",
        "for col in sorted(dataset_gpkg_pkl.columns):\n",
        "  if col != \"tar_geometry\":\n",
        "    print(f'  \"{col}\",')\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saC1b9Aibv_j"
      },
      "outputs": [],
      "source": [
        "selected_gpkg_columns = [\n",
        "  \"fea_topo_dsm_unsmooth_elevation\",\n",
        "  \"tar_gedi_elevation\",\n",
        "]\n",
        "\n",
        "selected_gpkg_columns = selected_gpkg_columns + ['tar_geometry']\n",
        "\n",
        "dataset_gpkg_geodataframe = gpd.GeoDataFrame(dataset_gpkg_pkl[selected_gpkg_columns], geometry='tar_geometry')\n",
        "\n",
        "dataset_gpkg_export = join(datasets_gpkg_dir, f\"{dataset_gpkg_name[:-4]}.gpkg\")\n",
        "dataset_gpkg_geodataframe.to_file(dataset_gpkg_export, driver=\"GPKG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FJKCE5qpJYZ"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHgZy_mxjvjD"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "collapsed_sections": [
        "p91jvg0TnJlh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}