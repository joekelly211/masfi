{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joekelly211/masfi/blob/main/7_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhx977-WIaWJ"
      },
      "source": [
        "# Imports and directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRnNty96IThZ"
      },
      "outputs": [],
      "source": [
        "# Define base directory\n",
        "# Use '/content/drive/MyDrive/' for a personal drive\n",
        "# Use '/gdrive/Shareddrives/' for a shared drive (must be created first)\n",
        "\n",
        "base_dir = \"/gdrive/Shareddrives/masfi\"\n",
        "# base_dir = '/content/drive/MyDrive/masfi'\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "if base_dir.startswith('/gdrive/Shareddrives/'):\n",
        "  drive.mount('/gdrive', force_remount=True)\n",
        "elif base_dir.startswith('/content/drive/MyDrive/'):\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "else: print(\"Create a base_dir beginning with '/gdrive/Shareddrives/' or '/content/drive/MyDrive/'.\")\n",
        "\n",
        "_path_to_add = os.path.realpath(base_dir)\n",
        "if _path_to_add not in sys.path:\n",
        "    sys.path.append(_path_to_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4n2MGF0aZtJ"
      },
      "outputs": [],
      "source": [
        "# Capture outputs\n",
        "%%capture\n",
        "# Installs and upgrades\n",
        "!apt-get install -y gdal-bin\n",
        "!pip install geopandas\n",
        "!pip install rasterstats\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpmgsb8KKMGN"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "try: import cupy # Only works on GPU runtime\n",
        "except: None\n",
        "import ast\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import gc\n",
        "import geopandas as gpd\n",
        "from google.colab import runtime\n",
        "import ipywidgets as widgets\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from numpy.random import normal\n",
        "from os import makedirs\n",
        "from os.path import join, exists, basename\n",
        "from osgeo import gdal, osr\n",
        "gdal.UseExceptions()\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import psutil\n",
        "from rasterstats import zonal_stats\n",
        "import re\n",
        "import requests\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "from sklearn.metrics import root_mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQwNO9T0_HPH"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "areas_dir = join(base_dir, \"1_areas\")\n",
        "polygons_dir = join(areas_dir, \"polygons\")\n",
        "masks_dir = join(areas_dir, \"masks\")\n",
        "targets_dir = join(base_dir, \"2_targets\")\n",
        "gedi_raster_final_dir = join(targets_dir, \"gedi_raster_final\")\n",
        "targets_pkl_final_dir = join(targets_dir, \"pkl_final\")\n",
        "feature_dir = join(base_dir, \"3_features\")\n",
        "feature_alpha_earth_dir = join(feature_dir, \"alpha_earth\")\n",
        "models_dir = join(base_dir, \"5_models\")\n",
        "scenarios_dir = join(base_dir, \"6_scenarios\")\n",
        "predictions_dir = join(base_dir, \"7_predictions\")\n",
        "model_comparison_dir = join(predictions_dir, \"model_comparison\")\n",
        "products_dir = join(model_comparison_dir, \"products\")\n",
        "\n",
        "# Create directories\n",
        "makedirs(predictions_dir, exist_ok=True)\n",
        "makedirs(model_comparison_dir, exist_ok=True)\n",
        "makedirs(products_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koHn-AiGG7KM"
      },
      "outputs": [],
      "source": [
        "# Global function: export an array as a .tif\n",
        "template_tif_path = join(areas_dir, \"template.tif\")\n",
        "nodatavalue = -11111\n",
        "compress = True\n",
        "def export_array_as_tif(input_array, output_tif, template=template_tif_path, nodatavalue=nodatavalue, compress=compress, dtype=gdal.GDT_Float32):\n",
        "    template_ds = gdal.Open(template)\n",
        "    template_band = template_ds.GetRasterBand(1)\n",
        "    template_dimensions, template_projection = template_ds.GetGeoTransform(), template_ds.GetProjection()\n",
        "    if compress: options = ['COMPRESS=ZSTD', 'ZSTD_LEVEL=1'] # Good speed / size ratio\n",
        "    else: options = []\n",
        "    if input_array.dtype == 'int16': dtype = gdal.GDT_Int16\n",
        "    driver = gdal.GetDriverByName(\"GTiff\").Create(output_tif, template_band.XSize, template_band.YSize, 1, dtype, options=options)\n",
        "    driver.GetRasterBand(1).WriteArray(input_array)\n",
        "    driver.GetRasterBand(1).SetNoDataValue(nodatavalue)\n",
        "    driver.SetGeoTransform(template_dimensions)\n",
        "    driver.SetProjection(template_projection)\n",
        "    template_ds = driver = None\n",
        "\n",
        "# Global function: read raster as array\n",
        "def read_raster_as_array(path):\n",
        "    ds = gdal.Open(path)\n",
        "    arr = ds.ReadAsArray()\n",
        "    ds = None\n",
        "    return arr\n",
        "\n",
        "# Global function: Sample raster values\n",
        "def sample_raster_values(pd_dataframe, raster_path, geom_x, geom_y, feature=False, n_threads=1):\n",
        "    # Derive column name from filename\n",
        "    raster_name = raster_path.split('/')[-1][:-4]\n",
        "    if feature: raster_name = 'fea_' + raster_name\n",
        "    # Load raster and extract metadata\n",
        "    raster = gdal.Open(raster_path)\n",
        "    band = raster.GetRasterBand(1)\n",
        "    geotransform = raster.GetGeoTransform()\n",
        "    raster_array = band.ReadAsArray()\n",
        "    nodata = band.GetNoDataValue()\n",
        "    rows, cols = raster_array.shape\n",
        "    fill_value = nodata if nodata is not None else np.nan\n",
        "    # Initialise output array with nodata\n",
        "    sampled_values = np.full(len(geom_x), fill_value, dtype=raster_array.dtype)\n",
        "    # Worker function for threaded sampling\n",
        "    def sample_chunk(start, end):\n",
        "        x_idx = ((geom_x[start:end] - geotransform[0]) / geotransform[1]).astype(int)\n",
        "        y_idx = ((geom_y[start:end] - geotransform[3]) / geotransform[5]).astype(int)\n",
        "        valid = (x_idx >= 0) & (x_idx < cols) & (y_idx >= 0) & (y_idx < rows)\n",
        "        local_values = np.full(end - start, fill_value, dtype=raster_array.dtype)\n",
        "        local_values[valid] = raster_array[y_idx[valid], x_idx[valid]]\n",
        "        sampled_values[start:end] = local_values\n",
        "    # Split points into chunks and process in parallel\n",
        "    n_points = len(geom_x)\n",
        "    chunk_size = (n_points + n_threads - 1) // n_threads\n",
        "    chunk_ranges = [(i, min(i + chunk_size, n_points)) for i in range(0, n_points, chunk_size)]\n",
        "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
        "        executor.map(lambda r: sample_chunk(*r), chunk_ranges)\n",
        "    # Assign to dataframe and release resources\n",
        "    pd_dataframe[raster_name] = sampled_values\n",
        "    raster = band = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lqjsLKZaQXo"
      },
      "source": [
        "# Select model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SqkKHKnaV-8"
      },
      "outputs": [],
      "source": [
        "# Select a baseline model, tested and trained in advance.\n",
        "# The target must have an uncertainty metric - otherwise\n",
        "# skip to the next notebook '8_statistics' and use the outputs\n",
        "# of the '6_scenarios' notebook.\n",
        "model_exists = False\n",
        "for subdir, dirs, files in os.walk(models_dir):\n",
        "  for file in files:\n",
        "    if file == 'model.json':\n",
        "      print(f'selected_model = \"{subdir.split(f\"{models_dir}/\",1)[1]}\"')\n",
        "      model_exists = True\n",
        "if not model_exists:\n",
        "  print(\"No model exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnerzp-gbapN"
      },
      "outputs": [],
      "source": [
        "selected_model = \"agbd_v2_1_alpha_earth_260207_194523\"\n",
        "\n",
        "# This must be True when using AlphaEarth features.\n",
        "alpha_earth = False\n",
        "if 'alpha_earth' in selected_model: alpha_earth = True\n",
        "\n",
        "# Define model directories\n",
        "selected_model_dir = join(models_dir,selected_model)\n",
        "selected_model_json = join(selected_model_dir, \"model.json\")\n",
        "selected_model_descr_dir = join(selected_model_dir, \"model_description.json\")\n",
        "selected_model_dataset_path = join(selected_model_dir, f\"{selected_model}.pkl\")\n",
        "selected_model_dataset = pd.read_pickle(selected_model_dataset_path)\n",
        "\n",
        "# Read description for model dataset attributes\n",
        "with open(join(selected_model_dir,\"model_dataset_description.json\")) as model_dataset_description_json:\n",
        "  model_dataset_description = json.load(model_dataset_description_json)\n",
        "model_dataset_name = model_dataset_description[\"model_dataset_name\"]\n",
        "number_of_columns = model_dataset_description[\"number_of_columns\"]\n",
        "number_of_rows = model_dataset_description[\"number_of_rows\"]\n",
        "id_column = model_dataset_description[\"id_column\"]\n",
        "selected_target = model_dataset_description[\"selected_target\"]\n",
        "uncertainty = model_dataset_description[\"uncertainty\"]\n",
        "covariates_renamed = model_dataset_description[\"covariates_renamed\"]\n",
        "selected_features = model_dataset_description[\"selected_features\"] + model_dataset_description[\"covariates_renamed\"]\n",
        "categorical_features_mappings = model_dataset_description[\"categorical_features_mappings\"]\n",
        "categorical_columns = model_dataset_description[\"categorical_columns\"]\n",
        "descriptive_parameters = model_dataset_description[\"descriptive_parameters\"]\n",
        "sample_imported_dataset = model_dataset_description[\"sample_imported_dataset\"]\n",
        "sample_imported_dataset_by_percent = model_dataset_description[\"sample_imported_dataset_by_percent\"]\n",
        "sample_imported_dataset_value = model_dataset_description[\"sample_imported_dataset_value\"]\n",
        "\n",
        "# Reload hyperparameters\n",
        "with open(selected_model_descr_dir) as model_description_json:\n",
        "  model_description = json.load(model_description_json)\n",
        "final_hyperparameters = ast.literal_eval(model_description[\"hyperparameters\"])\n",
        "\n",
        "# Remove early stopping and replace with mean n_estimators\n",
        "if \"early_stopping_rounds\" in final_hyperparameters:\n",
        "  final_hyperparameters = {k:v for k, v in final_hyperparameters.items() if k != \"early_stopping_rounds\"}\n",
        "  final_hyperparameters[\"n_estimators\"] = round(model_description[\"n_estimators mean\"])\n",
        "\n",
        "# Define directories\n",
        "scenarios_model_dir = join(scenarios_dir, selected_model)\n",
        "features_dir = join(scenarios_model_dir, \"features\")\n",
        "tile_templates_dir = join(scenarios_model_dir, 'tile_templates')\n",
        "feature_stacks_dir = join(scenarios_model_dir, 'feature_stacks')\n",
        "predictions_model_dir = join(predictions_dir, selected_model)\n",
        "model_iterations_dir = join(predictions_model_dir, \"model_iterations\")\n",
        "scenario_iterations_dir = join(predictions_model_dir, \"scenario_iterations\")\n",
        "tile_iteration_cache_dir = join(predictions_model_dir, \"tile_iteration_cache\")\n",
        "tile_prediction_templates_dir = join(predictions_model_dir, \"tile_prediction_templates\")\n",
        "tile_prediction_cache_dir = join(predictions_model_dir, \"tile_prediction_cache\")\n",
        "scenario_predictions_dir = join(predictions_model_dir, \"scenario_predictions\")\n",
        "\n",
        "# Create directories\n",
        "makedirs(predictions_model_dir, exist_ok=True)\n",
        "makedirs(model_iterations_dir, exist_ok=True)\n",
        "makedirs(scenario_iterations_dir, exist_ok=True)\n",
        "makedirs(tile_iteration_cache_dir, exist_ok=True)\n",
        "makedirs(tile_prediction_templates_dir, exist_ok=True)\n",
        "makedirs(tile_prediction_cache_dir, exist_ok=True)\n",
        "makedirs(scenario_predictions_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9-hQ7G37uZi"
      },
      "source": [
        "# Model iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWymSi4ndKUA"
      },
      "outputs": [],
      "source": [
        "# Verify that the target is equal to the mean\n",
        "print(f'mean = \"{selected_target}\"')\n",
        "\n",
        "# Calculate se from columns flagged 'uncertainty'\n",
        "if len(uncertainty)==0:\n",
        "  print(\"There are no flagged uncertainty columns to calculate SE from.\")\n",
        "  print(\"Manually create the metric from the available columns.\")\n",
        "  for col in selected_model_dataset.columns: print(f\"{col}\")\n",
        "else:\n",
        "  for col in selected_model_dataset.columns:\n",
        "    if col in uncertainty and col not in selected_target: print(f'se = \"{col}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBalj00xwmRX"
      },
      "outputs": [],
      "source": [
        "mean = \"tar_agbd\"\n",
        "se = \"tar_agbd_se\"\n",
        "\n",
        "# GEDI L4A agbd_se represents the prediction standard error incorporating both model\n",
        "# parameter uncertainty and residual variance (GEDI L4A ATBD Eq. 9, Kellner et al. 2021).\n",
        "# For Monte Carlo uncertainty propagation, agbd_se directly parameterises the standard\n",
        "# deviation of the prediction error distribution for each footprint.\n",
        "\n",
        "# Set model iterations\n",
        "model_iterations = 100\n",
        "\n",
        "# Define model (y axis changes for each iteration based on mean and se arrays)\n",
        "model_dataset_x = selected_model_dataset[selected_features].copy()\n",
        "for col in categorical_columns:\n",
        "    if col in model_dataset_x.columns:\n",
        "        model_dataset_x[col] = model_dataset_x[col].astype('category')\n",
        "mean_array = selected_model_dataset[mean].values\n",
        "se_array = selected_model_dataset[se].values\n",
        "\n",
        "# Detect model type from existing model or determine from target\n",
        "existing_model_path = join(model_iterations_dir, \"model_iteration_1.json\")\n",
        "if exists(existing_model_path):\n",
        "    # Load existing model and detect type\n",
        "    temp_booster = xgb.Booster()\n",
        "    temp_booster.load_model(existing_model_path)\n",
        "    model_config = json.loads(temp_booster.save_config())\n",
        "\n",
        "    objective_name = model_config['learner']['objective']['name']\n",
        "    num_class = int(model_config['learner']['learner_model_param'].get('num_class', '0'))\n",
        "    classification = any(obj_type in objective_name for obj_type in ['logistic', 'softprob', 'softmax'])\n",
        "    multiclass = classification and num_class > 2\n",
        "else:\n",
        "    # Determine from target variable characteristics\n",
        "    unique_values = len(np.unique(mean_array))\n",
        "    if unique_values <= 10 and all(val == int(val) for val in np.unique(mean_array)):\n",
        "        classification = True\n",
        "        multiclass = unique_values > 2\n",
        "        num_class = unique_values if multiclass else 0\n",
        "    else:\n",
        "        classification = False\n",
        "        multiclass = False\n",
        "        num_class = 0\n",
        "\n",
        "# Set model type\n",
        "if classification:\n",
        "    XGBPredictor = xgb.XGBClassifier(**final_hyperparameters)\n",
        "    if multiclass: print(f\"Model type: Multiclass classification ({num_class} classes)\")\n",
        "    else: print(\"Model type: Binary classification\")\n",
        "else:\n",
        "    XGBPredictor = xgb.XGBRegressor(**final_hyperparameters)\n",
        "    print(\"Model type: Regression\")\n",
        "\n",
        "model_params = XGBPredictor.get_params()\n",
        "model_params['eval_metric'] = model_description['metric_used_for_training']\n",
        "# Default fix for new XGBoost version\n",
        "[model_params.pop(key, None) for key in ['n_estimators', 'enable_categorical', 'missing']]\n",
        "\n",
        "# Progress label\n",
        "model_progress_index = 0\n",
        "model_progress_label = widgets.Label(f\"Model iteration: {model_progress_index}/{model_iterations}\")\n",
        "display(model_progress_label)\n",
        "\n",
        "for model_iteration in range(1,model_iterations+1):\n",
        "  # Set model iteration filename and check if already exists\n",
        "  model_iteration_filename = f\"model_iteration_{model_iteration}.json\"\n",
        "  model_iteration_path = join(model_iterations_dir, model_iteration_filename)\n",
        "  # If model iteration does not exist...\n",
        "  if not exists(model_iteration_path):\n",
        "    # Set the random seed based on iteration for replicability\n",
        "    np.random.seed(model_iteration)\n",
        "    # Set a normal distribution sample as the y for this iteration\n",
        "    model_dataset_y = normal(mean_array, se_array)\n",
        "    # Create DMatrix objects\n",
        "    model_dtrain = xgb.DMatrix(model_dataset_x, model_dataset_y, enable_categorical=True)\n",
        "    # Train the model iteration using the tested hyperparameters\n",
        "    model = xgb.train(model_params,\n",
        "                        model_dtrain,\n",
        "                        num_boost_round=final_hyperparameters['n_estimators'],\n",
        "                        verbose_eval=True)\n",
        "    # Save the model iteration\n",
        "    model.save_model(model_iteration_path)\n",
        "  # Update progress\n",
        "  model_progress_index += 1\n",
        "  model_progress_label.value = f\"Model iteration: {model_progress_index}/{model_iterations}\"\n",
        "print(\"All model iterations have been trained and saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1UxS-kO8_1d"
      },
      "source": [
        "# Scenario iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYxqe0eeKmKi"
      },
      "outputs": [],
      "source": [
        "# Scenarios must be designed and tested using 6_scenarios.ipynb first.\n",
        "\n",
        "# Check existing tile parameters\n",
        "template_tile_list = [f for f in os.listdir(tile_templates_dir) if f.endswith('.tif') and f.startswith('template_tile')]\n",
        "n_tiles = len(template_tile_list)\n",
        "assert n_tiles > 0, \"There are no template tiles. Run the template tiles section, even if only one is created.\"\n",
        "if n_tiles == 1: print(f\"# There is 1 template tile.\\n\")\n",
        "if n_tiles > 1: print(f\"# There are {n_tiles} template tiles.\\n\")\n",
        "\n",
        "# Collect available scenarios from the feature stack tiles directory\n",
        "scenario_stacks_list = []\n",
        "for scenario in os.listdir(feature_stacks_dir):\n",
        "    stack_files = [f for f in os.listdir(join(feature_stacks_dir, scenario)) if f.startswith('feature_stack_')]\n",
        "    if len(stack_files) == n_tiles:\n",
        "        scenario_stacks_list.append(scenario)\n",
        "\n",
        "print(\"scenarios_to_predict = [\")\n",
        "for scenario in sorted(scenario_stacks_list):\n",
        "  print(f'  \"{scenario}\",')\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE-bIxq9F3Vy"
      },
      "outputs": [],
      "source": [
        "# There is 1 template tile.\n",
        "\n",
        "scenarios_to_predict = [\n",
        "  \"2023\",\n",
        "  # \"2024\",\n",
        "  # \"2024_undisturbed_since_1996\",\n",
        "  # \"2024_undisturbed_since_1997\",\n",
        "  # \"2024_undisturbed_since_1998\",\n",
        "  # \"2024_undisturbed_since_1999\",\n",
        "  # \"2024_undisturbed_since_2000\",\n",
        "  # \"2024_undisturbed_since_2001\",\n",
        "  # \"2024_undisturbed_since_2002\",\n",
        "  # \"2024_undisturbed_since_2003\",\n",
        "  # \"2024_undisturbed_since_2004\",\n",
        "  # \"2024_undisturbed_since_2005\",\n",
        "  # \"2024_undisturbed_since_2006\",\n",
        "  # \"2024_undisturbed_since_2007\",\n",
        "  # \"2024_undisturbed_since_2008\",\n",
        "  # \"2024_undisturbed_since_2009\",\n",
        "  # \"2024_undisturbed_since_2010\",\n",
        "  # \"2024_undisturbed_since_2011\",\n",
        "  # \"2024_undisturbed_since_2012\",\n",
        "  # \"2024_undisturbed_since_2013\",\n",
        "  # \"2024_undisturbed_since_2014\",\n",
        "  # \"2024_undisturbed_since_2015\",\n",
        "  # \"2024_undisturbed_since_2016\",\n",
        "  # \"2024_undisturbed_since_2017\",\n",
        "  # \"2024_undisturbed_since_2018\",\n",
        "  # \"2024_undisturbed_since_2019\",\n",
        "  # \"2024_undisturbed_since_2020\",\n",
        "  # \"2024_undisturbed_since_2021\",\n",
        "  # \"2024_undisturbed_since_2022\",\n",
        "  # \"2024_undisturbed_since_2023\",\n",
        "  # \"2024_undisturbed_since_2024\",\n",
        "  # \"2024_undisturbed_since_oldgrowth_1\",\n",
        "  # \"2024_undisturbed_since_oldgrowth_2\",\n",
        "  # \"2024_oldgrowth_recovery_1\",\n",
        "  # \"2024_oldgrowth_recovery_2\",\n",
        "  # \"2024_road_mat_daling_deforestation_2023_30m_degradation_buffer\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VDnbOWSegeVJ"
      },
      "outputs": [],
      "source": [
        "# Set the number of scenario iterations. It must be <= the number of model iterations available.\n",
        "scenario_iterations = 100\n",
        "\n",
        "# Assert the number of scenario iterations is <= the number of model iterations available.\n",
        "model_iterations_available = len([f for f in os.listdir(model_iterations_dir) if f.startswith('model_iteration_') and f.endswith('.json')])\n",
        "assert scenario_iterations <= model_iterations_available, f\"Reduce the number of scenario iterations to <= {model_iterations_available}.\"\n",
        "\n",
        "# Prediction raster precision. GEDI AGBD can be set to 0, any higher is\n",
        "# spurious due to the wide prediction intervals of the source data.\n",
        "raster_precision = 0\n",
        "\n",
        "# Probabilities instead of classes IF binary classification\n",
        "predict_probabilities = False\n",
        "\n",
        "# Classification threshold IF binary classification\n",
        "classification_threshold = 0.5\n",
        "\n",
        "# Detect GPU availability and set predictor type\n",
        "try:\n",
        "    test_array = cupy.array([1, 2, 3])\n",
        "    del test_array\n",
        "    predictor_type = 'gpu_predictor'\n",
        "    gpu_id, use_gpu = 0, True\n",
        "    print(\"GPU detected and accessible - using GPU to load the feature stack and to predict.\")\n",
        "except:\n",
        "    predictor_type = 'cpu_predictor'\n",
        "    gpu_id, use_gpu = -1, False\n",
        "    print(\"GPU not accessible - using CPU prediction\")\n",
        "xgb.set_config(verbosity=0, use_rmm=use_gpu)\n",
        "\n",
        "# Detect model type using first model iteration\n",
        "first_model_path = join(model_iterations_dir, \"model_iteration_1.json\")\n",
        "booster = xgb.Booster()\n",
        "booster.load_model(first_model_path)\n",
        "model_config = json.loads(booster.save_config())\n",
        "objective_name = model_config['learner']['objective']['name']\n",
        "num_class = int(model_config['learner']['learner_model_param'].get('num_class', '0'))\n",
        "classification = any(obj_type in objective_name for obj_type in ['logistic', 'softprob', 'softmax'])\n",
        "multiclass = classification and num_class > 2\n",
        "if classification and multiclass: print(f\"Model type: Multiclass classification ({num_class} classes)\")\n",
        "elif classification: print(\"Model type: Binary classification\")\n",
        "else: print(\"Model type: Regression\")\n",
        "booster = None\n",
        "\n",
        "# Check existing tile parameters\n",
        "template_tile_list = [f for f in os.listdir(tile_templates_dir) if f.endswith('.tif') and f.startswith('template_tile')]\n",
        "n_tiles = len(template_tile_list)\n",
        "if n_tiles < 1: print(\"There are currently no template tiles.\")\n",
        "else:\n",
        "  template_tile = gdal.Open(join(tile_templates_dir, 'template_tile_1.tif'))\n",
        "  template_tile_x = template_tile.GetRasterBand(1).XSize\n",
        "  template_tile = None\n",
        "  print(f\"There are {n_tiles} template tiles.\")\n",
        "\n",
        "# Change template for Alpha Earth predictions, which have different spatial properties\n",
        "if alpha_earth:\n",
        "    if n_tiles == 1: template_base_path = join(tile_templates_dir, 'template_tile_1.tif')\n",
        "    else:\n",
        "        template_base_path = join(feature_alpha_earth_dir,\n",
        "            next(f for f in os.listdir(feature_alpha_earth_dir) if f.endswith('.tif')))\n",
        "else: template_base_path = template_tif_path\n",
        "\n",
        "# Progress labels\n",
        "n_scenarios = len(scenarios_to_predict)\n",
        "scenario_progress_label = widgets.Label(value=f\"Scenario progress: 0 / {n_scenarios}\")\n",
        "tile_progress_label = widgets.Label(value=\"Tile progress: -\")\n",
        "iteration_progress_label = widgets.Label(value=\"Iteration progress: -\")\n",
        "display(scenario_progress_label, tile_progress_label, iteration_progress_label)\n",
        "\n",
        "# Loop through each scenario\n",
        "for scenario_index, scenario in enumerate(scenarios_to_predict):\n",
        "  scenario_feature_stack_dir = join(feature_stacks_dir, scenario)\n",
        "  # Create scenario iterations directory\n",
        "  iterations_dir = join(scenario_iterations_dir, f\"{scenario}_iterations\")\n",
        "  makedirs(iterations_dir, exist_ok=True)\n",
        "\n",
        "  # Check if all scenario iterations already exist\n",
        "  scenario_iteration_list = []\n",
        "  for model_iteration in range(1, scenario_iterations + 1):\n",
        "    prediction_iteration_filename = f\"{scenario}__{selected_model}_iteration_{model_iteration}.tif\"\n",
        "    prediction_iteration_path = join(iterations_dir, prediction_iteration_filename)\n",
        "    scenario_iteration_list.append(prediction_iteration_path)\n",
        "  all_scenario_iterations_exist = all(exists(p) for p in scenario_iteration_list)\n",
        "\n",
        "  if not all_scenario_iterations_exist:\n",
        "    n_stacks = len([f for f in os.listdir(scenario_feature_stack_dir) if f.startswith('feature_stack_')])\n",
        "\n",
        "    # Single-stack prediction\n",
        "    if n_stacks == 1:\n",
        "      tile_progress_label.value = \"Tile progress: 0 / 1\"\n",
        "      iteration_progress_label.value = f\"Iteration progress: 0 / {scenario_iterations}\"\n",
        "\n",
        "      # Load template parameters\n",
        "      template_tile_path = join(tile_templates_dir, \"template_tile_1.tif\")\n",
        "      template_tile = gdal.Open(template_tile_path)\n",
        "      template_tile_y = template_tile.GetRasterBand(1).YSize\n",
        "      template_tile_x = template_tile.GetRasterBand(1).XSize\n",
        "      template_tile = None\n",
        "      n_pixels = template_tile_y * template_tile_x\n",
        "\n",
        "      # Load feature stack and valid indices\n",
        "      stack_path = join(scenario_feature_stack_dir, f\"feature_stack_{scenario}_1.npy\")\n",
        "      indices_path = join(scenario_feature_stack_dir, f\"valid_indices_{scenario}_1.npy\")\n",
        "      feature_stack = np.load(stack_path, mmap_mode='r')\n",
        "      valid_indices = np.load(indices_path)\n",
        "      n_valid = len(valid_indices)\n",
        "\n",
        "      # Load to GPU if available and valid pixels exist\n",
        "      if n_valid > 0 and use_gpu:\n",
        "        try:\n",
        "          feature_stack = cupy.asarray(feature_stack)\n",
        "        except Exception as e:\n",
        "          if \"Memory allocation error\" in str(e) or \"Out of memory\" in str(e):\n",
        "            print(\"GPU memory insufficient, switching to CPU.\")\n",
        "            cupy.get_default_memory_pool().free_all_blocks()\n",
        "            gc.collect()\n",
        "            use_gpu = False\n",
        "            predictor_type = 'cpu_predictor'\n",
        "          else: raise\n",
        "\n",
        "      # Predict all iterations using loaded stack\n",
        "      iteration_progress_index = 0\n",
        "      for model_iteration in range(1, scenario_iterations + 1):\n",
        "        model_path = join(model_iterations_dir, f\"model_iteration_{model_iteration}.json\")\n",
        "        prediction_iteration_filename = f\"{scenario}__{selected_model}_iteration_{model_iteration}.tif\"\n",
        "        prediction_iteration_path = join(iterations_dir, prediction_iteration_filename)\n",
        "\n",
        "        if not exists(prediction_iteration_path):\n",
        "          # Load model iteration\n",
        "          if classification:\n",
        "            XGBPredictor = xgb.XGBClassifier()\n",
        "            XGBPredictor.load_model(model_path)\n",
        "            XGBPredictor.set_params(predictor=predictor_type)\n",
        "            if use_gpu: XGBPredictor.set_params(device='cuda:0')\n",
        "          else:\n",
        "            XGBPredictor = xgb.XGBRegressor()\n",
        "            XGBPredictor.load_model(model_path)\n",
        "            XGBPredictor.set_params(predictor=predictor_type)\n",
        "            if use_gpu: XGBPredictor.set_params(device='cuda:0')\n",
        "\n",
        "          # Handle empty tiles\n",
        "          if n_valid == 0:\n",
        "            if raster_precision == 0:\n",
        "              prediction_array = np.full((template_tile_y, template_tile_x), nodatavalue, dtype=np.int16)\n",
        "            else:\n",
        "              prediction_array = np.full((template_tile_y, template_tile_x), nodatavalue, dtype=np.float32)\n",
        "          else:\n",
        "            # Predict - terminate runtime if GPU prediction fails\n",
        "            try:\n",
        "              if classification and predict_probabilities and not multiclass:\n",
        "                prediction_proba = XGBPredictor.predict_proba(feature_stack)\n",
        "                prediction = prediction_proba[:, 1]\n",
        "              else:\n",
        "                if classification and not multiclass:\n",
        "                  prediction_proba = XGBPredictor.predict_proba(feature_stack)\n",
        "                  prediction = (prediction_proba[:, 1] > classification_threshold).astype(int)\n",
        "                else:\n",
        "                  prediction = XGBPredictor.predict(feature_stack)\n",
        "                  if classification:\n",
        "                    if prediction.ndim > 1 and prediction.shape[1] > 1: prediction = np.argmax(prediction, axis=1)\n",
        "                    prediction = prediction.astype(int)\n",
        "            except Exception as e:\n",
        "              if \"Memory allocation error\" in str(e) or \"Out of memory\" in str(e):\n",
        "                print(\"GPU memory insufficient for prediction. Terminating runtime to save compute units, restart with TPU.\")\n",
        "                runtime.unassign()\n",
        "              else: raise\n",
        "\n",
        "            # Reconstruct full array from valid indices (C-order)\n",
        "            if raster_precision == 0:\n",
        "              prediction_flat = np.full(n_pixels, nodatavalue, dtype=np.int16)\n",
        "              prediction_flat[valid_indices] = np.round(prediction).astype(np.int16)\n",
        "            else:\n",
        "              prediction_flat = np.full(n_pixels, nodatavalue, dtype=np.float32)\n",
        "              prediction_flat[valid_indices] = np.round(prediction, raster_precision)\n",
        "            prediction = None\n",
        "            prediction_array = prediction_flat.reshape((template_tile_y, template_tile_x), order='C')\n",
        "            prediction_flat = None\n",
        "          export_array_as_tif(prediction_array, prediction_iteration_path, template=template_base_path, compress=True)\n",
        "          prediction_array = None\n",
        "\n",
        "        iteration_progress_index += 1\n",
        "        iteration_progress_label.value = f\"Iteration progress: {iteration_progress_index} / {scenario_iterations}\"\n",
        "      # Clean up single-stack feature stack from memory\n",
        "      feature_stack = valid_indices = None\n",
        "      tile_progress_label.value = \"Tile progress: 1 / 1\"\n",
        "\n",
        "    # Tiled prediction - load each stack once, predict all iterations per tile\n",
        "    if n_stacks > 1:\n",
        "      # Create tile cache directories for all iterations\n",
        "      tile_cache_dirs = {}\n",
        "      for model_iteration in range(1, scenario_iterations + 1):\n",
        "        prediction_iteration_filename = f\"{scenario}__{selected_model}_iteration_{model_iteration}.tif\"\n",
        "        tile_cache_iteration_dir = join(tile_iteration_cache_dir, prediction_iteration_filename[:-4])\n",
        "        makedirs(tile_cache_iteration_dir, exist_ok=True)\n",
        "        tile_cache_dirs[model_iteration] = tile_cache_iteration_dir\n",
        "\n",
        "      # Process each tile: load stack once, predict all iterations\n",
        "      for tile_count in range(1, n_stacks + 1):\n",
        "        # Determine which iterations still need this tile\n",
        "        iterations_needing_tile = []\n",
        "        for model_iteration in range(1, scenario_iterations + 1):\n",
        "          iteration_tile_path = join(tile_cache_dirs[model_iteration], f\"scenario_tile_{tile_count}.tif\")\n",
        "          prediction_iteration_path = join(iterations_dir, f\"{scenario}__{selected_model}_iteration_{model_iteration}.tif\")\n",
        "          if not exists(prediction_iteration_path) and not exists(iteration_tile_path):\n",
        "            iterations_needing_tile.append(model_iteration)\n",
        "\n",
        "        # Skip tile if no iterations need it\n",
        "        n_iterations_for_tile = len(iterations_needing_tile)\n",
        "        if n_iterations_for_tile == 0:\n",
        "          iteration_progress_label.value = f\"Iteration progress: {scenario_iterations} / {scenario_iterations}\"\n",
        "          tile_progress_label.value = f\"Tile progress: {tile_count} / {n_stacks}\"\n",
        "          continue\n",
        "        iteration_progress_label.value = f\"Iteration progress: 0 / {n_iterations_for_tile}\"\n",
        "\n",
        "        # Load template tile parameters\n",
        "        template_tile_path = join(tile_templates_dir, f\"template_tile_{tile_count}.tif\")\n",
        "        template_tile = gdal.Open(template_tile_path)\n",
        "        template_tile_y = template_tile.GetRasterBand(1).YSize\n",
        "        template_tile_x = template_tile.GetRasterBand(1).XSize\n",
        "        template_tile = None\n",
        "        n_pixels = template_tile_y * template_tile_x\n",
        "\n",
        "        # Load feature stack and valid indices once per tile\n",
        "        stack_path = join(scenario_feature_stack_dir, f\"feature_stack_{scenario}_{tile_count}.npy\")\n",
        "        indices_path = join(scenario_feature_stack_dir, f\"valid_indices_{scenario}_{tile_count}.npy\")\n",
        "        if not exists(stack_path):\n",
        "          print(f\"Warning: {basename(stack_path)} not found. Skipping tile {tile_count}.\")\n",
        "          continue\n",
        "        feature_stack = np.load(stack_path, mmap_mode='r')\n",
        "        valid_indices = np.load(indices_path)\n",
        "        n_valid = len(valid_indices)\n",
        "\n",
        "        # Handle empty tiles for all needed iterations\n",
        "        if n_valid == 0:\n",
        "          if raster_precision == 0:\n",
        "            prediction_tile = np.full((template_tile_y, template_tile_x), nodatavalue, dtype=np.int16)\n",
        "          else: prediction_tile = np.full((template_tile_y, template_tile_x), nodatavalue, dtype=np.float32)\n",
        "          tile_iteration_index = 0\n",
        "          for model_iteration in iterations_needing_tile:\n",
        "            iteration_tile_path = join(tile_cache_dirs[model_iteration], f\"scenario_tile_{tile_count}.tif\")\n",
        "            export_array_as_tif(prediction_tile, iteration_tile_path, template=template_tile_path, compress=False)\n",
        "            tile_iteration_index += 1\n",
        "            iteration_progress_label.value = f\"Iteration progress: {tile_iteration_index} / {n_iterations_for_tile}\"\n",
        "          prediction_tile = None\n",
        "          tile_progress_label.value = f\"Tile progress: {tile_count} / {n_stacks}\"\n",
        "          continue\n",
        "\n",
        "        # Load to GPU if available\n",
        "        tile_use_gpu = use_gpu\n",
        "        if use_gpu:\n",
        "          try: feature_stack = cupy.asarray(feature_stack)\n",
        "          except Exception as e:\n",
        "            if \"Memory allocation error\" in str(e) or \"Out of memory\" in str(e):\n",
        "              print(f\"GPU memory insufficient for tile {tile_count}, using CPU.\")\n",
        "              cupy.get_default_memory_pool().free_all_blocks()\n",
        "              gc.collect()\n",
        "              tile_use_gpu = False\n",
        "            else: raise\n",
        "\n",
        "        # Predict all needed iterations for this tile\n",
        "        tile_iteration_index = 0\n",
        "        for model_iteration in iterations_needing_tile:\n",
        "          iteration_tile_path = join(tile_cache_dirs[model_iteration], f\"scenario_tile_{tile_count}.tif\")\n",
        "          model_path = join(model_iterations_dir, f\"model_iteration_{model_iteration}.json\")\n",
        "          # Load model iteration\n",
        "          if classification:\n",
        "            XGBPredictor = xgb.XGBClassifier()\n",
        "            XGBPredictor.load_model(model_path)\n",
        "            XGBPredictor.set_params(predictor='gpu_predictor' if tile_use_gpu else 'cpu_predictor')\n",
        "            if tile_use_gpu: XGBPredictor.set_params(device='cuda:0')\n",
        "          else:\n",
        "            XGBPredictor = xgb.XGBRegressor()\n",
        "            XGBPredictor.load_model(model_path)\n",
        "            XGBPredictor.set_params(predictor='gpu_predictor' if tile_use_gpu else 'cpu_predictor')\n",
        "            if tile_use_gpu: XGBPredictor.set_params(device='cuda:0')\n",
        "          # Predict - terminate runtime if GPU prediction fails\n",
        "          try:\n",
        "            if classification and predict_probabilities and not multiclass:\n",
        "              prediction_proba = XGBPredictor.predict_proba(feature_stack)\n",
        "              prediction = prediction_proba[:, 1]\n",
        "            else:\n",
        "              if classification and not multiclass:\n",
        "                prediction_proba = XGBPredictor.predict_proba(feature_stack)\n",
        "                prediction = (prediction_proba[:, 1] > classification_threshold).astype(int)\n",
        "              else:\n",
        "                prediction = XGBPredictor.predict(feature_stack)\n",
        "                if classification:\n",
        "                  if prediction.ndim > 1 and prediction.shape[1] > 1: prediction = np.argmax(prediction, axis=1)\n",
        "                  prediction = prediction.astype(int)\n",
        "          except Exception as e:\n",
        "            if \"Memory allocation error\" in str(e) or \"Out of memory\" in str(e):\n",
        "              print(\"GPU memory insufficient for prediction. Terminating runtime to save compute units, restart with TPU.\")\n",
        "              runtime.unassign()\n",
        "            else: raise\n",
        "\n",
        "          # Reconstruct full tile from valid indices (C-order)\n",
        "          if raster_precision == 0:\n",
        "            prediction_flat = np.full(n_pixels, nodatavalue, dtype=np.int16)\n",
        "            prediction_flat[valid_indices] = np.round(prediction).astype(np.int16)\n",
        "          else:\n",
        "            prediction_flat = np.full(n_pixels, nodatavalue, dtype=np.float32)\n",
        "            prediction_flat[valid_indices] = np.round(prediction, raster_precision)\n",
        "          prediction = None\n",
        "          prediction_tile = prediction_flat.reshape((template_tile_y, template_tile_x), order='C')\n",
        "          prediction_flat = None\n",
        "          export_array_as_tif(prediction_tile, iteration_tile_path, template=template_tile_path, compress=False)\n",
        "          prediction_tile = None\n",
        "\n",
        "          tile_iteration_index += 1\n",
        "          iteration_progress_label.value = f\"Iteration progress: {tile_iteration_index} / {n_iterations_for_tile}\"\n",
        "\n",
        "        # Release tile resources\n",
        "        feature_stack = valid_indices = None\n",
        "        tile_progress_label.value = f\"Tile progress: {tile_count} / {n_stacks}\"\n",
        "\n",
        "      # Merge tiles for each iteration\n",
        "      tile_progress_label.value = \"Tile progress: merging\"\n",
        "      for model_iteration in range(1, scenario_iterations + 1):\n",
        "        prediction_iteration_filename = f\"{scenario}__{selected_model}_iteration_{model_iteration}.tif\"\n",
        "        prediction_iteration_path = join(iterations_dir, prediction_iteration_filename)\n",
        "        tile_cache_iteration_dir = tile_cache_dirs[model_iteration]\n",
        "        if not exists(prediction_iteration_path):\n",
        "          prediction_array = np.empty((0, template_tile_x))\n",
        "          tile_files = sorted([f for f in os.listdir(tile_cache_iteration_dir) if f.endswith('.tif')],\n",
        "                              key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
        "          for tile_file in tile_files:\n",
        "            tile_path = join(tile_cache_iteration_dir, tile_file)\n",
        "            tile_array = read_raster_as_array(tile_path)\n",
        "            prediction_array = np.vstack((prediction_array, tile_array))\n",
        "          export_array_as_tif(prediction_array, prediction_iteration_path, template=template_base_path)\n",
        "          prediction_array = None\n",
        "        # Delete tile cache for this iteration\n",
        "        if exists(tile_cache_iteration_dir):\n",
        "          shutil.rmtree(tile_cache_iteration_dir)\n",
        "\n",
        "        iteration_progress_label.value = f\"Merge progress: {model_iteration} / {scenario_iterations}\"\n",
        "\n",
        "  else:\n",
        "    tile_progress_label.value = \"Tile progress: complete\"\n",
        "    iteration_progress_label.value = \"Iteration progress: complete\"\n",
        "\n",
        "  scenario_progress_label.value = f\"Scenario progress: {scenario_index + 1} / {n_scenarios}\"\n",
        "\n",
        "print(\"\\nScenario iterations complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVDxVP__Jkjf"
      },
      "outputs": [],
      "source": [
        "# Merge oldgrowth iteration pairs\n",
        "# Old-growth scenarios exist in two versions: _1 uses land-use proxy for pre-Landsat\n",
        "# undisturbed forest (e.g. PAs without history of exploitation) and removes all Landsat-derived\n",
        "# disturbance. _2 removes all Landsat-derived disturbance. The merge takes the maximum mean,\n",
        "# avoiding underestimation where proxy may not capture all oldgrowth characteristics of the\n",
        "# entire project area. Merging at iteration level (rather than of the calculated mean)\n",
        "# allows Monte Carlo uncertainty propagation when calculating AGBD percentage loss between\n",
        "# the old-growth alternative scenario baseline to the 'actual' state.\n",
        "\n",
        "# The code block needs to run uninterrupted for statistics to be calculated,\n",
        "# E.g. average number of pixel contributions from each version of each scenario.\n",
        "\n",
        "# Identify oldgrowth _1 iteration directories\n",
        "oldgrowth_v1_dirs = [d for d in os.listdir(scenario_iterations_dir)\n",
        "                     if 'oldgrowth' in d and d.endswith('_1_iterations')]\n",
        "\n",
        "if not oldgrowth_v1_dirs: print(\"No oldgrowth version 1 iteration directories found to merge.\")\n",
        "else:\n",
        "    n_oldgrowth = len(oldgrowth_v1_dirs)\n",
        "    oldgrowth_progress_label = widgets.Label(value=f\"Oldgrowth scenario progress: 0 / {n_oldgrowth}\")\n",
        "    iteration_merge_progress_label = widgets.Label(value=\"Iteration merge progress: -\")\n",
        "    display(oldgrowth_progress_label, iteration_merge_progress_label)\n",
        "\n",
        "    for oldgrowth_index, v1_dir_name in enumerate(oldgrowth_v1_dirs):\n",
        "        # Define directory names and paths\n",
        "        v2_dir_name = v1_dir_name.replace('_1_iterations', '_2_iterations')\n",
        "        merged_dir_name = v1_dir_name.replace('_1_iterations', '_iterations')\n",
        "        v1_dir_path = join(scenario_iterations_dir, v1_dir_name)\n",
        "        v2_dir_path = join(scenario_iterations_dir, v2_dir_name)\n",
        "        merged_dir_path = join(scenario_iterations_dir, merged_dir_name)\n",
        "\n",
        "        # Scenario name for CSV output\n",
        "        scenario_name = v1_dir_name.replace('_1_iterations', '')\n",
        "\n",
        "        # Skip if merged directory already exists with iterations\n",
        "        if exists(merged_dir_path):\n",
        "            existing_merged = [f for f in os.listdir(merged_dir_path) if f.endswith('.tif')]\n",
        "            if existing_merged:\n",
        "                iteration_merge_progress_label.value = f\"Iteration merge progress: skipped (exists)\"\n",
        "                oldgrowth_progress_label.value = f\"Oldgrowth scenario progress: {oldgrowth_index + 1} / {n_oldgrowth}\"\n",
        "                continue\n",
        "\n",
        "        # Check version 2 exists\n",
        "        if not exists(v2_dir_path):\n",
        "            print(f\"Warning: {v2_dir_name} not found, skipping merge for {v1_dir_name}\")\n",
        "            oldgrowth_progress_label.value = f\"Oldgrowth scenario progress: {oldgrowth_index + 1} / {n_oldgrowth}\"\n",
        "            continue\n",
        "\n",
        "        # Collect iteration files from both versions\n",
        "        v1_files = sorted([f for f in os.listdir(v1_dir_path) if f.endswith('.tif')])\n",
        "        v2_files = sorted([f for f in os.listdir(v2_dir_path) if f.endswith('.tif')])\n",
        "        if len(v1_files) != len(v2_files):\n",
        "            print(f\"Warning: iteration count mismatch ({len(v1_files)} vs {len(v2_files)}), skipping {v1_dir_name}\")\n",
        "            oldgrowth_progress_label.value = f\"Oldgrowth scenario progress: {oldgrowth_index + 1} / {n_oldgrowth}\"\n",
        "            continue\n",
        "        makedirs(merged_dir_path, exist_ok=True)\n",
        "        n_iterations = len(v1_files)\n",
        "\n",
        "        # Accumulators for cross-iteration version selection and difference stats\n",
        "        iteration_percentage_v1 = []\n",
        "        iteration_percentage_v2 = []\n",
        "        iteration_mean_absolute_difference = []\n",
        "        iteration_mean_absolute_difference_v1_selected = []\n",
        "        iteration_mean_absolute_difference_v2_selected = []\n",
        "\n",
        "        # Merge each iteration pair\n",
        "        for iteration_index, v1_file in enumerate(v1_files):\n",
        "            # Construct merged filename (remove _1 suffix from scenario name in filename)\n",
        "            merged_file = v1_file.replace('_1__', '__')\n",
        "            merged_path = join(merged_dir_path, merged_file)\n",
        "            if not exists(merged_path):\n",
        "                # Construct v2 filename and paths\n",
        "                v2_file = v1_file.replace('_1__', '_2__')\n",
        "                v1_path = join(v1_dir_path, v1_file)\n",
        "                v2_path = join(v2_dir_path, v2_file)\n",
        "                if not exists(v2_path):\n",
        "                    print(f\"Warning: {v2_file} not found, skipping\")\n",
        "                    continue\n",
        "\n",
        "                # Load both iterations\n",
        "                v1_array = read_raster_as_array(v1_path)\n",
        "                v2_array = read_raster_as_array(v2_path)\n",
        "\n",
        "                # Take maximum value per pixel (nodata remains nodata as both versions share same mask)\n",
        "                merged_array = np.maximum(v1_array, v2_array)\n",
        "\n",
        "                # Per-pixel version selection and absolute difference stats\n",
        "                valid = ~np.isnan(v1_array) & ~np.isnan(v2_array)\n",
        "                absolute_difference = np.abs(v1_array - v2_array)\n",
        "                v1_selected = valid & (v1_array >= v2_array)\n",
        "                v2_selected = valid & (v2_array > v1_array)\n",
        "                n_valid = int(valid.sum())\n",
        "                n_v1 = int(v1_selected.sum())\n",
        "                n_v2 = int(v2_selected.sum())\n",
        "                if n_valid:\n",
        "                    iteration_percentage_v1.append(100 * n_v1 / n_valid)\n",
        "                    iteration_percentage_v2.append(100 * n_v2 / n_valid)\n",
        "                    iteration_mean_absolute_difference.append(float(np.nanmean(absolute_difference[valid])))\n",
        "                if n_v1:\n",
        "                    iteration_mean_absolute_difference_v1_selected.append(float(np.nanmean(absolute_difference[v1_selected])))\n",
        "                if n_v2:\n",
        "                    iteration_mean_absolute_difference_v2_selected.append(float(np.nanmean(absolute_difference[v2_selected])))\n",
        "\n",
        "                # Export merged iteration\n",
        "                export_array_as_tif(merged_array, merged_path, template=v1_path, compress=True)\n",
        "                merged_array = v1_array = v2_array = absolute_difference = None\n",
        "\n",
        "            iteration_merge_progress_label.value = f\"Iteration merge progress: {iteration_index + 1} / {n_iterations}\"\n",
        "\n",
        "        # Summarise and save version selection stats across iterations\n",
        "        if iteration_percentage_v1:\n",
        "            summary = {\n",
        "                'metric': [\n",
        "                    'percentage_v1_pixels', 'percentage_v2_pixels',\n",
        "                    'mean_absolute_difference_all',\n",
        "                    'mean_absolute_difference_v1_selected',\n",
        "                    'mean_absolute_difference_v2_selected'\n",
        "                ],\n",
        "                'min': [\n",
        "                    np.min(iteration_percentage_v1), np.min(iteration_percentage_v2),\n",
        "                    np.min(iteration_mean_absolute_difference),\n",
        "                    np.min(iteration_mean_absolute_difference_v1_selected) if iteration_mean_absolute_difference_v1_selected else np.nan,\n",
        "                    np.min(iteration_mean_absolute_difference_v2_selected) if iteration_mean_absolute_difference_v2_selected else np.nan\n",
        "                ],\n",
        "                'max': [\n",
        "                    np.max(iteration_percentage_v1), np.max(iteration_percentage_v2),\n",
        "                    np.max(iteration_mean_absolute_difference),\n",
        "                    np.max(iteration_mean_absolute_difference_v1_selected) if iteration_mean_absolute_difference_v1_selected else np.nan,\n",
        "                    np.max(iteration_mean_absolute_difference_v2_selected) if iteration_mean_absolute_difference_v2_selected else np.nan\n",
        "                ],\n",
        "                'mean': [\n",
        "                    np.mean(iteration_percentage_v1), np.mean(iteration_percentage_v2),\n",
        "                    np.mean(iteration_mean_absolute_difference),\n",
        "                    np.mean(iteration_mean_absolute_difference_v1_selected) if iteration_mean_absolute_difference_v1_selected else np.nan,\n",
        "                    np.mean(iteration_mean_absolute_difference_v2_selected) if iteration_mean_absolute_difference_v2_selected else np.nan\n",
        "                ]\n",
        "            }\n",
        "            stats_df = pd.DataFrame(summary).round(4)\n",
        "            stats_csv_path = join(predictions_model_dir, f\"{scenario_name}_version_percentage.csv\")\n",
        "            stats_df.to_csv(stats_csv_path, index=False)\n",
        "            print(f\"\\n{scenario_name} version selection stats (across {len(iteration_percentage_v1)} iterations):\")\n",
        "            print(stats_df.to_string(index=False))\n",
        "            print(f\"Saved to {stats_csv_path}\\n\")\n",
        "\n",
        "        oldgrowth_progress_label.value = f\"Oldgrowth scenario progress: {oldgrowth_index + 1} / {n_oldgrowth}\"\n",
        "\n",
        "    print(\"Oldgrowth iteration merging complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario predictions"
      ],
      "metadata": {
        "id": "BiP-LeK_oCCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect scenarios with iterations\n",
        "# Excludes oldgrowth _1 and _2 variants since merged versions are used for statistics\n",
        "scenarios_iterations_list = []\n",
        "for subdir in os.listdir(scenario_iterations_dir):\n",
        "    scenario_name = subdir[:-11]\n",
        "    if 'oldgrowth' in scenario_name and (scenario_name.endswith('_1') or scenario_name.endswith('_2')):\n",
        "        continue\n",
        "    scenarios_iterations_list.append(scenario_name)\n",
        "\n",
        "# Select scenarios to calculate mean, confidence intervals and uncertainty\n",
        "print(\"scenarios_to_calculate = [\")\n",
        "for scenario in sorted(scenarios_iterations_list):\n",
        "    print(f'  \"{scenario}\",')\n",
        "print(\"]\")"
      ],
      "metadata": {
        "id": "7tU93Ftoo14L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scenarios_to_calculate = [\n",
        "  \"2023\",\n",
        "  # \"2024\",\n",
        "  # \"2024_undisturbed_since_1996\",\n",
        "  # \"2024_undisturbed_since_1997\",\n",
        "  # \"2024_undisturbed_since_1998\",\n",
        "  # \"2024_undisturbed_since_1999\",\n",
        "  # \"2024_undisturbed_since_2000\",\n",
        "  # \"2024_undisturbed_since_2001\",\n",
        "  # \"2024_undisturbed_since_2002\",\n",
        "  # \"2024_undisturbed_since_2003\",\n",
        "  # \"2024_undisturbed_since_2004\",\n",
        "  # \"2024_undisturbed_since_2005\",\n",
        "  # \"2024_undisturbed_since_2006\",\n",
        "  # \"2024_undisturbed_since_2007\",\n",
        "  # \"2024_undisturbed_since_2008\",\n",
        "  # \"2024_undisturbed_since_2009\",\n",
        "  # \"2024_undisturbed_since_2010\",\n",
        "  # \"2024_undisturbed_since_2011\",\n",
        "  # \"2024_undisturbed_since_2012\",\n",
        "  # \"2024_undisturbed_since_2013\",\n",
        "  # \"2024_undisturbed_since_2014\",\n",
        "  # \"2024_undisturbed_since_2015\",\n",
        "  # \"2024_undisturbed_since_2016\",\n",
        "  # \"2024_undisturbed_since_2017\",\n",
        "  # \"2024_undisturbed_since_2018\",\n",
        "  # \"2024_undisturbed_since_2019\",\n",
        "  # \"2024_undisturbed_since_2020\",\n",
        "  # \"2024_undisturbed_since_2021\",\n",
        "  # \"2024_undisturbed_since_2022\",\n",
        "  # \"2024_undisturbed_since_2023\",\n",
        "  # \"2024_undisturbed_since_2024\",\n",
        "  # \"2024_undisturbed_since_oldgrowth\",\n",
        "  # \"2024_oldgrowth_recovery\",\n",
        "  # \"2024_road_mat_daling_deforestation_2023_30m_degradation_buffer\",\n",
        "]"
      ],
      "metadata": {
        "id": "ucUSlOBno3Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check iteration quality\n",
        "# High proportion of values <= 0 may indicate corrupt iterations.\n",
        "# Delete and repredict affected files if necessary.\n",
        "check_iterations = False\n",
        "nonpositive_threshold_percent = 1\n",
        "\n",
        "# Check the number of prediction iterations\n",
        "scenario_iterations = {}\n",
        "for scenario in scenarios_to_calculate:\n",
        "    iterations_dir = join(scenario_iterations_dir, f\"{scenario}_iterations\")\n",
        "    iterations = 0\n",
        "    for subdir in os.listdir(iterations_dir):\n",
        "        if subdir.endswith(\".tif\"):\n",
        "            if check_iterations:\n",
        "                iteration_path = join(iterations_dir, subdir)\n",
        "                iteration_array = read_raster_as_array(iteration_path)\n",
        "                valid_mask = iteration_array != nodatavalue\n",
        "                n_valid = np.count_nonzero(valid_mask)\n",
        "                if n_valid > 0:\n",
        "                    nonpositive_count = np.count_nonzero(iteration_array[valid_mask] <= 0)\n",
        "                    nonpositive_percent = (nonpositive_count / n_valid) * 100\n",
        "                    if nonpositive_percent > nonpositive_threshold_percent:\n",
        "                        print(f\"Warning: {subdir} has {nonpositive_percent:.1f}% values <= 0 in valid pixels.\")\n",
        "            iterations += 1\n",
        "    scenario_iterations[scenario] = iterations\n",
        "    print(f\"There are {iterations} prediction iterations for scenario {scenario} statistics.\")"
      ],
      "metadata": {
        "id": "2wI7hE12oRjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory-aware tiling for statistics calculation.\n",
        "override_n_prediction_tiles = True\n",
        "n_prediction_tiles_override = 1\n",
        "memory_utilisation = 0.9 # Set to <= 0.9 to ensure crashes are avoided\n",
        "\n",
        "assert memory_utilisation > 0 and memory_utilisation <= 1, \"Set memory_utilisation to a value between 0 and 1\"\n",
        "\n",
        "# Get raster dimensions from first iteration of first scenario\n",
        "first_scenario = scenarios_to_calculate[0]\n",
        "first_iterations_dir = join(scenario_iterations_dir, f\"{first_scenario}_iterations\")\n",
        "first_iteration_file = next(f for f in os.listdir(first_iterations_dir) if f.endswith('.tif'))\n",
        "first_iteration_path = join(first_iterations_dir, first_iteration_file)\n",
        "first_ds = gdal.Open(first_iteration_path)\n",
        "raster_height = first_ds.RasterYSize\n",
        "raster_width = first_ds.RasterXSize\n",
        "first_ds = None\n",
        "print(f\"Iteration raster dimensions: {raster_width} x {raster_height} pixels.\")\n",
        "\n",
        "# Max iteration count across scenarios for worst-case memory estimate\n",
        "max_iterations = max(scenario_iterations.values())\n",
        "\n",
        "# Stack per tile: n_iterations * tile_h * width * 8 bytes (float64)\n",
        "# Factor of 1.1 accounts for working arrays\n",
        "bytes_per_row = max_iterations * raster_width * 8 * 1.1\n",
        "total_memory_needed = bytes_per_row * raster_height\n",
        "print(f\"RAM required for full statistics pass: ~{total_memory_needed / (1024**3):.3f} GB\")\n",
        "print(f\"RAM currently available: {psutil.virtual_memory().available / (1024**3):.3f} GB\")\n",
        "n_prediction_tiles = max(1, int(np.ceil(total_memory_needed / (psutil.virtual_memory().available * memory_utilisation))))\n",
        "\n",
        "# Calculate prediction tile dimensions (split on y-axis only)\n",
        "prediction_tile_height = int(np.ceil(raster_height / n_prediction_tiles))\n",
        "prediction_tile_height_remainder = raster_height % prediction_tile_height\n",
        "n_prediction_tiles = max(1, len(range(0, raster_height, prediction_tile_height)))\n",
        "\n",
        "if override_n_prediction_tiles:\n",
        "    prediction_tile_height = int(np.ceil(raster_height / n_prediction_tiles_override))\n",
        "    prediction_tile_height_remainder = raster_height % prediction_tile_height\n",
        "    n_prediction_tiles = n_prediction_tiles_override\n",
        "    print(\"n_prediction_tiles has been overridden.\")\n",
        "\n",
        "print(f\"The statistics calculation should be divided into {n_prediction_tiles} tiles.\")\n",
        "\n",
        "# Check existing prediction template tiles\n",
        "prediction_template_tile_list = [f for f in os.listdir(tile_prediction_templates_dir) if f.endswith('.tif') and f.startswith('prediction_template_tile')]\n",
        "n_prediction_tiles_exist = len(prediction_template_tile_list)\n",
        "\n",
        "if n_prediction_tiles_exist < 1: print(\"There are currently no prediction template tiles.\")\n",
        "if n_prediction_tiles_exist >= 1:\n",
        "    prediction_tile_ds = gdal.Open(join(tile_prediction_templates_dir, 'prediction_template_tile_1.tif'))\n",
        "    prediction_tile_height_exist = prediction_tile_ds.GetRasterBand(1).YSize\n",
        "    prediction_tile_ds = None\n",
        "    prediction_tile_last_ds = gdal.Open(join(tile_prediction_templates_dir, f'prediction_template_tile_{n_prediction_tiles_exist}.tif'))\n",
        "    prediction_tile_height_remainder_exist = prediction_tile_last_ds.GetRasterBand(1).YSize\n",
        "    prediction_tile_last_ds = None\n",
        "    if n_prediction_tiles_exist == 1:\n",
        "        print(f\"There is a single prediction 'tile' with a height of {prediction_tile_height_exist} pixels.\")\n",
        "        prediction_tile_height_remainder_exist = 0\n",
        "    else:\n",
        "        print(f\"There are {n_prediction_tiles_exist} prediction template tiles, the first {n_prediction_tiles_exist - 1} having a height of {prediction_tile_height_exist} pixels, the last {prediction_tile_height_remainder_exist} pixels.\")\n",
        "\n",
        "# Check if prediction tiles need to be changed\n",
        "change_prediction_tiles = True\n",
        "if override_n_prediction_tiles:\n",
        "    if n_prediction_tiles == n_prediction_tiles_exist: change_prediction_tiles = False\n",
        "if n_prediction_tiles == n_prediction_tiles_exist and prediction_tile_height == prediction_tile_height_exist:\n",
        "    change_prediction_tiles = False\n",
        "\n",
        "if change_prediction_tiles and n_prediction_tiles_exist >= 1:\n",
        "    # Prompt before deleting cached prediction tiles\n",
        "    print(f\"\\nPrediction tile count has changed from {n_prediction_tiles_exist} to {n_prediction_tiles}.\")\n",
        "    print(\"This will delete existing prediction template tiles and all cached prediction tiles.\")\n",
        "    print(\"Type 'OK' to proceed, or anything else to abort.\")\n",
        "    confirmation = input(\"Confirm: \").strip()\n",
        "    if confirmation != \"OK\":\n",
        "        raise RuntimeError(\"Aborted. Adjust override settings or re-run to keep existing tiles.\")\n",
        "\n",
        "if change_prediction_tiles:\n",
        "    # Delete existing prediction template tiles\n",
        "    for f in os.listdir(tile_prediction_templates_dir):\n",
        "        if f.startswith('prediction_template_tile') and f.endswith('.tif'):\n",
        "            os.remove(join(tile_prediction_templates_dir, f))\n",
        "\n",
        "    # Delete cached prediction tiles for all scenarios\n",
        "    for subdir in os.listdir(tile_prediction_cache_dir):\n",
        "        subdir_path = join(tile_prediction_cache_dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            shutil.rmtree(subdir_path)\n",
        "\n",
        "    # Generate new prediction template tiles from first iteration raster\n",
        "    tile_number = 1\n",
        "    for y_start in range(0, raster_height, prediction_tile_height):\n",
        "        if prediction_tile_height_remainder != 0 and tile_number == n_prediction_tiles:\n",
        "            current_height = prediction_tile_height_remainder\n",
        "        else: current_height = prediction_tile_height\n",
        "        tiling_string = (f\"gdal_translate -of GTIFF -srcwin 0, {y_start}, {raster_width}, {current_height} \"\n",
        "                         f\"{first_iteration_path} {tile_prediction_templates_dir}/prediction_template_tile_{tile_number}.tif\")\n",
        "        os.system(tiling_string)\n",
        "        tile_number += 1\n",
        "    print(\"Prediction template tile creation complete.\")\n",
        "\n",
        "else: print(\"No changes to existing prediction tiles are required.\")"
      ],
      "metadata": {
        "id": "EcA5xKwFoDgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Raster precision settings\n",
        "mean_precision = 2\n",
        "ci_precision = 2\n",
        "uncertainty_precision = 2\n",
        "\n",
        "# Quantify scenario predictions using Monte Carlo simulation with percentile-based\n",
        "# confidence intervals (IPCC Approach 2) and percentage uncertainty.\n",
        "\n",
        "# Each model iteration sampled target values from normal distributions using GEDI L4A\n",
        "# agbd (mean) and agbd_se (standard deviation). The resulting collection of respective\n",
        "# prediction iterations represent the distribution of possible AGBD values\n",
        "# given measurement uncertainty.\n",
        "\n",
        "# Confidence intervals derive from percentiles of the empirical (actual rather\n",
        "# than theoretical) distribution: CI half-width = (P_97.5 - P_2.5) / 2\n",
        "# Percentiles directly characterise the distribution without assuming normality,\n",
        "# are robust to outliers, and handle bounded distributions (AGBD >= 0).\n",
        "\n",
        "# Percentage uncertainty = CI half-width / mean * 100\n",
        "# This represents precision of estimates given input uncertainty, not total predictive\n",
        "# accuracy (Liang et al. 2023, p.6).\n",
        "\n",
        "# References:\n",
        "# IPCC (2006) Guidelines Vol.1 Ch.3: Uncertainties, Section 3.2.3.2\n",
        "# IPCC (2019) Refinement Vol.1 Ch.3: Uncertainties, Section 3.2.3.2\n",
        "# Liang et al. (2023) Remote Sensing of Environment 284:113367\n",
        "\n",
        "# Check prediction template tiles\n",
        "prediction_template_tile_list = [f for f in os.listdir(tile_prediction_templates_dir) if f.endswith('.tif') and f.startswith('prediction_template_tile')]\n",
        "n_prediction_tiles = len(prediction_template_tile_list)\n",
        "assert n_prediction_tiles > 0, \"There are no prediction template tiles. Run the previous section.\"\n",
        "\n",
        "# Prediction template tile dimensions\n",
        "prediction_tile_1_ds = gdal.Open(join(tile_prediction_templates_dir, 'prediction_template_tile_1.tif'))\n",
        "prediction_tile_width = prediction_tile_1_ds.GetRasterBand(1).XSize\n",
        "prediction_tile_1_ds = None\n",
        "print(f\"There are {n_prediction_tiles} prediction template tiles.\")\n",
        "\n",
        "# Progress labels\n",
        "scenario_progress_index = 0\n",
        "scenario_progress_label = widgets.Label(f\"Scenario predictions progress: {scenario_progress_index}/{len(scenarios_to_calculate)}\")\n",
        "tile_progress_label = widgets.Label(value=\"Prediction tile progress: -\")\n",
        "iteration_progress_label = widgets.Label(value=\"Iteration loading progress: -\")\n",
        "display(scenario_progress_label, tile_progress_label, iteration_progress_label)\n",
        "\n",
        "# Loop through the scenarios\n",
        "for scenario, iteration_count in scenario_iterations.items():\n",
        "    base_filename = f\"{scenario}__{selected_model}\"\n",
        "    iterations_dir = join(scenario_iterations_dir, f\"{scenario}_iterations\")\n",
        "\n",
        "    # Define output paths\n",
        "    mean_filename = f\"mean__{base_filename}.tif\"\n",
        "    mean_path = join(scenario_predictions_dir, mean_filename)\n",
        "    ci_filename = f\"ci95__{base_filename}.tif\"\n",
        "    ci_path = join(scenario_predictions_dir, ci_filename)\n",
        "    uncertainty_filename = f\"uncertainty__{base_filename}.tif\"\n",
        "    uncertainty_path = join(scenario_predictions_dir, uncertainty_filename)\n",
        "\n",
        "    # If any output does not exist, recalculate all\n",
        "    if not exists(mean_path) or not exists(ci_path) or not exists(uncertainty_path):\n",
        "\n",
        "        # Create scenario cache directory\n",
        "        scenario_cache_dir = join(tile_prediction_cache_dir, scenario)\n",
        "        makedirs(scenario_cache_dir, exist_ok=True)\n",
        "\n",
        "        # Collect iteration file paths\n",
        "        iteration_paths = [join(iterations_dir, f) for f in os.listdir(iterations_dir) if f.endswith(\".tif\")]\n",
        "        n_iterations = len(iteration_paths)\n",
        "\n",
        "        # Percentile interpolation indices (constant across tiles)\n",
        "        n = n_iterations\n",
        "        lower_index = 0.025 * (n - 1)\n",
        "        upper_index = 0.975 * (n - 1)\n",
        "        lower_floor = int(np.floor(lower_index))\n",
        "        upper_floor = int(np.floor(upper_index))\n",
        "        lower_fraction = lower_index - lower_floor\n",
        "        upper_fraction = upper_index - upper_floor\n",
        "\n",
        "        # Open all iteration datasets once (read strips per tile)\n",
        "        iteration_progress_label.value = f\"Opening {n_iterations} iteration datasets\"\n",
        "        iteration_datasets = [gdal.Open(p) for p in iteration_paths]\n",
        "\n",
        "        # Process each prediction tile\n",
        "        y_start = 0\n",
        "        for tile_idx in range(1, n_prediction_tiles + 1):\n",
        "            tile_progress_label.value = f\"Prediction tile progress: {tile_idx} / {n_prediction_tiles}\"\n",
        "\n",
        "            # Cached tile output paths\n",
        "            mean_tile_path = join(scenario_cache_dir, f\"mean_{tile_idx}.tif\")\n",
        "            ci_tile_path = join(scenario_cache_dir, f\"ci95_{tile_idx}.tif\")\n",
        "            uncertainty_tile_path = join(scenario_cache_dir, f\"uncertainty_{tile_idx}.tif\")\n",
        "\n",
        "            # Get tile dimensions from prediction template\n",
        "            prediction_template_path = join(tile_prediction_templates_dir, f\"prediction_template_tile_{tile_idx}.tif\")\n",
        "            prediction_template_ds = gdal.Open(prediction_template_path)\n",
        "            current_tile_height = prediction_template_ds.GetRasterBand(1).YSize\n",
        "            current_tile_width = prediction_template_ds.GetRasterBand(1).XSize\n",
        "            prediction_template_ds = None\n",
        "\n",
        "            # Skip tile if all three cached outputs exist\n",
        "            if exists(mean_tile_path) and exists(ci_tile_path) and exists(uncertainty_tile_path):\n",
        "                iteration_progress_label.value = f\"Tile {tile_idx}: skipped (cached)\"\n",
        "                y_start += current_tile_height\n",
        "                continue\n",
        "\n",
        "            # Load strip from each iteration into stack\n",
        "            tile_stack = np.empty((n_iterations, current_tile_height, current_tile_width), dtype=np.float64)\n",
        "            for iter_idx, ds in enumerate(iteration_datasets):\n",
        "                band = ds.GetRasterBand(1)\n",
        "                tile_stack[iter_idx] = band.ReadAsArray(0, y_start, current_tile_width, current_tile_height)\n",
        "                iteration_progress_label.value = f\"Tile {tile_idx}: loading iteration {iter_idx + 1} / {n_iterations}\"\n",
        "\n",
        "            # Valid mask from first iteration (identical across all iterations)\n",
        "            valid_mask = tile_stack[0] != nodatavalue\n",
        "\n",
        "            # Calculate mean across iterations\n",
        "            mean_array = np.mean(tile_stack, axis=0)\n",
        "\n",
        "            # Sort in-place, index at percentile positions. Faster than np.nanpercentile.\n",
        "            # Nodata values (-11111) sort to bottom; excluded by valid_mask.\n",
        "            tile_stack.sort(axis=0)\n",
        "            sorted_stack = tile_stack\n",
        "            tile_stack = None\n",
        "\n",
        "            # Interpolate between adjacent sorted values\n",
        "            ci_lower = (sorted_stack[lower_floor] * (1 - lower_fraction) +\n",
        "                        sorted_stack[min(lower_floor + 1, n - 1)] * lower_fraction)\n",
        "            ci_upper = (sorted_stack[upper_floor] * (1 - upper_fraction) +\n",
        "                        sorted_stack[min(upper_floor + 1, n - 1)] * upper_fraction)\n",
        "            sorted_stack = None\n",
        "\n",
        "            # CI half-width\n",
        "            ci_halfwidth = (ci_upper - ci_lower) / 2\n",
        "\n",
        "            # Relative uncertainty as percentage\n",
        "            percentage_uncertainty = np.zeros_like(mean_array, dtype=np.float64)\n",
        "            nonzero_mean_mask = valid_mask & (mean_array != 0)\n",
        "            percentage_uncertainty[nonzero_mean_mask] = (ci_halfwidth[nonzero_mean_mask] / np.abs(mean_array[nonzero_mean_mask])) * 100\n",
        "\n",
        "            # Round and apply nodata mask\n",
        "            if mean_precision == 0:\n",
        "                mean_rounded = np.where(valid_mask, np.round(mean_array, mean_precision).astype(np.int16), nodatavalue).astype(np.int16)\n",
        "            else:\n",
        "                mean_rounded = np.where(valid_mask, np.round(mean_array, mean_precision), nodatavalue)\n",
        "            if ci_precision == 0:\n",
        "                ci_rounded = np.where(valid_mask, np.round(ci_halfwidth, ci_precision).astype(np.int16), nodatavalue).astype(np.int16)\n",
        "            else:\n",
        "                ci_rounded = np.where(valid_mask, np.round(ci_halfwidth, ci_precision), nodatavalue)\n",
        "            if uncertainty_precision == 0:\n",
        "                uncertainty_rounded = np.where(valid_mask, np.round(percentage_uncertainty, uncertainty_precision).astype(np.int16), nodatavalue).astype(np.int16)\n",
        "            else:\n",
        "                uncertainty_rounded = np.where(valid_mask, np.round(percentage_uncertainty, uncertainty_precision), nodatavalue)\n",
        "\n",
        "            # Export mean, CI and uncertainty tile rasters to cache\n",
        "            export_array_as_tif(mean_rounded, mean_tile_path, template=prediction_template_path, compress=True)\n",
        "            export_array_as_tif(ci_rounded, ci_tile_path, template=prediction_template_path, compress=True)\n",
        "            export_array_as_tif(uncertainty_rounded, uncertainty_tile_path, template=prediction_template_path, compress=True)\n",
        "            mean_rounded = ci_rounded = uncertainty_rounded = None\n",
        "            mean_array = ci_halfwidth = percentage_uncertainty = None\n",
        "\n",
        "            # Update y offset\n",
        "            y_start += current_tile_height\n",
        "\n",
        "        # Close iteration datasets\n",
        "        iteration_datasets = None\n",
        "\n",
        "        # Merge cached tiles into final rasters\n",
        "        tile_progress_label.value = \"Prediction tile progress: merging\"\n",
        "        for output_path, prefix in [(mean_path, \"mean\"), (ci_path, \"ci95\"), (uncertainty_path, \"uncertainty\")]:\n",
        "            merged_array = np.empty((0, prediction_tile_width))\n",
        "            for tile_idx in range(1, n_prediction_tiles + 1):\n",
        "                tile_path = join(scenario_cache_dir, f\"{prefix}_{tile_idx}.tif\")\n",
        "                tile_array = read_raster_as_array(tile_path)\n",
        "                merged_array = np.vstack((merged_array, tile_array))\n",
        "            export_array_as_tif(merged_array, output_path, template=first_iteration_path)\n",
        "            merged_array = None\n",
        "\n",
        "        # Delete scenario cache directory\n",
        "        shutil.rmtree(scenario_cache_dir)\n",
        "\n",
        "    else:\n",
        "        tile_progress_label.value = \"Prediction tile progress: skipped (exists)\"\n",
        "        iteration_progress_label.value = \"Iteration loading progress: skipped (exists)\"\n",
        "        print(f\"{mean_filename}, {ci_filename} and {uncertainty_filename} already exist.\")\n",
        "\n",
        "    scenario_progress_index += 1\n",
        "    scenario_progress_label.value = f\"Scenario predictions progress: {scenario_progress_index}/{len(scenarios_to_calculate)}\"\n",
        "\n",
        "print(\"\\nStatistics calculations complete.\")"
      ],
      "metadata": {
        "id": "MDh9J_WzoF8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model comparison"
      ],
      "metadata": {
        "id": "mFRSKZkpTiqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GEDI raster patterns\n",
        "l4d_prefix, l4d_suffix = \"GEDI04_D_V2_original_epsg32648_UTM\", \"_agbd.tif\"\n",
        "l4b_filename = \"GEDI04_B_V2_1_reprojected_epsg4326_WGS84_R01000M.tif\"\n",
        "veg_grid_filename = \"GEDI_vegetation_grid_original_epsg6933_EASE-Grid_agbd-a0_20190417_20230316.tif\"\n",
        "\n",
        "# Forest mask year 2023 used for all products, as this was the final GEDI data collection year\n",
        "gedi_mask_year = 2023\n",
        "\n",
        "# Template for clipping\n",
        "template_gdf = gpd.read_file(join(polygons_dir, \"template.gpkg\"))\n",
        "\n",
        "# Locate GEDI product rasters\n",
        "gedi_products = {'L4D': [], 'L4B': None, 'vegetation_grid': None}\n",
        "gedi04d_dir = join(gedi_raster_final_dir, \"GEDI04_D_V2\")\n",
        "gedi04b_dir = join(gedi_raster_final_dir, \"GEDI04_B_V2_1\")\n",
        "veg_dir = join(gedi_raster_final_dir, \"GEDI_vegetation_grid\")\n",
        "\n",
        "if exists(gedi04d_dir):\n",
        "    gedi_products['L4D'] = [join(gedi04d_dir, f) for f in os.listdir(gedi04d_dir) if f.startswith(l4d_prefix) and f.endswith(l4d_suffix)]\n",
        "print(f\"# L4D grid: {len(gedi_products['L4D'])} UTM tiles.\")\n",
        "\n",
        "if exists(gedi04b_dir) and exists(join(gedi04b_dir, l4b_filename)):\n",
        "    gedi_products['L4B'] = join(gedi04b_dir, l4b_filename)\n",
        "print(f\"# L4B grid: {'found' if gedi_products['L4B'] else 'not found'}\")\n",
        "\n",
        "if exists(veg_dir) and exists(join(veg_dir, veg_grid_filename)):\n",
        "    gedi_products['vegetation_grid'] = join(veg_dir, veg_grid_filename)\n",
        "print(f\"# Vegetation grid (AGBD): {'found' if gedi_products['vegetation_grid'] else 'not found'}\")\n",
        "\n",
        "# Copy and mask GEDI rasters to forest extent\n",
        "print(\"\\nCopying and masking GEDI rasters\")\n",
        "\n",
        "# Mask raster to forest extent, resampling mask if needed\n",
        "def apply_forest_mask(raster_path, mask_path, output_path):\n",
        "    if exists(output_path):\n",
        "        print(f\"  Exists: {os.path.basename(output_path)}\")\n",
        "        return\n",
        "    raster_ds = gdal.Open(raster_path)\n",
        "    raster_proj = raster_ds.GetProjection()\n",
        "    raster_gt = raster_ds.GetGeoTransform()\n",
        "    raster_xsize, raster_ysize = raster_ds.RasterXSize, raster_ds.RasterYSize\n",
        "    raster_bounds = [raster_gt[0], raster_gt[3] + raster_gt[5] * raster_ysize, raster_gt[0] + raster_gt[1] * raster_xsize, raster_gt[3]]\n",
        "    mask_resampled = gdal.Warp('', mask_path, options=gdal.WarpOptions(format='MEM', dstSRS=raster_proj, outputBounds=raster_bounds, width=raster_xsize, height=raster_ysize, resampleAlg='near', dstNodata=nodatavalue))\n",
        "    mask_array = mask_resampled.GetRasterBand(1).ReadAsArray()\n",
        "    raster_array = raster_ds.GetRasterBand(1).ReadAsArray()\n",
        "    # convert original data gaps to -1 (non-forest becomes nodatavalue)\n",
        "    raster_array = np.where(raster_array == nodatavalue, -1, raster_array)\n",
        "    raster_array = np.where(mask_array == 1, raster_array, nodatavalue)\n",
        "    driver = gdal.GetDriverByName('GTiff')\n",
        "    out_ds = driver.Create(output_path, raster_xsize, raster_ysize, 1, raster_ds.GetRasterBand(1).DataType, options=['COMPRESS=ZSTD', 'ZSTD_LEVEL=1'])\n",
        "    out_ds.SetGeoTransform(raster_gt)\n",
        "    out_ds.SetProjection(raster_proj)\n",
        "    out_band = out_ds.GetRasterBand(1)\n",
        "    out_band.WriteArray(raster_array)\n",
        "    out_band.SetNoDataValue(nodatavalue)\n",
        "    out_ds = raster_ds = mask_resampled = None\n",
        "    print(f\"  Created: {os.path.basename(output_path)}\")\n",
        "\n",
        "gedi_mask_path = join(masks_dir, f\"mask_forest_{gedi_mask_year}.tif\")\n",
        "\n",
        "# Mask L4D rasters\n",
        "l4d_masked = []\n",
        "if gedi_products['L4D']:\n",
        "    print(\"L4D rasters:\")\n",
        "    for raster_path in gedi_products['L4D']:\n",
        "        filename = os.path.basename(raster_path).replace('_original', '').replace('.tif', f'_masked_{gedi_mask_year}.tif')\n",
        "        output_path = join(products_dir, filename)\n",
        "        apply_forest_mask(raster_path, gedi_mask_path, output_path)\n",
        "        l4d_masked.append(output_path)\n",
        "\n",
        "# Mask L4B raster\n",
        "l4b_masked = None\n",
        "if gedi_products['L4B']:\n",
        "    print(\"L4B raster:\")\n",
        "    filename = os.path.basename(gedi_products['L4B']).replace('_original', '').replace('.tif', f'_masked_{gedi_mask_year}.tif')\n",
        "    output_path = join(products_dir, filename)\n",
        "    apply_forest_mask(gedi_products['L4B'], gedi_mask_path, output_path)\n",
        "    l4b_masked = output_path\n",
        "\n",
        "# Mask vegetation_grid raster\n",
        "veg_masked = None\n",
        "if gedi_products['vegetation_grid']:\n",
        "    print(\"Vegetation grid raster:\")\n",
        "    filename = os.path.basename(gedi_products['vegetation_grid']).replace('_original', '').replace('.tif', f'_masked_{gedi_mask_year}.tif')\n",
        "    output_path = join(products_dir, filename)\n",
        "    apply_forest_mask(gedi_products['vegetation_grid'], gedi_mask_path, output_path)\n",
        "    veg_masked = output_path\n",
        "\n",
        "print(f\"\\nMasked rasters: L4D={len(l4d_masked)}, L4B={'1' if l4b_masked else '0'}, Vegetation grid={'1' if veg_masked else '0'}\")"
      ],
      "metadata": {
        "id": "lulH4FkDPr4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L4D validation metrics URL\n",
        "l4d_gpkg_url = \"https://data.ornldaac.earthdata.nasa.gov/public/gedi/GEDI_L4D_Imputed_Waveforms/comp/GEDI_L4D_20190418_20230316_validation_metrics.gpkg\"\n",
        "\n",
        "# Forest cover threshold for tile inclusion\n",
        "l4d_forest_threshold = 0.95\n",
        "\n",
        "# Forest mask year: 2023 used for L4D\n",
        "gedi_mask_year = 2023\n",
        "\n",
        "gpkg_raw = join(products_dir, \"GEDI_L4D_validation_metrics_raw.gpkg\")\n",
        "gpkg_selected = join(products_dir, \"GEDI_L4D_validation_metrics_selected.gpkg\")\n",
        "l4d_accuracy_path = join(model_comparison_dir, \"l4d_tile_accuracy.csv\")\n",
        "\n",
        "# Columns required for pooled accuracy calculation\n",
        "l4d_cols = ['rmse_agbd', 'agbd_mean_valid', 'valid_data_size_agbd', 'geometry']\n",
        "\n",
        "# Download validation gpkg\n",
        "if not exists(gpkg_raw):\n",
        "    print(\"Downloading L4D validation gpkg...\")\n",
        "    response = requests.get(l4d_gpkg_url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    with open(gpkg_raw, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192): f.write(chunk)\n",
        "    print(\"  Download complete\")\n",
        "else: print(\"L4D validation gpkg exists\")\n",
        "\n",
        "# Select tiles fully within template extent\n",
        "if not exists(gpkg_selected):\n",
        "    print(\"Selecting tiles within template extent...\")\n",
        "    tiles_gdf = gpd.read_file(gpkg_raw)[l4d_cols].to_crs(template_gdf.crs)\n",
        "    template_union = template_gdf.union_all()\n",
        "    tiles_selected = tiles_gdf[tiles_gdf.within(template_union)]\n",
        "    tiles_selected.to_file(gpkg_selected, driver=\"GPKG\")\n",
        "else: print(\"Selected gpkg exists\")\n",
        "\n",
        "# Calculate pooled accuracy for tiles meeting forest threshold\n",
        "tiles_gdf = gpd.read_file(gpkg_selected)\n",
        "print(f\"  Tiles within template extent: {len(tiles_gdf)}\")\n",
        "rmse_col, mean_col, n_col = \"rmse_agbd\", \"agbd_mean_valid\", \"valid_data_size_agbd\"\n",
        "gedi_mask_path = join(masks_dir, f\"mask_forest_{gedi_mask_year}.tif\")\n",
        "\n",
        "# Create temporary mask with nodata converted to 0 (for zonal histogram)\n",
        "mask_ds = gdal.Open(gedi_mask_path)\n",
        "mask_array = mask_ds.GetRasterBand(1).ReadAsArray()\n",
        "mask_array = np.where(mask_array == nodatavalue, 0, mask_array)\n",
        "temp_mask_path = join(products_dir, \"temp_forest_mask.tif\")\n",
        "export_array_as_tif(mask_array, temp_mask_path, template=gedi_mask_path)\n",
        "\n",
        "# Calculate forest fraction per tile using zonal histogram\n",
        "stats = zonal_stats(tiles_gdf.to_crs(mask_ds.GetProjection()), temp_mask_path, categorical=True)\n",
        "forest_fractions = [s.get(1, 0) / sum(s.values()) if s else 0 for s in stats]\n",
        "tiles_gdf['forest_fraction'] = forest_fractions\n",
        "mask_ds = None\n",
        "os.remove(temp_mask_path)\n",
        "\n",
        "# Filter by forest threshold and valid metrics\n",
        "tiles_valid = tiles_gdf[tiles_gdf['forest_fraction'] >= l4d_forest_threshold].dropna(subset=[rmse_col, mean_col, n_col])\n",
        "print(f\"  Tiles >={l4d_forest_threshold*100:.0f}% forest: {len(tiles_valid)}\")\n",
        "\n",
        "n = tiles_valid[n_col].values\n",
        "rmse_vals = tiles_valid[rmse_col].values\n",
        "mean_vals = tiles_valid[mean_col].values\n",
        "\n",
        "# Pooled metrics\n",
        "pooled_rmse = np.sqrt(np.sum(n * rmse_vals**2) / np.sum(n))\n",
        "pooled_mean = np.sum(n * mean_vals) / np.sum(n)\n",
        "pooled_rrmse = (pooled_rmse / pooled_mean) * 100\n",
        "print(f\"  RMSE={pooled_rmse:.4f}, rRMSE={pooled_rrmse:.2f}%, mean={pooled_mean:.2f}\")\n",
        "\n",
        "# Save results\n",
        "l4d_accuracy = {'source': f'L4D grid (tiles >={l4d_forest_threshold*100:.0f}% forest)', 'rmse': pooled_rmse, 'rrmse': pooled_rrmse, 'n_tiles': len(tiles_valid), 'n_validation_points': int(np.sum(n)), 'forest_threshold': l4d_forest_threshold}\n",
        "pd.DataFrame([l4d_accuracy]).to_csv(l4d_accuracy_path, index=False)\n",
        "print(f\"  Saved: {l4d_accuracy_path}\")"
      ],
      "metadata": {
        "id": "csNsaqoajjMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find model predictions\n",
        "# scenarios_dir: single prediction ({year}__{model}.tif)\n",
        "# predictions_dir: Monte Carlo mean (mean__{year}__{model}.tif)\n",
        "model_predictions = {}\n",
        "for source, pattern in [(scenarios_dir, r'^(\\d{4})__'), (predictions_dir, r'^mean__(\\d{4})__')]:\n",
        "    if not exists(source): continue\n",
        "    source_key = 'scenarios_dir' if source == scenarios_dir else 'predictions_dir'\n",
        "    for model_name in os.listdir(source):\n",
        "        pred_dir = join(source, model_name, 'scenario_predictions')\n",
        "        if not exists(pred_dir): continue\n",
        "        years = set()\n",
        "        for f in os.listdir(pred_dir):\n",
        "            match = re.match(pattern, f)\n",
        "            if match: years.add(match.group(1))\n",
        "        if years:\n",
        "            if model_name not in model_predictions: model_predictions[model_name] = {}\n",
        "            model_predictions[model_name][source_key] = sorted(years)\n",
        "\n",
        "# Print selectable dictionary\n",
        "print(\"\\n# Model predictions available:\")\n",
        "print(\"selected_predictions = {\")\n",
        "for model, categories in model_predictions.items():\n",
        "    print(f\"    '{model}': {{\")\n",
        "    for cat, years in categories.items():\n",
        "        print(f\"        '{cat}': [\")\n",
        "        for y in years:\n",
        "            print(f\"            '{y}',\")\n",
        "        print(f\"        ],\")\n",
        "    print(f\"    }},\")\n",
        "print(\"}\")"
      ],
      "metadata": {
        "id": "V3oTEwdbzyw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model predictions available:\n",
        "selected_predictions = {\n",
        "    # 'gedi_elevation_v2_1_260202_123700': {\n",
        "    #     'scenarios_dir': [\n",
        "    #         '2015',\n",
        "    #     ],\n",
        "    # },\n",
        "    'agbd_v2_1_260206_133525': {\n",
        "        # 'scenarios_dir': [\n",
        "        #     '2023',\n",
        "        #     '2024',\n",
        "        # ],\n",
        "        'predictions_dir': [\n",
        "            '2023',\n",
        "            # '2024',\n",
        "        ],\n",
        "    },\n",
        "    'agbd_v2_1_alpha_earth_260207_194523': {\n",
        "        'predictions_dir': [\n",
        "            '2023',\n",
        "        ],\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "m7FCBjQK0Csg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the original GEDI 4A .pkl generated in '2_variates.ipynb'\n",
        "print(\"Available datasets\")\n",
        "for f in os.listdir(targets_pkl_final_dir):\n",
        "    if f.endswith(\".pkl\"):\n",
        "        print(f'original_gedi4a_dataset = \"{f}\"')"
      ],
      "metadata": {
        "id": "uxtXAuVwHnP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_gedi4a_dataset = \"GEDI04_A_V2_1.pkl\"\n",
        "\n",
        "# Load footprints from the original GEDI L4A dataset\n",
        "# Accuracy comparison at sensitivity >= 0.98\n",
        "# Only 2023 and 2024 footprints used,\n",
        "# both have equal potential for temporal misalignment with end-of-year predictions.\n",
        "original_gedi4a_df = pd.read_pickle(join(targets_pkl_final_dir, original_gedi4a_dataset))\n",
        "accuracy_df = original_gedi4a_df[['geometry', 'timestamp', 'agbd', 'sensitivity']].copy()\n",
        "accuracy_df['year'] = pd.to_datetime(accuracy_df['timestamp']).dt.year\n",
        "accuracy_df = accuracy_df[(accuracy_df['sensitivity'] >= 0.98) & (accuracy_df['year'].isin([2023, 2024]))]\n",
        "\n",
        "category_labels = {'scenarios_dir': 'single prediction', 'predictions_dir': 'prediction mean'}\n",
        "results = []\n",
        "\n",
        "# Build list of sources to evaluate\n",
        "sources = [\n",
        "    ('L4D grid', l4d_masked),\n",
        "    ('L4B grid', [l4b_masked] if l4b_masked else []),\n",
        "    ('Veg grid', [veg_masked] if veg_masked else []),\n",
        "]\n",
        "for model_name, categories in selected_predictions.items():\n",
        "    for category, years in categories.items():\n",
        "        pred_dir = join(scenarios_dir if category == 'scenarios_dir' else predictions_dir, model_name, 'scenario_predictions')\n",
        "        for year in years:\n",
        "            raster_path = join(pred_dir, f\"{year}__{model_name}.tif\" if category == 'scenarios_dir' else f\"mean__{year}__{model_name}.tif\")\n",
        "            if exists(raster_path):\n",
        "                sources.append((f\"{model_name} ({category_labels[category]} {year})\", [raster_path]))\n",
        "\n",
        "# Evaluate each source\n",
        "for label, raster_paths in sources:\n",
        "    if not raster_paths: continue\n",
        "\n",
        "    # Sample rasters\n",
        "    samples = np.full(len(accuracy_df), nodatavalue, dtype=float)\n",
        "    for raster_path in raster_paths:\n",
        "        raster_ds = gdal.Open(raster_path)\n",
        "        srs = osr.SpatialReference()\n",
        "        srs.ImportFromWkt(raster_ds.GetProjection())\n",
        "        epsg = int(srs.GetAuthorityCode(None))\n",
        "        raster_ds = None\n",
        "        gdf = gpd.GeoDataFrame(accuracy_df, geometry='geometry', crs='EPSG:4326').to_crs(epsg=epsg)\n",
        "        temp_df = pd.DataFrame(index=accuracy_df.index)\n",
        "        sample_raster_values(temp_df, raster_path, gdf.geometry.x.values, gdf.geometry.y.values)\n",
        "        values = temp_df.iloc[:, 0].values\n",
        "        valid_update = (values >= 0) & (samples < 0)\n",
        "        samples[valid_update] = values[valid_update]\n",
        "\n",
        "    # Calculate metrics\n",
        "    valid_mask = samples >= 0\n",
        "    if valid_mask.sum() == 0: continue\n",
        "    obs, pred = accuracy_df['agbd'].values[valid_mask].astype('float32'), samples[valid_mask].astype('float32')\n",
        "    rmse = root_mean_squared_error(obs, pred)\n",
        "    results.append({'source': label, 'r2': r2_score(obs, pred), 'me': np.mean(obs - pred), 'rmse': rmse, 'rrmse': (rmse / np.mean(obs)) * 100, 'n_points': len(obs)})\n",
        "    print(f\"{label}: {len(obs)} points\")\n",
        "\n",
        "# Model cross-validation metrics\n",
        "for model_name in selected_predictions.keys():\n",
        "    model_desc_path = join(models_dir, model_name, \"model_description.json\")\n",
        "    if not exists(model_desc_path): continue\n",
        "    with open(model_desc_path) as f:\n",
        "        model_desc = json.load(f)\n",
        "    results.append({\n",
        "        'source': f'{model_name} (cross-validation)',\n",
        "        'r2': model_desc.get('score_validation (r2) mean', np.nan), 'me': model_desc.get('score_validation (me) mean', np.nan),\n",
        "        'rmse': model_desc.get('score_validation (rmse) mean', np.nan), 'rrmse': model_desc.get('score_validation (rrmse) mean', np.nan), 'n_points': np.nan\n",
        "    })\n",
        "print(\"Cross-validation: completed\")\n",
        "\n",
        "# Build comparison table\n",
        "comparison_df = pd.DataFrame(results)\n",
        "col_order = ['source', 'r2', 'me', 'rmse', 'rrmse', 'n_points']\n",
        "comparison_df = comparison_df[[c for c in col_order if c in comparison_df.columns]]\n",
        "comparison_path = join(model_comparison_dir, \"accuracy_comparison.csv\")\n",
        "comparison_df.to_csv(comparison_path, index=False)\n",
        "print(f\"\\nComparison saved: {comparison_path}\")\n",
        "print(comparison_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "LAHg3FT5rrIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nezNm_Gz3cnz"
      },
      "source": [
        "# Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hwTeCjzEgbB"
      },
      "outputs": [],
      "source": [
        "# Useful for stopping background execution upon completion\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "i1UxS-kO8_1d",
        "BiP-LeK_oCCK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}